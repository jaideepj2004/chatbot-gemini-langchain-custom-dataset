{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "!pip install -q --upgrade google-generativeai langchain-google-genai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to securely store your API key\n",
    "# from google.colab import userdata\n",
    "#dotenv package to load the API key\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY='AIzaSyCwmGOl-1oTUJgQc5dgShxJItP1bf8q_7w'\n",
    "\n",
    "genai.configure(api_key='AIzaSyCwmGOl-1oTUJgQc5dgShxJItP1bf8q_7w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo -e 'GOOGLE_API_KEY=AIzaSyCwmGOl-1oTUJgQc5dgShxJItP1bf8q_7w' > .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown\n",
    "import textwrap\n",
    "import os\n",
    "\n",
    "# Set your API key\n",
    "GOOGLE_API_KEY = 'AIzaSyCwmGOl-1oTUJgQc5dgShxJItP1bf8q_7w'\n",
    "\n",
    "# Configure the genai package with the API key\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Write the API key to a .env file\n",
    "with open('.env', 'w') as f:\n",
    "    f.write(f'GOOGLE_API_KEY={GOOGLE_API_KEY}\\n')\n",
    "\n",
    "# Check the content of the current directory (use dir on Windows)\n",
    "os.system('dir' if os.name == 'nt' else 'ls -a')\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Verify if the environment variable is set correctly\n",
    "api_key = os.getenv('GOOGLE_API_KEY')\n",
    "if api_key:\n",
    "    print(\"API key loaded successfully.\")\n",
    "else:\n",
    "    print(\"Failed to load API key.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a helper function that will convert the markdown into nicely formatted text\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•','*')\n",
    "  return Markdown(textwrap.indent(text, '>', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\"What is the meaning of life?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meaning of life is a profound and philosophical question that has been pondered by humans for centuries. There is no one definitive answer, as the meaning of life can vary from person to person and may change over time.\n",
      "\n",
      "Some people believe that the meaning of life is to find happiness or fulfillment. Others believe that it is to make a positive impact on the world, or to leave a legacy. Still others believe that the meaning of life is to simply experience it and enjoy the journey.\n",
      "\n",
      "Ultimately, the meaning of life is up to each individual to decide. There is no right or wrong answer, and the only way to find out what the meaning of life is for you is to explore your own beliefs and values.\n",
      "\n",
      "Here are some additional perspectives on the meaning of life:\n",
      "\n",
      "* **The Aristotelian view:** Aristotle believed that the meaning of life is to achieve eudaimonia, which is a state of happiness and well-being. He argued that this can be achieved through living a virtuous life and fulfilling one's potential.\n",
      "* **The Buddhist view:** Buddhism teaches that the meaning of life is to end suffering. This can be achieved through following the Eightfold Path, which is a set of ethical guidelines that lead to enlightenment.\n",
      "* **The existentialist view:** Existentialism is a philosophy that emphasizes the importance of individual freedom and choice. Existentialists believe that the meaning of life is to create one's own meaning through their actions and experiences.\n",
      "* **The nihilist view:** Nihilism is a philosophy that holds that life has no inherent meaning or purpose. Nihilists believe that the only way to cope with this is to embrace the absurdity of life and find joy in the moment.\n",
      "\n",
      "No matter what your beliefs are, the search for the meaning of life is an important part of being human. It is a journey that can lead to greater self-awareness, purpose, and happiness.\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       ">The meaning of life is a profound and philosophical question that has been pondered by humans for centuries. There is no one definitive answer, as the meaning of life can vary from person to person and may change over time.\n",
       ">\n",
       ">Some people believe that the meaning of life is to find happiness or fulfillment. Others believe that it is to make a positive impact on the world, or to leave a legacy. Still others believe that the meaning of life is to simply experience it and enjoy the journey.\n",
       ">\n",
       ">Ultimately, the meaning of life is up to each individual to decide. There is no right or wrong answer, and the only way to find out what the meaning of life is for you is to explore your own beliefs and values.\n",
       ">\n",
       ">Here are some additional perspectives on the meaning of life:\n",
       ">\n",
       ">* **The Aristotelian view:** Aristotle believed that the meaning of life is to achieve eudaimonia, which is a state of happiness and well-being. He argued that this can be achieved through living a virtuous life and fulfilling one's potential.\n",
       ">* **The Buddhist view:** Buddhism teaches that the meaning of life is to end suffering. This can be achieved through following the Eightfold Path, which is a set of ethical guidelines that lead to enlightenment.\n",
       ">* **The existentialist view:** Existentialism is a philosophy that emphasizes the importance of individual freedom and choice. Existentialists believe that the meaning of life is to create one's own meaning through their actions and experiences.\n",
       ">* **The nihilist view:** Nihilism is a philosophy that holds that life has no inherent meaning or purpose. Nihilists believe that the only way to cope with this is to embrace the absurdity of life and find joy in the moment.\n",
       ">\n",
       ">No matter what your beliefs are, the search for the meaning of life is an important part of being human. It is a journey that can lead to greater self-awareness, purpose, and happiness."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke(\"What is Mean Average Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       ">**Mean Average Precision (mAP)** is a performance metric used to evaluate object detection models. It measures the average precision across all classes and instance (object) locations in an image or set of images.\n",
       ">\n",
       ">**Calculation:**\n",
       ">\n",
       ">mAP is calculated as the mean of the Average Precision (AP) values for each class. AP, in turn, is calculated as the area under the precision-recall curve (AUC-PR).\n",
       ">\n",
       ">**Precision-Recall Curve:**\n",
       ">\n",
       ">The precision-recall curve plots the precision against the recall for different detection thresholds.\n",
       ">\n",
       ">* **Precision:** True positives / (True positives + False positives)\n",
       ">* **Recall:** True positives / (True positives + False negatives)\n",
       ">\n",
       ">**Steps for Calculating mAP:**\n",
       ">\n",
       ">1. Calculate the precision and recall for different detection thresholds for each class.\n",
       ">2. Plot the precision-recall curve for each class.\n",
       ">3. Calculate the AUC-PR for each class.\n",
       ">4. Calculate the AP for each class as the mean of the AUC-PR values.\n",
       ">5. Calculate the mAP as the mean of the AP values across all classes.\n",
       ">\n",
       ">**Interpretation:**\n",
       ">\n",
       ">* A higher mAP value indicates a better-performing object detection model.\n",
       ">* It measures both the accuracy (precision) and the completeness (recall) of the model's detections.\n",
       ">* A model with a high mAP can correctly identify and locate objects accurately while minimizing false positives and false negatives.\n",
       ">\n",
       ">**Advantages:**\n",
       ">\n",
       ">* Provides a comprehensive evaluation of object detection models.\n",
       ">* Considers both precision and recall, making it a balanced metric.\n",
       ">* Can be used to compare different models and identify areas for improvement.\n",
       ">\n",
       ">**Disadvantages:**\n",
       ">\n",
       ">* Can be computationally expensive to calculate, especially for large datasets.\n",
       ">* May be sensitive to the choice of detection thresholds."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "to_markdown(result.content)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import io\n",
    "# from PIL import Image\n",
    "\n",
    "# def show_image(url):\n",
    "#   response = requests.get(url)\n",
    "#   image = Image.open(io.BytesIO(response.content))\n",
    "#   display(image)\n",
    "\n",
    "# show_image(\"https://picsum.photos/seed/picsum/200/300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.messages import HumanMessage\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-pro-vision\")\n",
    "\n",
    "# message = HumanMessage(\n",
    "#     content=[\n",
    "#         {\n",
    "#             \"type\":\"text\",\n",
    "#             \"text\":\"What's in this image\"\n",
    "#         },\n",
    "#         {\n",
    "#             \"type\":\"image_url\",\n",
    "#             \"image_url\": \"https://picsum.photos/seed/picsum/200/300\"\n",
    "#         }\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# llm.invoke([message])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_image(\"https://t0.gstatic.com/licensed-image?q=tbn:ANd9GcQ_Kevbk21QBRy-PgB4kQpS79brbmmEG7m3VOTShAn4PecDU5H5UxrJxE3Dw1JiaG17V88QIol19-3TM2wCHw\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import  ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-pro-vision\")\n",
    "# message = HumanMessage(\n",
    "#     content=[\n",
    "#         {\n",
    "#             \"type\" : \"text\",\n",
    "#             \"text\" : \"Write a detailed blog post based on this picture, make sure to cover each and every aspect in the blog post\"\n",
    "#         },\n",
    "#         {\n",
    "#             \"type\":  \"image_url\",\n",
    "#             \"image_url\": \"https://t0.gstatic.com/licensed-image?q=tbn:ANd9GcQ_Kevbk21QBRy-PgB4kQpS79brbmmEG7m3VOTShAn4PecDU5H5UxrJxE3Dw1JiaG17V88QIol19-3TM2wCHw\"\n",
    "#         }\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = llm.invoke([message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_markdown(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\jaide\\anaconda3\\lib\\site-packages (0.2.6)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from langchain) (0.2.10)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from langchain) (0.1.82)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from langchain) (1.10.8)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from langchain) (8.4.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.5)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain) (2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\jaide\\anaconda3\\lib\\site-packages (4.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in c:\\users\\jaide\\anaconda3\\lib\\site-packages (0.5.3)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (1.2.1)\n",
      "Requirement already satisfied: requests>=2.28 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (1.10.8)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (0.111.0)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (0.30.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.22.5 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (1.24.3)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (4.11.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (1.18.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (1.25.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (0.13.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (4.66.4)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (6.4.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (1.64.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (4.1.3)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (0.12.3)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (30.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (8.4.2)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (6.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (3.10.5)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from chromadb) (0.27.0)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (24.1)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.4)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.37.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.0.4)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (3.1.2)\n",
      "Requirement already satisfied: python-multipart>=0.0.7 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.0.9)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (5.4.0)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (2.2.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.5.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\jaide\\appdata\\roaming\\python\\python311\\site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.58.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.26.16)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: protobuf in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (4.23.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.11.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=7.1,>=6.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (6.0.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.2)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.25.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.25.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.46b0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.46b0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.46b0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (68.0.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from requests>=2.28->chromadb) (2.0.4)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.0.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (13.7.1)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb) (2.6.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.7.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jaide\\appdata\\roaming\\python\\python311\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.15.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.4.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install pypdf\n",
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file pdfs already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in c:\\users\\jaide\\anaconda3\\lib\\site-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from gdown) (3.9.0)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from gdown) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from gdown) (4.66.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown) (2.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2023.7.22)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\jaide\\anaconda3\\lib\\site-packages (from tqdm->gdown) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1hPQlXrX8FbaYaLypxTmeVOFNitbBMlEE\n",
      "To: c:\\Users\\jaide\\OneDrive\\Desktop\\Data Science\\Internship\\SassyClick\\prototype2 gemini+langchain\\pdfs\\yolov7paper.pdf\n",
      "100%|██████████| 2.27M/2.27M [00:00<00:00, 4.38MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1vILwiv6nS2wI3chxNabMgry3qnV67TxM\n",
      "To: c:\\Users\\jaide\\OneDrive\\Desktop\\Data Science\\Internship\\SassyClick\\prototype2 gemini+langchain\\pdfs\\rachelgreecv.pdf\n",
      "100%|██████████| 271k/271k [00:00<00:00, 1.75MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'pdfs/rachelgreecv.pdf'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install gdown if not already installed\n",
    "!pip install gdown\n",
    "\n",
    "# Import gdown\n",
    "import gdown\n",
    "\n",
    "# URLs of the files to download\n",
    "url_yolov7paper = 'https://drive.google.com/uc?id=1hPQlXrX8FbaYaLypxTmeVOFNitbBMlEE'\n",
    "url_rachelgreecv = 'https://drive.google.com/uc?id=1vILwiv6nS2wI3chxNabMgry3qnV67TxM'\n",
    "\n",
    "# Destination paths\n",
    "output_yolov7paper = 'pdfs/yolov7paper.pdf'\n",
    "output_rachelgreecv = 'pdfs/rachelgreecv.pdf'\n",
    "\n",
    "# Download the files\n",
    "gdown.download(url_yolov7paper, output_yolov7paper, quiet=False)\n",
    "gdown.download(url_rachelgreecv, output_rachelgreecv, quiet=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFDirectoryLoader(\"pdfs\", load_hidden=True)\n",
    "data = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='LEC-1: Introduction to DBMS \\n1. What is Data?\\na. Data is a collection of raw, unorganized facts and details like text, observations, figures, symbols,\\nand descriptions of things etc.In other words, data does not carry any specific purpose and has no significance by itself.\\nMoreover, data is measured in terms of bits and bytes – which are basic units of information in the\\ncontext of computer storage and processing.\\nb. Data can be recorded and doesn’t have any meaning unless processed.\\n2. Types of Data\\na. Quanti tative\\ni.Numerical form\\nii.Weight, volume, cost of an item.\\nb. Qualitative\\ni.Descriptive, but not numerical.\\nii.Name, gender, hair color of a person.\\n3. What is Information?\\na. Info. Is processed, organized, and structured data.\\nb. It provides context of the data and enables decision making.\\nc. Processed data that make sense to us.\\nd. Information is extracted from the data, by analyzing and interpreti ng pieces of data.\\ne. E.g., you have data of all the people living in your locality, its Data, when you analyze and i\\nnterpret\\nth\\ne data and come to some conclusion that:\\ni.There are 100 senior citizens.\\nii.The sex ratio is 1.1.\\niii. Newborn babies are 100.These are information.\\n4. Data vs Information\\na. Data is a collection of facts, while information puts those facts into context.\\nb. While data is raw and unorganized, information is organized.\\nc. Data points are individual and sometimes unrelated. Information maps out that data to provide abig-picture view of how it all fits together.\\nd. Data, on its own, is meaningless. When it’s analyzed and interpreted, it becomes meaningfulinformation\\n.\\ne. Da\\nta does not depend on information; however, information depends on data.\\nf. Data typically comes in the f orm of graphs, numbers, figures, or statistics. Information is typicall y\\npr\\nesented through words, language, thoughts, and ideas.\\ng. Data isn’t sufficient for decision-making , but you can make decisions based on information.\\n5. What is Database ?\\na. Database is an electronic place/system where data is stored in a way that it can be  easily accessed,\\nmanaged,  and updated.\\nb. To make real use Data, we need Database management system s. (DBMS)\\n6. What is DBMS ?\\na. A database -management system (DBMS) is a collection of interrelated data  and a set of\\nprograms to access those data . The collection of data, usually referred to as the database ,\\ncontai\\nns information relevant to an enterprise. The primary goal of a DBMS is to provide a way to\\nstore and retrieve database  information  that is both convenient and efficient.\\nb. A DBMS is the database itself, along with all the software and functionality. It is used to perform\\ndifferent operations, like addition , access , updating, an d deletion  of the data.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 0}), Document(page_content='7. \\n8. DBMS vs File Systems\\na. File-processing systems  has major disadvantages .\\ni.Data Redundancy and inconsistency\\nii.Difficulty in accessing data\\niii. Data isolation\\niv. Integrity problems\\nv.Atomicity problems\\nvi. Concurrent -access anomalies\\nvii. Security problems\\nb. Above 7 are also the Advantages of DBMS  (answer to “ Why to use DBMS? ”)\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 1}), Document(page_content='LEC-2: DBMS Architecture \\n1. View of Data  (Three Schema Architecture)\\na. The major purpose of DBMS is to provide users with an abstract view  of the data. That is, t he\\nsystem hides certain details of how the data is stored and maintained.\\nb. To \\nsimplify user interaction with the system, abstraction is applied through several levels of\\nabstraction.\\nc. The main objective  of three level architecture is to enable multiple users to access the same dat a\\nwith a personalized view while storing the underlying data only once\\nd. Phys\\nical level / Internal level\\ni.The lowest level of abstraction describes how the data are stored.\\nii.Low -level data structures used.\\niii. It has Physical  schema which describes physical storage structure of DB.\\niv. Talks about: Storage allocation (N -ary tree etc), Data compression & encryption etc.\\nv.Goal : We must define algorithms that allow efficient access to data.\\ne. Logical level / Conceptual level:\\ni.The conceptual schema  describes the design of a database at the conceptual leve l,\\ndescribes wh at data are stored in DB, and what relationships  exist among those data.\\nii.User at logical level does not need to be aware about physical -level structures.\\niii. DBA, who must decide what information to keep in the DB use the logical level of\\nabstraction.\\niv\\n.Goal : ease to use.\\nf. View level / External level:\\ni.Highest level of abstraction aims to simplify users’ interaction with the system by\\nproviding different view to different end- user.\\nii.Each view schema  describes the database part that a particular user group is interest ed\\nand hides the remaining database fro m that user group.\\niii. At the external level, a database contains several schemas that sometimes called as\\nsubschema. The subschema is used to describe the different view of the database.\\niv. At views also provide a security mechanism to prevent users from accessing certain parts\\nof DB.\\ng. \\n2. Instances and Schemas\\na. The collection of information stored in the DB at a particular moment is called an instance of DB.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 2}), Document(page_content='b. The overall design of the DB is called the DB schema.\\nc. Schema is structural  description of data. Schema doesn’t change frequently. Data may change\\nfrequently.\\nd. DB schema  corresponds to the variable declarations (along with type) in a program.\\ne. We have 3 types of Schemas: Physical, Logical , several view schemas  called subschemas.\\nf. Logical schema is most important in terms of its effect on application programs , as programmers\\nconstruct apps by using logical schema.\\ng. Physical data independence , physical schema change should not affect logica l\\nsch\\nema/application programs.\\n3. Data Models:\\na. Provides a way to describe the design of a DB at logical level.\\nb. Underlying the structure of the DB is the Data Model; a collection of conceptual tools for describing\\ndata, data relationships, data semantics & consistency constraints .\\nc. E.g., ER model, Relational  Model, object -oriented model, object -relational  data model etc.\\n4. Database  Languages:\\na. Data definition language  (DDL) to specify the database schema.\\nb. Data manipulation language  (DML)  to express database queries and updates.\\nc. Practically , both language features are present in a single DB language, e.g., SQL language.\\nd. DDL\\ni.We specify consistency constraints, which must be checked, every time DB is updated.\\ne. DML\\ni.Data manipulation involves\\n1. Retrieval  of information stored in DB.\\n2. Insertion  of new information into DB.\\n3. Deletion of information from the DB.\\n4. Updating  existing information stored in DB.\\nii.Query language , a part of DML to specify statement requesting the retrieval of\\ninformation.\\n5. How is Database accessed from Application programs?\\na. Apps (written in host languages, C/C++, Java) interacts with DB.\\nb. E.g., Banking system’s module generating payrolls access DB by executing DML statements from\\nthe host language.\\nc. API is provided to send DML/DDL statements to DB and retrieve the results.\\ni.Open Database Connectivity ( ODBC), Microsoft “C”.\\nii.Java Database Connectivity ( JDBC ), Java.\\n6. Database Administrator (DBA)\\na. A person who has central control of both the data and the programs that access those data.\\nb. Functions  of DBA\\ni.Schema Definition\\nii.Storage structure and access methods .\\niii. Schema and physical organization modifications.\\niv. Authorization control.\\nv.Routine maintenance\\n1. Periodic backups.\\n2. Security patches.\\n3. Any upgrades.\\n7. DBMS  Application  Architectures: Client machines, on which remote DB users work, and server machines\\non which DB system runs.\\na. T1 Architecture\\ni.The client, server & DB all present on the same machine.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 3}), Document(page_content='b. T2 Architecture\\ni.App is partitioned into 2 -components.\\nii.Client machine, which invokes DB system functionality at server end through que ry\\nla\\nnguage statements.\\niii. API standards  like ODBC & JDBC  are used to interact between client and server.\\nc. T3 Architecture\\ni.App is partitioned into 3 logical components.\\nii.Client machine is just a frontend and doesn’t contain any direct DB calls.\\niii. Client machine  communicates with App server, and App server communicated with DB\\nsystem to access data.\\niv. Business logic, what action to take at that condition is in App server itself.\\nv.T3 architecture are best for WWW Applications.\\nvi. Advantages :\\n1. Scalability  due to distributed application servers.\\n2. Data integrity, App server acts as a middle layer between client and DB, which\\nminimize the chances of data corruption .\\n3. Security , client can’t directly access DB, hence it is more secure.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 4}), Document(page_content='LEC-3: Entity-Relationship Model \\n1. Data Model: Collection of conceptual tools for describing data, data relationships, data semantics, and consistency\\nconstraints.\\n2. ER Model\\n1. It is a high level data model based on a perception of a real world that consists of a collection of basic objects, calledentities and of relationships among these objects.\\n2. Graphical representation of ER Model is ER diagram, which acts as a blueprint of DB.\\n3. Entity: An Entity is a “thing” or “object” in the real world that is distinguishable from all other objects.\\n1. It has physical existence.\\n2. Each student in a college is an entity.\\n3. Entity can be uniquely identi fied. (By a primary a ttribute, aka Primary Key)\\n4. Strong Entity: Can be uniquely identi fied.\\n5. Weak Entity: Can’t be uniquely identi fied., depends on some other strong entity.\\n1. It doesn’t have su ﬃcient a ttributes, to select a uniquely identi fiable a ttribute.\\n2. Loan -> Strong Entity, Payment -> Weak, as instalments are sequential number counter can be generatedseparate for each loan.\\n3. Weak entity depends on strong entity for existence.\\n4. Entity set\\n1. It is a set of entities of the same type that share the same properties, or a ttributes.\\n2. E.g., Student is an entity set.\\n3. E.g., Customer of a bank\\n5. Attributes\\n1. An entity is represented by a set of a ttributes.\\n2. Each entity has a value for each of its a ttributes.\\n3. For each a ttribute, there is a set of permi tted values, called the domain, or value set, of that a ttribute.\\n4. E.g., Student Entity has following a ttributes\\nA. Student_ID\\nB. Name\\nC. Standard\\nD. Course\\nE. Batch\\nF. Contact number\\nG. Address\\n5. Types of A ttributes\\n1. Simple\\n1. Attributes which can’t be divided further.\\n2. E.g., Customer’s account number in a bank, Student’s Roll number etc.\\n2. Composite\\n1. Can be divided into subparts (that is, other a ttributes).\\n2. E.g., Name of a person, can be divided into first-name, middle-name, last-name.\\n3. If user wants to refer to an entire a ttribute or to only a component of the a ttribute.\\n4. Address can also be divided, street, city, state, PIN code.\\n3. Single-valued\\n1. Only one value a ttribute.\\n2. e.g., Student ID, loan-number for a loan.\\n4. Multi-valued\\n1. Attribute having more than one value.\\n2. e.g., phone-number, nominee-name on some insurance, dependent-name etc.\\n3. Limit constraint may be applied, upper or lower limits.\\n5. Derived\\n1. Value of this type of a ttribute can be derived from the value of other related a ttributes.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 5}), Document(page_content='2. e.g., Age, loan-age, membership-period etc.\\n6. NULL Value\\n1. An attribute takes a null value when an entity does not have a value for it.\\n2. It may indicate “not applicable”, value doesn’t exist. e.g., person having no middle-name\\n3. It may indicate “unknown”.\\n1. Unknown can indicate missing entry, e.g., name value of a customer is NULL, means it is missing as name\\nmust have some value.\\n2. Not known, salary a ttribute value of an employee is null, means it is not known yet.\\n6. Relationships\\n1. Association among two or more entities.\\n2. e.g., Person has vehicle, Parent has Child, Customer borrow loan etc.\\n3. Strong Relationship, between two independent entities.\\n4. Weak Relationship, between weak entity and its owner/strong entity.\\n1. e.g., Loan <instalment-payments> Payment.\\n5. Degree of Relationship\\n1. Number of entities participating in a relationship.\\n2. Unary, Only one entity participates. e.g., Employee manages employee.\\n3. Binary, two entities participates. e.g., Student takes Course.\\n4. Ternary relationship, three entities participates. E.g, Employee works-on branch, employee works-on job.\\n5. Binary are common.\\n7. Relationships Constraints\\n1. Mapping Cardinality / Cardinality Ratio\\n1. Number of entities to which another entity can be associated via a relationship.\\n2. One to one, Entity in A associates with at most one entity in B, where A & B are entity sets. And an entityof B is associated with at most one entity of A.\\n1. E.g., Citizen has Aadhar Card.\\n3. One to many, Entity in A associated with N entity in B. While entity in B is associated with at most oneentity in A.\\n1. e.g., Citizen has Vehicle.\\n4. Many to one, Entity in A associated with at most one entity in B. While entity in B can be associated withN entity in A.\\n1. e.g., Course taken by Professor.\\n5. Many to many, Entity in A associated with N entity in B. While entity in B also associated with N entity inA.\\n1. Customer buys product.\\n2. Student a ttend course.\\n2.Participation Constraints\\n1. Aka, Minimum cardinality constraint.\\n2. Types, Partial & Total Participation.\\n3. Partial Participation, not all entities are involved in the relationship instance.\\n4. Total Participation, each entity must be involved in at least one relationship instance.\\n5. e.g., Customer borrow loan, loan has total participation as it can’t exist without customer entity. And  \\ncustomer has partial participation.\\n6. Weak entity has total participation constraint, but strong may not have total.\\n8. ER Notations\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 6}), Document(page_content='CodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 7}), Document(page_content='LEC-4: Extended ER Features \\n1. Basic ER Features studied in the LEC-3, can be used to model most DB features but when complexity increases, it is\\nbetter to use some Extended ER features to model the DB Schema.\\n2. Specialisation\\n1. In ER model, we may require to subgroup an entity set into other entity sets that are distinct in some way with otherentity sets.\\n2. Specialisation is spli tting up the entity set into further sub entity sets on the basis of their functionalities,\\nspecialities and features.\\n3. It is a Top-Down approach.\\n4. e.g., Person entity set can be divided into customer, student, employee. Person is superclass and other specialisedentity sets are subclasses.\\n1. We have “is-a”  relationship between superclass and subclass.\\n2. Depicted by triangle component.\\n5. Why Specialisation?\\n1. Certain a ttributes may only be applicable to a few entities of\\nthe parent entity set.\\n2. DB designer can show the distinctive features of the sub entities.\\n3. To group such entities we apply Specialisation, to overall re fine the DB blueprint.\\n3. Generalisation\\n1. It is just a reverse of Specialisation.\\n2. DB Designer, may encounter certain properties of two entities are overlapping. Designer may consider to make anew generalised entity set. That generalised entity set will be a super class.\\n3. “is-a” relationship is present between subclass and super class.\\n4. e.g., Car, Jeep and Bus  all have some common a ttributes, to avoid data repetition for the common a ttributes. DB\\ndesigner may consider to Generalise to a new entity set “Vehicle”.\\n5. It is a Bottom-up approach.\\n6. Why Generalisation?\\n1. Makes DB more re fined and simpler.\\n2. Common a ttributes are not repeated.\\n4. Attribute Inheritance\\n1. Both  Specialisation and Generalisation, has a ttribute inheritance.\\n2.The attributes of higher level entity sets are inherited by lower level entity sets.\\n3. E.g., Customer & Employee inherit the a ttributes of Person.\\n5. Participation Inheritance\\n1. If a parent entity set participates in a relationship then its child entity sets will also participate in that relationship.\\n6. Aggregation\\n1. How to show relationships among relationships? - Aggregation is the technique.\\n2. Abstraction is applied to treat relationships as higher-level entities. We can call it Abstract entity.\\n3. Avoid redundancy by aggregating relationship as an entity set itself.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 8}), Document(page_content='LEC-7: Relational Model \\n1. Relational Model (RM) organises the data in the form of relations (tables).\\n2. A relational DB consists of collection of tables, each of which is assigned a unique name.\\n3. A row  in a table represents a relationship among a set of values, and table is collection of such relationships.\\n4. Tuple: A single row of the table representing a single data point / a unique record.\\n5. Columns: represents the a ttributes of the relation. Each a ttribute, there is a permi tted value, called domain of the\\nattribute.\\n6. Relation Schema: de fines the design and structure of the relation, contains the name of the relation and all the\\ncolumns/a ttributes.\\n7. Common RM based DBMS systems, aka RDBMS: Oracle, IBM, MySQL, MS Access.\\n8. Degree of table: number of a ttributes/columns in a given table/relation.\\n9. Cardinality: Total no. of tuples in a given relation.\\n10. Relational Key: Set of a ttributes which can uniquely identify an each tuple.\\n11. Important properties of a Table in Relational Model\\n1.The name of relation is distinct among all other relation.\\n2.The values have to be atomic. Can’t be broken down further.\\n3.The name of each a ttribute/column must be unique.\\n4. Each tuple must be unique in a table.\\n5.The sequence of row and column has no signi ficance.\\n6. Tables must follow integrity constraints - it helps to maintain data consistency across the tables.\\n12. Relational Model Keys\\n1. Super Key (SK ): Any P&C of a ttributes present in a table which can uniquely identify each tuple.\\n2. Candidate Key (CK): minimum subset of super keys, which can uniquely identify each tuple. It contains no\\nredundant a ttribute.\\n1. CK value shouldn’t be NULL.\\n3. Primary Key (PK):\\n1. Selected out of CK set, has the least no. of a ttributes.\\n4. Alternate Key (AK)\\n1. All CK except PK.\\n5. Foreign Key (FK )\\n1. It creates relation between two tables.\\n2. A relation, say r1, may include among its a ttributes the PK of an other relation, say r2. This a ttribute is called FK\\nfrom r1 referencing r2.\\n3.The relation r1 is aka Referencing (Child) relation of the FK dependency, and r2 is called Referenced (Parent)relation of the FK.\\n4. FK helps to cross reference between two di ﬀerent relations.\\n6. Composite Key: PK formed using at least 2 a ttributes.\\n7. Compound Key: PK which is formed using 2 FK.\\n8. Surrogate Key:\\n1. Synthetic PK.\\n2. Generated automatically by DB, usually an integer value.\\n3. May be used as PK.\\n13. Integrity Constraints\\n1. CRUD Operations must be done with some integrity policy so that DB is always consistent.\\n2. Introduced so that we do not accidentally corrupt the DB.\\n3. Domain Constraints\\n1. Restricts the value in the a ttribute of relation, speci fies the Domain.\\n2. Restrict the Data types of every a ttribute.\\n3. E.g., We want to specify that the enrolment should happen for candidate birth year < 2002.\\n4. Entity Constraints\\n1. Every relation should have PK. PK != NULL.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 9}), Document(page_content='5. Referential Constraints \\n1. Specified between two relations & helps maintain consistency among tuples of two relations. \\n2. It requires that the value appearing in speci fied attributes of any tuple in referencing relation also appear in the \\nspecified attributes of at least one tuple in the referenced relation.   \\n3. If FK in referencing table refers to PK of referenced table then every value of the FK in referencing table must be \\nNULL or available in referenced table. \\n4. FK must have the matching PK for its each value in the parent table or it must be NULL. \\n6. Key Constraints: The six types of key constraints present in the Database management system are:- \\n1. NOT NULL:  This constraint will restrict the user from not having a NULL value. It ensures that every element in the database has a value. \\n2. UNIQUE: It helps us to ensure that all the values consisting in a column are di ﬀerent from each other. \\n3. DEFAULT: it is used to set the default value to the column. The default value is added to the columns if no value is speci fied for them.  \\n4. CHECK: It is one of the integrity constraints in DBMS. It keeps the check that integrity of data is maintained before and after the completion of the CRUD. \\n5. PRIMARY KEY: This is an a ttribute or set of a ttributes that can uniquely identify each entity in the entity set. The \\nprimary key must contain unique as well as not null values. \\n6. FOREIGN KEY: Whenever there is some relationship between two entities, there must be some common attribute between them. This common a ttribute must be the primary key of an entity set and will become the \\nforeign key of another entity set. This key will prevent every action which can result in loss of connection between tables.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 10}), Document(page_content='LEC-8: Transform - ER Model to Relational Model \\n1. Both ER-Model and Relational Model are abstract logical representation of real world enterprises. Because the two\\nmodels implies the similar design principles, we can convert ER design into Relational design.\\n2. Converting a DB representation from an ER diagram to a table format is the way we arrive at Relational DB-design froman ER diagram.\\n3. ER diagram notations to relations:\\n1. Strong Entity\\n1. Becomes an individual table with entity name, a ttributes becomes columns of the relation.\\n2. Entity’s Primary Key (PK) is used as Relation’s PK.\\n3. FK are added to establish relationships with other relations.\\n2. Weak Entity\\n1. A table is formed with all the a ttributes of the entity.\\n2. PK of its corresponding Strong Entity will be added as FK .\\n3. PK of the relation will be a composite PK, {FK + Partial discriminator Key}.\\n3. Single Values A ttributes\\n1. Represented as columns directly in the tables/relations.\\n4. Composite A ttributes\\n1. Handled by creating a separate a ttribute itself in the original relation for each composite a ttribute.\\n2. e.g., Address: {street-name, house-no}, is a composite a ttribute in customer relation, we add address-street-\\nname & address-house-name as new columns in the a ttribute and ignore “address” as an a ttribute.\\n5. Multivalued A ttributes\\n1. New tables (named as original a ttribute name) are created for each multivalued a ttribute.\\n2. PK of the entity is used as column FK  in the new table.\\n3. Multivalued a ttribute’s similar name is added as a column to de fine multiple values.\\n4. PK of the new table would be {FK + multivalued name}.\\n5. e.g., For Strong entity Employee, dependent-name is a multivalued a ttribute.\\n1. New table named dependent-name will be formed with columns emp-id, and dname.\\n2. PK: {emp-id, name}\\n3. FK: {emp-id}\\n6. Derived A ttributes: Not considered in the tables.\\n7. Generalisation\\n1. Method-1: Create a table for the higher level entity set. For each lower-level entity set, create a table thatincludes a column for each of the a ttributes of that entity set plus a column for each a ttribute of the primary key\\nof the higher-level entity set.\\nFor e.g., Banking System generalisation of Account - saving & current.\\n1. Table 1: account (account-number, balance)\\n2. Table 2: savings-account (account-number, interest-rate, daily-withdrawal-limit)\\n3. Table 3: current-account (account-number, overdraft -amount, per-transaction-charges)\\n2. Method-2: An alternative representation is possible, if the generalisation is disjoint and complete—that is, if noentity is a member of two lower-level entity sets directly below a higher-level entity set, and if every entity inthe higher level entity set is also a member of one of the lower-level entity sets. Here, do not create a table forthe higher-level entity set. Instead, for each lower-level entity set, create a table that includes a column for eachof the a ttributes of that entity set plus a column for each a ttribute of the higher-level entity sets.\\nTables would be:\\n1. Table 1: savings-account (account-number, balance, interest-rate, daily-withdrawal-limit)\\n2. Table 2: current-account (account-number, balance, overdraft -amount, per-transaction-charges)\\n3. Drawbacks of Method-2: If the second method were used for an overlapping generalisation, some values suchas balance would be stored twice unnecessarily. Similarly, if the generalisation were not complete—that is, ifsome accounts were neither savings nor current accounts—then such accounts could not be represented withthe second method.\\n8. Aggregation\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 11}), Document(page_content='1. Table of the relationship set is made. \\n2. Attributes includes primary keys of entity set and aggregation set’s entities. \\n3. Also, add descriptive a ttribute if any on the relationship.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 12}), Document(page_content='LEC-9: SQL in 1-Video \\n1. SQL: Structured Query Language, used to access and manipulate data.\\n2. SQL used CRUD operations to communicate with DB.\\n1. CREATE - execute INSERT statements to insert new tuple into the relation.\\n2. READ - Read data already in the relations.\\n3. UPDATE - Modify already inserted data in the relation.\\n4. DELETE - Delete speci fic data point/tuple/row or multiple rows.\\n3. SQL is not DB, is a query language.\\n4. What is RDBMS? (Relational Database Management System)\\n1. Software that enable us to implement designed relational model.\\n2. e.g., MySQL, MS SQL, Oracle, IBM etc.\\n3. Table/Relation is the simplest form of data storage object in R-DB.\\n4. MySQL is open-source RDBMS, and it uses SQL for all CRUD operations\\n5. MySQL used client-server model, where client is CLI or frontend that used services provided by MySQL server.\\n6. Diﬀerence between SQL and MySQL\\n1. SQL is Structured Query language used to perform CRUD operations in R-DB, while MySQL is a RDBMS used to\\nstore, manage and administrate DB (provided by itself) using SQL.\\nSQL DATA TYPES (Ref: https://www.w3schools.com/sql/sql_datatypes.asp ) \\n1. In SQL DB, data is stored in the form of tables.\\n2. Data can be of di ﬀerent types, like INT, CHAR etc.\\nDATATYPE Description\\nCHAR string(0-255), string with size = (0, 255], e.g., \\nCHAR(251)\\nVARCHAR string(0-255)\\nTINYTEXT String(0-255)\\nTEXT string(0-65535)\\nBLOB string(0-65535)\\nMEDIUMTEXT string(0-16777215)\\nMEDIUMBLOB string(0-16777215)\\nLONGTEXT string(0-4294967295)\\nLONGBLOB string(0-4294967295)\\nTINYINT integer(-128 to 127)\\nSMALLINT integer(-32768 to 32767)\\nMEDIUMINT integer(-8388608 to 8388607)\\nINT integer(-2147483648 to 2147483647)\\nBIGINT integer (-9223372036854775808 to \\n9223372036854775807)\\nFLOAT Decimal with precision to 23 digits\\nDOUBLE Decimal with 24 to 53 digitsDATATYPE\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 13}), Document(page_content='3. Size: TINY < SMALL < MEDIUM < INT < BIGINT. \\n4. Variable length Data types e.g., VARCHAR, are be tter to use as they occupy space equal to the actual data size. \\n5. Values can also be unsigned e.g., INT UNSIGNED. \\n6. Types of SQL commands: \\n1. DDL (data de finition language): de fining relation schema. \\n1. CREATE: create table, DB, view. \\n2. ALTER TABLE: modi fication in table structure. e.g, change column datatype or add/remove columns. \\n3. DROP: delete table, DB, view. \\n4. TRUNCATE: remove all the tuples from the table. \\n5. RENAME: rename DB name, table name, column name etc. \\n2. DRL/DQL (data retrieval language / data query language): retrieve data from the tables. \\n1. SELECT \\n3. DML (data modi fication language): use to perform modi fications in the DB \\n1. INSERT: insert data into a relation \\n2. UPDATE: update relation data. \\n3. DELETE: delete row(s) from the relation. \\n4. DCL (Data Control language): grant or revoke authorities from user. \\n1. GRANT: access privileges to the DB \\n2. REVOKE: revoke user access privileges. \\n5. TCL (Transaction control language): to manage transactions done in the DB \\n1. START TRANSACTION: begin a transaction \\n2. COMMIT: apply all the changes and end transaction \\n3. ROLLBACK: discard changes and end transaction \\n4. SAVEPOINT: checkout within the group of transactions in which to rollback. \\nMANAGING DB (DDL) \\n1. Creation of DB \\n1. CREATE DATABASE IF NOT EXISTS db-name; \\n2. USE db-name; //need to execute to choose on which DB CREATE TABLE etc commands will be executed. \\n//make switching between DBs possible. \\n3. DROP DATABASE IF EXISTS db-name; //dropping database. \\n4. SHOW DATABASES; //list all the DBs in the server. \\n5. SHOW TABLES; //list tables in the selected DB. DECIMAL Double stored as string\\nDATE YYYY-MM-DD\\nDATETIME YYYY-MM-DD HH:MM:SS\\nTIMESTAMP YYYYMMDDHHMMSS\\nTIME HH:MM:SS\\nENUM One of the preset values\\nSET One or many of the preset values\\nBOOLEAN 0/1\\nBIT e.g., BIT(n), n upto 64, store values in bits.Description DATATYPE\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 14}), Document(page_content=\"DATA RETRIEVAL LANGUAGE (DRL) \\n1. Syntax: SELECT <set of column names> FROM <table_name>; \\n2. Order of execution from RIGHT to LEFT. \\n3. Q. Can we use SELECT keyword without using FROM clause? \\n1. Yes, using DUAL Tables. \\n2. Dual tables are dummy tables created by MySQL, help users to do certain obvious actions without referring to user \\ndefined tables. \\n3. e.g., SELECT 55 + 11; SELECT now(); SELECT ucase(); etc. \\n4. WHERE \\n1. Reduce rows based on given conditions. \\n2. E.g., SELECT * FROM customer WHERE age > 18; \\n5. BETWEEN \\n1. SELECT * FROM customer WHERE age between 0 AND 100; \\n2. In the above e.g., 0 and 100 are inclusive. \\n6. IN \\n1. Reduces OR conditions; \\n2. e.g., SELECT *  FROM o ﬃcers WHERE o ﬃcer_name IN ('Lakshay', ‘Maharana Pratap', ‘Deepika’); \\n7. AND/OR/NOT \\n1. AND: WHERE cond1 AND cond2 \\n2. OR: WHERE cond1 OR cond2 \\n3. NOT: WHERE col_name NOT IN (1,2,3,4); \\n8. IS NULL \\n1. e.g., SELECT * FROM customer WHERE prime_status is NULL; \\n9. Pattern Searching / Wildcard (‘%’, ‘_’) \\n1. ‘%’, any number of character from 0 to n. Similar to ‘*’ asterisk in regex. \\n2. ‘_’, only one character. \\n3. SELECT * FROM customer WHERE name LIKE ‘%p_’; \\n10. ORDER BY \\n1. Sorting the data retrieved using WHERE clause. \\n2. ORDER BY <column-name> DESC; \\n3. DESC = Descending and ASC = Ascending \\n4. e.g., SELECT * FROM customer ORDER BY name DESC; \\n11. GROUP BY \\n1. GROUP BY Clause is used to collect data from multiple records and group the result by one or more column. It is generally used in a SELECT statement. \\n2. Groups into category based on column given. \\n3. SELECT c1, c2, c3 FROM sample_table WHERE cond GROUP BY c1, c2, c3. \\n4. All the column names mentioned after SELECT statement shall be repeated in GROUP BY, in order to successfully execute the query. \\n5. Used with aggregation functions to perform various actions. \\n1. COUNT() \\n2. SUM() \\n3. AVG() \\n4. MIN() \\n5. MAX() \\n12. DISTINCT \\n1. Find distinct values in the table. \\n2. SELECT DISTINCT(col_name) FROM table_name; \\n3. GROUP BY can also be used for the same \\n1. “Select col_name from table GROUP BY col_name;” same output as above DISTINCT query. \\nCodeHelp\", metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 15}), Document(page_content='2. SQL is smart enough to realise that if you are using GROUP BY and not using any aggregation function, then\\nyou mean “DISTINCT”.\\n13. GROUP BY HAVING\\n1. Out of the categories made by GROUP BY, we would like to know only particular thing (cond).\\n2. Similar to WHERE.\\n3. Select COUNT(cust_id), country from customer GROUP BY country HAVING COUNT(cust_id) > 50;\\n4. WHERE vs HAVING\\n1. Both have same function of filtering the row base on certain conditions.\\n2. WHERE clause is used to filter the rows from the table based on speci fied condition\\n3. HAVING clause is used to filter the rows from the groups based on the speci fied condition.\\n4. HAVING is used after GROUP BY while WHERE is used before GROUP BY clause.\\n5. If you are using HAVING, GROUP BY is necessary.\\n6. WHERE can be used with SELECT, UPDATE & DELETE keywords while GROUP BY used with SELECT.\\nCONSTRAINTS (DDL) \\n1. Primary Key\\n1. PK is not null, unique and only one per table.\\n2.Foreign Key\\n1. FK refers to PK of other table.\\n2. Each relation can having any number of FK.\\n3. CREATE TABLE ORDER (\\nid INT PRIMARY KEY,\\ndelivery_date DATE,\\norder_placed_date DATE,\\ncust_id INT,\\nFOREIGN KEY (cust_id) REFERENCES customer(id)\\n);\\n3.UNIQUE\\n1. Unique, can be null, table can have multiple unique att ributes.\\n2. CREATE TABLE customer (\\n…\\nemail VARCHAR(1024) UNIQUE,\\n…\\n);\\n4.CHECK\\n1. CREATE TABLE customer (\\n…\\nCONSTRAINT age_check CHECK (age > 12),\\n…\\n);\\n2. “age_check”, can also avoid this, MySQL generates name of constraint automatically.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 16}), Document(page_content='5. DEFAULT\\n1. Set default value of the column.\\n2. CREATE TABLE account (\\n…\\ns\\naving-rate DOUBLE NOT NULL DEFAULT 4.25,\\n…\\n);\\n6. An attribute can be PK and FK both in a table.\\n7. ALTER OPERATIONS\\n1. Changes schema\\n2. ADD\\n1. Add new column.\\n2. ALTER TABLE table_name ADD new_col_name datatype ADD new_col_name_2 datatype;\\n3. e.g., ALTER TABLE customer ADD age INT NOT NULL;\\n3. MODIFY\\n1. Change datatype of an a ttribute.\\n2. ALTER TABLE table-name MODIFY col-name col-datatype;\\n3. E.g., VARCHAR TO CHAR\\nAL\\nTER TABLE customer MODIFY name CHAR(1024);\\n4. CHANGE COLUMN\\n1. Rename column name.\\n2. ALTER TABLE table-name CHANGE COLUMN old-col-name new-col-name new-col-datatype;\\n3. e.g., ALTER TABLE customer CHANGE COLUMN name customer-name VARCHAR(1024);\\n5. DROP COLUMN\\n1. Drop a column completely.\\n2. ALTER TABLE table-name DROP COLUMN col-name;\\n3. e.g., ALTER TABLE customer DROP COLUMN middle-name;\\n6. RENAME\\n1. Rename table name itself.\\n2. ALTER TABLE table-name RENAME TO new-table-name;\\n3. e.g., ALTER TABLE customer RENAME TO customer-details;\\nDATA MANIPULATION LANGUAGE (DML) \\n1. INSERT\\n1. INSERT INTO table-name(col1, col2, col3) VALUES (v1, v2, v3), (val1, val2, val3);\\n2. UPDATE\\n1. UPDATE table-name SET col1 = 1, col2 = ‘abc’ WHERE id = 1;\\n2. Update multiple rows e.g.,\\n1. UPDATE student SET standard = standard + 1;\\n3. ON UPDATE CASCADE\\n1. Can be added to the table while creating constraints. Suppose there is a situation where we have two tables\\nsuch that primary key of one table is the foreign key for another table. if we update the primary key of the firsttable then using the ON UPDATE CASCADE foreign key of the second table automatically get updated.\\n3. DELETE\\n1. DELETE FROM table-name WHERE id = 1;\\n2. DELETE FROM table-name; //all rows will be deleted.\\n3. DELETE CASCADE - (to overcome DELETE constraint of Referential constraints)\\n1. What would happen to child entry if parent table’s entry is deleted?\\n2. CREATE TABLE ORDER (\\nor\\nder_id int PRIMARY KEY,\\nde\\nlivery_date DATE,\\nc\\nust_id INT,\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 17}), Document(page_content='FOREIGN KEY(cust_id) REFERENCES customer(id) ON DELETE CASCADE \\n); \\n3. ON DELETE NULL - (can FK have null values?)\\n1. CREATE TABLE ORDER (\\nor\\nder_id int PRIMARY KEY,\\nde\\nlivery_date DATE,\\nc\\nust_id INT,\\nF\\nOREIGN KEY(cust_id) REFERENCES customer(id) ON DELETE SET NULL\\n);\\n4. REPLACE\\n1. Primarily used for already present tuple in a table.\\n2. As UPDATE, using REPLACE with the help of WHERE clause in PK, then that row will be replaced.\\n3. As INSERT, if there is no duplicate data new tuple will be inserted.\\n4. REPLACE INTO student (id, class) VALUES(4, 3);\\n5. REPLACE INTO table SET col1 = val1, col2 = val2;\\nJOINING TABLES \\n1. All RDBMS are relational in nature, we refer to other tables to get meaningful outcomes.\\n2. FK are used to do reference to other table.\\n3. INNER JOIN\\n1. Returns a resultant table that has matching values from both the tables or all the tables.\\n2. SELECT column-list FROM table1 INNER JOIN table2 ON condition1\\nINNER J\\nOIN table3 ON condition2\\n…;\\n3. Alias in MySQL (AS)\\n1. Aliases in MySQL is used to give a temporary name to a table or a column in a table for the purpose ofa particular query. It works as a nickname for expressing the tables or column names. It makes the query shortand neat.\\n2. SELECT col_name AS alias_name FROM table_name;\\n3. SELECT col_name1, col_name2,... FROM table_name AS alias_name;\\n4. OUTER JOIN\\n1. LEFT JOIN\\n1.This returns a resulting table that all the data from le ft table and the matched data from the right table.\\n2. SELECT columns FROM table LEFT JOIN table2 ON Join_Condition;\\n2. RIGHT JOIN\\n1.This returns a resulting table that all the data from right table and the matched data from the le ft table.\\n2. SELECT columns FROM table RIGHT JOIN table2 ON join_cond;\\n3. FULL JOIN\\n1.This returns a resulting table that contains all data when there is a match on le ft or right table data.\\n2. Emulated in MySQL using LEFT and RIGHT JOIN.\\n3. LEFT JOIN UNION RIGHT JOIN.\\n4. SELECT columns FROM table1 as t1 LEFT JOIN table2 as t2 ON t1.id = t2.id\\nUNION\\nSELECT columns FROM table1 as t1 RIGHT JOIN table2 as t2 ON t1.id = t2.id ;\\n5. UNION ALL, can also be used this will duplicate values as well while UNION gives unique values.\\n5. CROSS JOIN\\n1.This returns all the cartesian products of the data present in both tables. Hence, all possible variationsare reflected in the output.\\n2. Used rarely in practical purpose.\\n3. Table-1 has 10 rows and table-2 has 5, then resultant would have 50 rows.\\n4. SELECT column-lists FROM table1 CROSS JOIN table2;\\n6. SELF JOIN\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 18}), Document(page_content='1. It is used to get the output from a particular table when the same table is joined to itself. \\n2. Used very less. \\n3. Emulated using INNER JOIN. \\n4. SELECT columns FROM table as t1 INNER JOIN table as t2 ON t1.id = t2.id ; \\n7. Join without using join keywords. \\n1. SELECT * FROM table1,  table2 WHERE condition; \\n2. e.g., SELECT artist_name, album_name, year_recordedFROM artist, albumWHERE artist.id = album.artist_id; \\nSET OPERATIONS \\n1. Used to combine multiple select statements. \\n2. Always gives distinct rows. \\n3. UNION \\n1. Combines two or more SELECT statements. \\n2. SELECT * FROM table1 \\nUNION SELECT * FROM table2; \\n3. Number of column, order of column must be same for table1 and table2. \\n4. INTERSECT \\n1. Returns common values of the tables. \\n2. Emulated. \\n3. SELECT DISTINCT column-list FROM table-1 INNER JOIN table-2 USING(join_cond); \\n4. SELECT DISTINCT * FROM table1 INNER JOIN table2 ON USING(id); \\n5. MINUS \\n1.This operator returns the distinct row from the first table that does not occur in the second table. \\n2. Emulated. \\n3. SELECT column_list FROM table1 LEFT JOIN table2 ON condition WHERE table2.column_name IS NULL; \\n4. e.g., SELECT id FROM table-1 LEFT JOIN table-2 USING(id) WHERE table-2.id  IS NULL; \\n \\nSUB QUERIES \\n1. Outer query depends on inner query. \\n2. Alternative to joins. \\n3. Nested queries. \\n4. SELECT column_list (s) FROM  table_name  WHERE  column_name OPERATOR (SELECT column_list (s)  FROM table_name [WHERE]); \\n5. e.g., SELECT * FROM table1 WHERE col1 IN (SELECT col1 FROM table1); \\n6. Sub queries exist mainly in 3 clauses \\n1. Inside a WHERE clause. JOIN SET Operations\\nCombines multiple tables based on matching \\ncondition.Combination is resulting set from two or more \\nSELECT statements.\\nColumn wise combination. Row wise combination.\\nData types of two tables can be diﬀerent. Datatypes of corresponding columns from each \\ntable should be the same.\\nCan generate both distinct or duplicate rows. Generate distinct rows.\\nThe number of column(s) selected may or may not \\nbe the same from each table.The number of column(s) selected must be the \\nsame from each table.\\nCombines results horizontally. Combines results vertically.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 19}), Document(page_content='2. Inside a FROM clause. \\n3. Inside a SELECT clause. \\n7. Subquery using FROM clause \\n1. SELECT MAX(rating) FROM (SELECT * FROM movie WHERE country = ‘India’) as temp; \\n8. Subquery using SELECT \\n1. SELECT (SELECT column_list(s) FROM T_name WHERE condition), columnList(s) FROM T2_name WHERE \\ncondition; \\n9. Derived Subquery \\n1. SELECT columnLists(s) FROM (SELECT columnLists(s) FROM table_name WHERE [condition]) as new_table_name; \\n10. Co-related sub-queries \\n1. With a normal nested subquery, the inner SELECT query runs first and executes once, returning values to be used by the main query. A correlated subquery, however, executes once for each candidate row considered by the outer query. In other words, the inner query is driven by the outer query. \\nJOIN VS SUB-QUERIES \\nMySQL VIEWS \\n1. A view is a database object that has no values. Its contents are based on the base table. It contains rows and columns similar to the real table. \\n2. In MySQL, the View is a virtual table created by a query by joining one or more tables. It is operated similarly to the base table but does not contain any data of its own. \\n3.The View and table have one main di ﬀerence that the views are de finitions built on top of other tables (or views). If any \\nchanges occur in the underlying table, the same changes re flected in the View also. \\n4. CREATE VIEW view_name AS SELECT columns FROM tables [WHERE conditions]; \\n5. ALTER VIEW view_name AS SELECT columns FROM table WHERE conditions; \\n6. DROP VIEW IF EXISTS view_name; \\n7. CREATE VIEW Trainer AS SELECT c.course_name, c.trainer, t.email FROM courses c, contact t WHERE c.id = t.id; (View using Join clause). \\nNOTE: We can also import/export table schema from files (.csv or json).JOINS SUBQUERIES\\nFaster Slower\\nJoins maximise calculation burden on DBMS Keeps responsibility of calculation on user.\\nComplex, diﬃcult to understand and implement Comparatively easy to understand and implement.\\nChoosing optimal join for optimal use case is \\ndiﬃcultEasy.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 20}), Document(page_content=\"LEC-11: Normalisation \\n1. Normalisation is a step towards DB optimisation.\\n2. Functional Dependency (FD)\\n1. It's a relationship between the primary key a ttribute (usually) of the relation to that of the other a ttribute of the\\nrelation.\\n2. X -> Y, the le ft side of FD is known as a Determinant, the right side of the production is known as a Dependent.\\n3. Types of FD\\n1. Trivial FD\\n1. A → B has trivial functional dependency if B is a subset of A. A->A, B->B are also Trivial FD.\\n2. Non-trivial FD\\n1. A → B has a non-trivial functional dependency if B is not a subset of A. [A intersection B is NULL].\\n4. Rules of FD (Armstrong’s axioms)\\n1. Reflexive\\n1. If ‘A’ is a set of a ttributes and ‘B’ is a subset of ‘A’. Then, A→ B holds.\\n2. If A ⊇ B then A → B.\\n2. Augmentation\\n1. If B can be determined from A, then adding an a ttribute to this functional dependency won’t change\\nanything.\\n2. If A→ B holds, then AX→ BX holds too. ‘X’ being a set of a ttributes.\\n3. Transitivity\\n1. If A determines B and B determines C, we can say that A determines C.\\n2. if A→ B and B→ C then A→ C.\\n3. Why Normalisation?\\n1. To avoid redundancy in the DB, not to store redundant data.\\n4. What happen if we have redundant data?\\n1. Insertion, deletion and updation anomalies arises.\\n5. Anomalies\\n1. Anomalies means abnormalities, there are three types of anomalies introduced by data redundancy.\\n2. Insertion anomaly\\n1. When certain data (a ttribute) can not be inserted into the DB without the presence of other data.\\n3. Deletion anomaly\\n1.The delete anomaly refers to the situation where the deletion of data results in the unintended loss of some\\nother important data.\\n4. Updation anomaly (or modi fication anomaly)\\n1.The update anomaly is when an update of a single data value requires multiple rows of data to be updated.\\n2. Due to updation to many places, may be Data inconsistency arises, if one forgets to update the data at all theintended places.\\n5. Due to these anomalies, DB size increases and DB performance become very slow.\\n6. To rectify these anomalies and the e ﬀect of these of DB, we use Database optimisation technique called\\nNORMALISATION.\\n6. What is Normalisation?\\n1. Normalisation is used to minimise the redundancy from a relations. It is also used to eliminate undesirablecharacteristics like Insertion, Update, and Deletion Anomalies.\\n2. Normalisation divides the composite a ttributes into individual a ttributes OR larger table into smaller and links them\\nusing relationships.\\n3.The normal form is used to reduce redundancy from the database table.\\n7. Types of Normal forms\\n1. 1NF\\n1. Every relation cell must have atomic value.\\n2. Relation must not have multi-valued a ttributes.\\nCodeHelp\", metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 21}), Document(page_content='2. 2NF \\n1. Relation must be in 1NF. \\n2.There should not be any partial dependency. \\n1. All non-prime a ttributes must be fully dependent on PK. \\n2. Non prime a ttribute can not depend on the part of the PK. \\n3. 3NF \\n1. Relation must be in 2NF. \\n2. No transitivity dependency exists. \\n1. Non-prime a ttribute should not find a non-prime a ttribute. \\n4. BCNF (Boyce-Codd normal form) \\n1. Relation must be in 3NF. \\n2. FD: A -> B, A must be a super key. \\n1. We must not derive prime a ttribute from any prime or non-prime a ttribute. \\n8. Advantages of Normalisation \\n1. Normalisation helps to minimise data redundancy. \\n2. Greater overall database organisation. \\n3. Data consistency is maintained in DB.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 22}), Document(page_content='LEC-12: Transaction \\n1. Transaction\\n1. A unit of work done against the DB in a logical sequence.\\n2. Sequence is very important in transaction.\\n3. It is a logical unit of work that contains one or more SQL statements. The result of all these statements in a\\ntransaction either gets completed successfully (all the changes made to the database are permanent) or if at anypoint any failure happens it gets rollbacked (all the changes being done are undone.)\\n2. ACID Properties\\n1. To ensure integrity of the data, we require that the DB system maintain the following properties of the transaction.\\n2. Atomicity\\n1. Either all operations of transaction are re flected properly in the DB, or none are.\\n3. Consistency\\n1. Integrity constraints must be maintained before and after transaction.\\n2. DB must be consistent after transaction happens.\\n4. Isolation\\n1. Even though multiple transactions may execute concurrently, the system guarantees that, for every pair oftransactions Ti and Tj, it appears to Ti that either Tj finished execution before Ti started, or Tj started executionafter Ti finished. Thus, each transaction is unaware of other transactions executing concurrently in the system.\\n2. Multiple transactions can happen in the system in isolation, without interfering each other.\\n5. Durability\\n1. After transaction completes successfully, the changes it has made to the database persist, even if there are\\nsystem failures.\\n3. Transaction states\\n1. Active state\\n1.The very first state of the life cycle of the transaction, all the read and write operations are beingperformed. If they execute without any error the T comes to Partially commi tted state. Although if any\\nerror occurs then it leads to a Failed state.\\n2. Partially commi tted state\\n1. After transaction is executed the changes are saved in the bu ﬀer in the main memory. If the changes made\\nare permanent on the DB then the state will transfer to the commi tted state and if there is any failure, the T\\nwill go to Failed state.\\n3. Commi tted state\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 23}), Document(page_content='1. When updates are made permanent on the DB. Then the T is said to be in the commi tted state. Rollback \\ncan’t be done from the commi tted states. New consistent state is achieved at this stage. \\n4. Failed state \\n1. When T is being executed and some failure occurs. Due to this it is impossible to continue the execution of \\nthe T. \\n5. Aborted state \\n1. When T reaches the failed state, all the changes made in the bu ﬀer are reversed. A fter that the T rollback \\ncompletely. T reaches abort state after rollback. DB’s state prior to the T is achieved. \\n6. Terminated state \\n1. A transaction is said to have terminated if has either commi tted or aborted.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 24}), Document(page_content='LEC-13: How to implement Atomicity and Durability in Transactions \\n1. Recovery Mechanism Component of DBMS supports atomicity and durability. \\n2. Shadow-copy scheme \\n1. Based on making copies of DB (aka, shadow copies).\\n2. Assumption only one Transaction (T) is active at a time.\\n3. A pointer called db-pointer is maintained on the disk; which at any instant points to current copy of DB.\\n4. T, that wants to update DB first creates a complete copy of DB.\\n5. All further updates are done on new DB copy leaving the original copy (shadow copy) untouched.\\n6. If at any point the T has to be aborted the system deletes the new copy. And the old copy is not aﬀ ected.\\n7. If T success, it is commi tted as,\\n1. OS makes sure all the pages of the new copy of DB wri tten on the disk. \\n2. DB system updates the db-pointer to point to the new copy of DB.\\n3. New copy is now the current copy of DB.\\n4.The old copy is deleted.\\n5.The T is said to have been COMMITTED at the point where the updated db-pointer is wri tten to disk. \\n8. Atomicity \\n1. If T fails at any time before db-pointer is updated, the old content of DB are not aﬀ ected.\\n2. T abort can be done by just deleting the new copy of DB.\\n3. Hence, either all updates are re flected or none.\\n9. Durability \\n1. Suppose, system fails are any time before the updated db-pointer is wri tten to disk. \\n2. When the system restarts, it will read db-pointer & will thus, see the original content of DB and none of the e ﬀects of T will \\nbe visible. \\n3. T is assumed to be successful only when db-pointer is updated.\\n4. If system fails after db-pointer has been updated. Before that all the pages of the new copy were wri tten to disk. Hence, \\nwhen system restarts, it will read new DB copy. \\n10.The implementation is dependent on write to the db-pointer being atomic. Luckily, disk system provide atomic updates to entire \\nblock or at least a disk sector. So, we make sure db-pointer lies entirely in a single sector. By storing db-pointer at the beginning of a block. \\n11. Ineﬃcient, as entire DB is copied for every Transaction.\\n3. Log-based recovery methods \\n1.The log is a sequence of records. Log of each transaction is maintained in some stable storage so that if any failure occurs, then it can be recovered from there. \\n2. If any operation is performed on the database, then it will be recorded in the log.\\n3. But the process of storing the logs should be done before the actual transaction is applied in the database.\\n4. Stable storage is a classi fication of computer data storage technology that guarantees atomicity for any given write operation \\nand allows so ftware to be wri tten that is robust against some hardware and power failures. \\n5. Deferred DB Modi fications \\n1. Ensuring atomicity by recording all the DB modi fications in the log but deferring the execution of all the write operations \\nuntil the final action of the T has been executed. \\n2. Log information is used to execute deferred writes when T is completed.\\n3. If system crashed before the T completes, or if T is aborted, the information in the logs are ignored.\\n4. If T completes, the records associated to it in the log file are used in executing the deferred writes.\\n5. If failure occur while this updating is taking place, we preform redo. \\n6. Immediate DB Modi fications \\n1. DB modi fications to be output to the DB while the T is still in active state.\\n2. DB modi fications wri tten by active T are called uncommi tted modi fications.\\n3. In the event of crash or T failure, system uses old value field of the log records to restore modi fied values.\\n4. Update takes place only after log records in a stable storage.\\n5. Failure handling\\n1. System failure before T completes, or if T aborted, then old value field is used to undo the T.\\n2. If T completes and system crashes, then new value field is used to redo T having commit logs in the logs.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 25}), Document(page_content=\"LEC-14: Indexing in DBMS \\n1. Indexing is used to optimise the performance of a database by minimising the number of disk accesses required when a query is \\nprocessed. \\n2.The index is a type of data structure. It is used to locate and access the data in a database table quickly. \\n3. Speeds up operation with read operations like SELECT queries, WHERE clause etc. \\n4. Search Key: Contains copy of primary key or candidate key of the table or something else. \\n5. Data Reference: Pointer holding the address of disk block where the value of the corresponding key is stored. \\n6. Indexing is optional, but increases access speed. It is not the primary mean to access the tuple, it is the secondary mean. \\n7. Index file is always sorted. \\n8. Indexing Methods \\n1. Primary Index (Clustering Index) \\n1. A file may have several indices, on di ﬀerent search keys. If the data file containing the records is sequentially ordered, a \\nPrimary index is an index whose search key also de fines the sequential order of the file. \\n2. NOTE: The term primary index is sometimes used to mean an index on a primary key. However, such usage is nonstandard and should be avoided. \\n3. All files are ordered sequentially on some search key. It could be Primary Key or non-primary key. \\n4. Dense And Sparse Indices \\n1. Dense Index \\n1.The dense index contains an index record for every search key value in the data file. \\n2.The index record contains the search-key value and a pointer to the first data record with that search-key value. The rest of the records with the same search-key value would be stored sequentially after the first record. \\n3. It needs more space to store index record itself. The index records have the search key and a pointer to the actual record on the disk. \\n2. Sparse Index \\n1. An index record appears for only some of the search-key values. \\n2. Sparse Index helps you to resolve the issues of dense Indexing in DBMS. In this method of indexing technique, a range of index columns stores the same data block address, and when data needs to be retrieved, the block address will be fetched. \\n5. Primary Indexing can be based on Data file is sorted w.r.t Primary Key a ttribute or non-key a ttributes. \\n6. Based on Key a ttribute \\n1. Data file is sorted w.r.t primary key a ttribute. \\n2. PK will be used as search-key in Index. \\n3. Sparse Index will be formed i.e., no. of entries in the index file = no. of blocks in datafile. \\n7. Based on Non-Key a ttribute \\n1. Data file is sorted w.r.t non-key a ttribute. \\n2. No. Of entries in the index  = unique non-key a ttribute value in the data file. \\n3.This is dense index as, all the unique values have an entry in the index file. \\n4. E.g., Let’s assume that a company recruited many employees in various departments. In this case, clustering indexing in DBMS should be created for all employees who belong to the same dept. \\n8. Multi-level Index \\n1. Index with two or more levels. \\n2. If the single level index become enough large that the binary search it self would take much time, we can break down indexing into multiple levels. \\n2. Secondary Index (Non-Clustering Index) \\n1. Datafile is unsorted. Hence, Primary Indexing is not possible. \\n2. Can be done on key or non-key a ttribute. \\n3. Called secondary indexing because normally one indexing is already applied. \\n4. No. Of entries in the index file = no. of records in the data file. \\n5. It's an example of Dense index. \\nCodeHelp\", metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 26}), Document(page_content='9. Advantages of Indexing \\n1. Faster access and retrieval of data.\\n2. IO is less.\\n10. Limitations of Indexing \\n1. Additional space to store index table\\n2. Indexing Decrease performance in INSERT, DELETE, and UPDATE query.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 27}), Document(page_content='LEC-15: NoSQL \\n1. NoSQL databases (aka \"not only SQL\") are non-tabular databases and store data di ﬀerently than relational tables. NoSQL databases \\ncome in a variety of types based on their data model. The main types are document, key-value, wide-column, and graph. They \\nprovide flexible schemas and scale easily with large amounts of data and high user loads.\\n1.They are schema free.\\n2. Data structures used are not tabular, they are more flexible, has the ability to adjust dynamically.\\n3. Can handle huge amount of data (big data). \\n4. Most of the NoSQL are open sources and has the capability of horizontal scaling.\\n5. It just stores data in some format other than relational. \\n2. History behind NoSQL \\n1. NoSQL databases emerged in the late 2000s as the cost of storage dramatically decreased. Gone were the days of needing to \\ncreate a complex, di ﬃcult-to-manage data model in order to avoid data duplication. Developers (rather than storage) were \\nbecoming the primary cost of so ftware development, so NoSQL databases optimised for developer productivity. \\n2. Data becoming unstructured more, hence structuring (de fining schema in advance) them had becoming costly.\\n3. NoSQL databases allow developers to store huge amounts of unstructured data, giving them a lot of flexibility.\\n4. Recognising the need to rapidly adapt to changing requirements in a so ftware system. Developers needed the ability to iterate \\nquickly and make changes throughout their so ftware stack — all the way down to the database. NoSQL databases gave them \\nthis flexibility. \\n5. Cloud computing also rose in popularity, and developers began using public clouds to host their applications and data. They \\nwanted the ability to distribute data across multiple servers and regions to make their applications resilient, to scale out instead of scale up, and to intelligently geo-place their data. Some NoSQL databases like MongoDB provide these capabilities. \\n3. NoSQL Databases Advantages \\nA. Flexible Schema \\n1. RDBMS has pre-de fined schema, which become an issue when we do not have all the data with us or we need to change \\nthe schema. It\\'s a huge task to change schema on the go. \\nB. Horizontal Scaling \\n1. Horizontal scaling, also known as scale-out, refers to bringing on additional nodes to share the load. This is di ﬃcult with \\nrelational databases due to the di ﬃculty in spreading out related data across nodes. With non-relational databases, this is \\nmade simpler since collections are self-contained and not coupled relationally. This allows them to be distributed across \\nnodes more simply, as queries do not have to “join” them together across nodes. \\n2. Scaling horizontally is achieved through Sharding OR Replica-sets.\\nC. High Availability \\n1. NoSQL databases are highly available due to its auto replication feature i.e. whenever any kind of failure happens data replicates itself to the preceding consistent state. \\n2. If a server fails, we can access that data from another server as well, as in NoSQL database data is stored at multiple servers. \\nD. Easy insert and read operations. \\n1. Queries in NoSQL databases can be faster than SQL databases. Why? Data in SQL databases is typically normalised, so queries for a single object or entity require you to join data from multiple tables. As your tables grow in size, the joins can become expensive. However, data in NoSQL databases is typically stored in a way that is optimised for queries. The rule of \\nthumb when you use MongoDB is data that is accessed together should be stored together. Queries typically do not require joins, so the queries are very fast. \\n2. But diﬃcult delete or update operations.\\nE. Caching mechanism. \\nF. NoSQL use case is more for Cloud applications.\\n4. When to use NoSQL? \\n1. Fast-paced Agile development\\n2. Storage of structured and semi-structured data\\n3. Huge volumes of data\\n4. Requirements for scale-out architecture\\n5. Modern application paradigms like micro-services and real-time streaming.', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 28}), Document(page_content=\"2. Storage of structured and semi-structured data\\n3. Huge volumes of data\\n4. Requirements for scale-out architecture\\n5. Modern application paradigms like micro-services and real-time streaming.\\n5. NoSQL DB Misconceptions \\n1. Relationship data is best suited for relational databases.\\n1. A common misconception is that NoSQL databases or non-relational databases don’t store relationship data well. NoSQL databases can store relationship data — they just store it di ﬀerently than relational databases do. In fact, when compared \\nwith relational databases, many find modelling relationship data in NoSQL databases to be easier than in relational \\ndatabases, because related data doesn’t have to be split between tables. NoSQL data models allow related data to be nested within a single data structure. \\n2. NoSQL databases don't support ACID transactions.\\nCodeHelp\", metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 28}), Document(page_content='1. Another common misconception is that NoSQL databases don\\'t support ACID transactions. Some NoSQL databases like \\nMongoDB do, in fact, support ACID transactions. \\n6. Types of NoSQL Data Models \\n1. Key-Value Stores \\n1.The simplest type of NoSQL database is a key-value store. Every data element in the database is stored as a key value pair consisting of an a ttribute name (or \"key\") and a value. In a sense, a key-value store is like a relational database with only \\ntwo columns: the key or a ttribute name (such as \"state\") and the value (such as \"Alaska\"). \\n2. Use cases include shopping carts, user preferences, and user pro files. \\n3. e.g., Oracle NoSQL, Amazon DynamoDB, MongoDB also supports Key-Value store, Redis. \\n4. A key-value database associates a value (which can be anything from a number or simple string to a complex object) with a key, which is used to keep track of the object. In its simplest form, a key-value store is like a dictionary/array/map object as it exists in most programming paradigms, but which is stored in a persistent way and managed by a Database Management System (DBMS). \\n5. Key-value databases use compact, e ﬃcient index structures to be able to quickly and reliably locate a value by its key, \\nmaking them ideal for systems that need to be able to find and retrieve data in constant time. \\n6.There are several use-cases where choosing a key value store approach is an optimal solution: \\na) Real time random data access, e.g., user session a ttributes in an online application such as gaming or finance. \\nb) Caching mechanism for frequently accessed data or confi guration based on keys. \\nc) Application is designed on simple key-based queries. \\n2. Column-Oriented / Columnar / C-Store / Wide-Column \\n1.The data is stored such that each row of a column will be next to other rows from that same column. \\n2. While a relational database stores data in rows and reads data row by row, a column store is organised as a set of columns. This means that when you want to run analytics on a small number of columns, you can read those columns directly without consuming memory with the unwanted data. Columns are o ften of the same type and bene fit from more e ﬃcient \\ncompression, making reads even faster. Columnar databases can quickly aggregate the value of a given column (adding up the total sales for the year, for example). Use cases include analytics. \\n3. e.g., Cassandra, RedShi ft, Snow flake. \\n3. Document Based Stores \\n1.This DB store data in documents similar to JSON (JavaScript Object Notation) objects. Each document contains pairs of fields and values. The values can typically be a variety of types including things like strings, numbers, booleans, arrays, or \\nobjects. \\n2. Use cases include e-commerce platforms, trading platforms, and mobile app development across industries. \\n3. Supports ACID properties hence, suitable for Transactions. \\n4. e.g., MongoDB, CouchDB. \\n4. Graph Based Stores \\n1. A graph database focuses on the relationship between data elements. Each element is stored as a node (such as a person in a social media graph). The connections between elements are called links or relationships. In a graph database, \\nconnections are first-class elements of the database, stored directly. In relational databases, links are implied, using data to \\nexpress the relationships. \\n2. A graph database is optimised to capture and search the connections between data elements, overcoming the overhead associated with JOINing multiple tables in SQL. \\n3. Very few real-world business systems can survive solely on graph queries. As a result graph databases are usually run alongside other more traditional databases. \\n4. Use cases include fraud detection, social networks, and knowledge graphs. \\n7. NoSQL Databases Dis-advantages \\n1. Data Redundancy', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 29}), Document(page_content='4. Use cases include fraud detection, social networks, and knowledge graphs. \\n7. NoSQL Databases Dis-advantages \\n1. Data Redundancy \\n1. Since data models in NoSQL databases are typically optimised for queries and not for reducing data duplication, NoSQL databases can be larger than SQL databases. Storage is currently so cheap that most consider this a minor drawback, and some NoSQL databases also support compression to reduce the storage footprint. \\n2. Update & Delete operations are costly. \\n3. All type of NoSQL Data model doesn’t ful fil all of your application needs \\n1. Depending on the NoSQL database type you select, you may not be able to achieve all of your use cases in a single database. For example, graph databases are excellent for analysing relationships in your data but may not provide what you need for everyday retrieval of the data such as range queries. When selecting a NoSQL database, consider what your use cases will be and if a general purpose database like MongoDB would be a be tter option. \\n4. Doesn’t support ACID properties in general. \\n5. Doesn’t support data entry with consistency constraints. \\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 29}), Document(page_content='8. SQL vs NoSQL \\n \\nSQL Databases NoSQL Databases\\nData Storage Model Tables with ﬁxed rows and \\ncolumnsDocument: JSON documents, \\nKey-value: key-value pairs, Wide-column: tables with rows and dynamic columns, Graph: nodes and edges\\nDevelopment History Developed in the 1970s with a \\nfocus on reducing data duplicationDeveloped in the late 2000s with \\na focus on scaling and allowing for rapid application change driven by agile and DevOps practices.\\nExamples Oracle, MySQL, Microsoft SQL \\nServer, and PostgreSQLDocument: MongoDB and \\nCouchDB, Key-value: Redis and DynamoDB, Wide-column: Cassandra and HBase, Graph: Neo4j and Amazon Neptune\\nPrimary Purpose General Purpose Document: general purpose, Key-\\nvalue: large amounts of data with simple lookup queries, Wide-column: large amounts of data with predictable query patterns, Graph: analyzing and traversing relationships between connected data\\nSchemas Fixed Flexible\\nScaling Vertical (Scale-up) Horizontal (scale-out across \\ncommodity servers)\\nACID Properties Supported Not Supported, except in DB like \\nMongoDB etc.\\nJOINS Typically Required Typically not required\\nData to object mapping Required object-relational \\nmappingMany do not require ORMs. \\nMongoDB documents map directly to data structures in most popular programming languages.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 30}), Document(page_content='LEC-16: Types of Databases \\n1. Relational Databases \\n1. Based on Relational Model.\\n2. Relational databases are quite popular, even though it was a system designed in the 1970s. Also known as relational database \\nmanagement systems (RDBMS), relational databases commonly use Structured Query Language (SQL) for operations such as \\ncreating, reading, updating, and deleting data. Relational databases store information in discrete tables, which can be JOINed \\ntogether by fields known as foreign keys. For example, you might have a User table which contains information about all your \\nusers, and join it to a Purchases table, which contains information about all the purchases they’ve made. MySQL, Microso ft SQL \\nServer, and Oracle are types of relational databases. \\n3. they are ubiquitous, having acquired a steady user base since the 1970s\\n4. they are highly optimised for working with structured data. \\n5. they provide a stronger guarantee of data normalisation\\n6. they use a well-known querying language through SQL \\n7. Scalability issues (Horizontal Scaling). \\n8. Data become huge, system become more complex.\\n2. Object Oriented Databases \\n1.The object-oriented data model, is based on the object-oriented-programming paradigm, which is now in wide use. \\nInheritance, object-identity, and encapsulation (information hiding), with methods to provide an interface to objects, are \\namong the key concepts of object-oriented programming that have found applications in data modelling. The object-oriented \\ndata model also supports a rich type system, including structured and collection types. While inheritance and, to some extent, \\ncomplex types are also present in the E-R model, encapsulation and object-identity distinguish the object-oriented data model from the E-R model. \\n2. Sometimes the database can be very complex, having multiple relations. So, maintaining a relationship between them can be tedious at times. \\n1. In Object-oriented databases data is treated as an object.\\n2. All bits of information come in one instantly available object package instead of multiple tables.\\n3. Advantages \\n1. Data storage and retrieval is easy and quick.\\n2. Can handle complex data relations and more variety of data types that standard relational databases.\\n3. Relatively friendly to model the advance real world problems\\n4. Works with functionality of OOPs and Object Oriented languages.\\n4. Disadvantages \\n1. High complexity causes performance issues like read, write, update and delete operations are slowed down.\\n2. Not much of a community support as isn’t widely adopted as relational databases.\\n3. Does not support views like relational databases.\\n5. e.g., ObjectDB, GemStone etc. \\n3. NoSQL Databases \\n1. NoSQL databases (aka \"not only SQL\") are non-tabular databases and store data di ﬀerently than relational tables. NoSQL \\ndatabases come in a variety of types based on their data model. The main types are document, key-value, wide-column, and \\ngraph. They provide flexible schemas and scale easily with large amounts of data and high user loads. \\n2.They are schema free.\\n3. Data structures used are not tabular, they are more flexible, has the ability to adjust dynamically.\\n4. Can handle huge amount of data (big data).\\n5. Most of the NoSQL are open sources and has the capability of horizontal scaling.\\n6. It just stores data in some format other than relational.\\n7. Refer LEC-15 notes…\\n4. Hierarchical Databases \\n1. As the name suggests, the hierarchical database model is most appropriate for use cases in which the main focus of information gathering is based on a concrete hierarchy, such as several individual employees reporting to a single department at a \\ncompany. \\n2.The schema for hierarchical databases is de fined by its tree-like organisation, in which there is typically a root  “parent” \\ndirectory of data stored as records that links to various other subdirectory branches, and each subdirectory branch, or child record, may link to various other subdirectory branches.', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 31}), Document(page_content='directory of data stored as records that links to various other subdirectory branches, and each subdirectory branch, or child record, may link to various other subdirectory branches. \\n3.The hierarchical database structure dictates that, while a parent record can have several child records, each child record can only have one parent record. Data within records is stored in the form of fields, and each field can only contain one value. Retrieving \\nhierarchical data from a hierarchical database architecture requires traversing the entire tree, starting at the root node. \\n4. Since the disk storage system is also inherently a hierarchical structure, these models can also be used as physical models.\\n5.The key advantage of a hierarchical database is its ease of use. The one-to-many organisation of data makes traversing the \\ndatabase simple and fast, which is ideal for use cases such as website drop-down menus or computer folders in systems like \\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 31}), Document(page_content='Microso ft Windows OS. Due to the separation of the tables from physical storage structures, information can easily be added or \\ndeleted without aﬀ ecting the entirety of the database. And most major programming languages o ﬀer functionality for reading \\ntree structure databases. \\n6.The major disadvantage of hierarchical databases is their inflexible nature. The one-to-many structure is not ideal for complex \\nstructures as it cannot describe relationships in which each child node has multiple parents nodes. Also the tree-like \\norganisation of data requires top-to-bo ttom sequential searching, which is time consuming, and requires repetitive storage of \\ndata in multiple di ﬀerent entities, which can be redundant. \\n7. e.g., IBM IMS. \\n5. Network Databases \\n1. Extension of Hierarchical databases \\n2.The child records are given the freedom to associate with multiple parent records. \\n3. Organised in a Graph structure. \\n4. Can handle complex relations. \\n5. Maintenance is tedious. \\n6. M:N links may cause slow retrieval. \\n7. Not much web community support. \\n8. e.g., Integrated Data Store (IDS), IDMS (Integrated Database Management System), Raima Database Manager, TurboIMAGE etc.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 32}), Document(page_content='LEC-17: Clustering in DBMS \\n1. Database Clustering (making Replica-sets) is the process of combining more than one servers or instances connecting a single database. \\nSometimes one server may not be adequate to manage the amount of data or the number of requests, that is when a Data Cluster is needed. \\nDatabase clustering, SQL server clustering, and SQL clustering are closely associated with SQL is the language used to manage the database information.  \\n2. Replicate the same dataset on different servers.  \\n3. Advantages\\n1. Data Redundancy: Clustering of databases helps with data redundancy, as we store the same data at multiple servers. Don’t confuse this \\ndata redundancy as repetition of the same data that might lead to some anomalies. The redundancy that clustering offers is required and is quite certain due to the synchronisation. In case any of the servers had to face a failure due to any possible reason, the data is available at other servers to access.\\n2. Load balancing: or scalability doesn’t come by default with the database. It has to be brought by clustering regularly. It also depends on the setup. Basically, what load balancing does is allocating the workload among the different servers that are part of the cluster. This indicates that more users can be supported and if for some reasons if a huge spike in the traf ﬁc appears, there is a higher assurance that it will be able to \\nsupport the new traf ﬁc. One machine is not going to get all of the hits. This can provide scaling seamlessly as required. This links directly to \\nhigh availability. Without load balancing, a particular machine could get overworked and traf ﬁc would slow down, leading to decrement of \\nthe traf ﬁc to zero.  \\n3. High availability: When you can access a database, it implies that it is available. High availability refers the amount of time a database is \\nconsidered available. The amount of availability you need greatly depends on the number of transactions you are running on your database and how often you are running any kind of analytics on your data. With database clustering, we can reach extremely high levels of availability due to load balancing and have extra machines. In case a server got shut down the database will, however, be available.  \\n4. How does Clustering Work?\\n1. In cluster architecture, all requests are split with many computers so that an individual user request is executed and produced by a number of computer systems. The clustering is serviceable deﬁnitely by the ability of load balancing and high-availability. If one node collapses, the request is handled by another node. Consequently, there are few or no possibilities of absolute system failures.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 33}), Document(page_content='LEC-18: Partitioning & Sharding in DBMS (DB Optimisation) \\n1. A big problem can be solved easily when it is chopped into several smaller sub-problems. That is what the partitioning technique does. It divides a \\nbig database containing data metrics and indexes into smaller and handy slices of data called partitions. The partitioned tables are directly used by SQL queries without any alteration. Once the database is partitioned, the data deﬁnition language can easily work on the smaller partitioned slices, instead of handling the giant database altogether. This is how partitioning cuts down the problems in managing large database tables.  \\n2. Partitioning is the technique used to divide stored database objects into separate servers. Due to this, there is an increase in performance, controllability of the data. We can manage huge chunks of data optimally. When we horizontally scale our machines/servers, we know that it gives us a challenging time dealing with relational databases as it’s quite tough to maintain the relations. But if we apply partitioning to the database that is already scaled out i.e. equipped with multiple servers, we can partition our database among those servers and handle the big data easily.  \\n3. Vertical Partitioning\\n1. Slicing relation vertically / column-wise.  \\n2. Need to access different servers to get complete tuples.  \\n4. Horizontal Partitioning\\n1. Slicing relation horizontally / row-wise.  \\n2. Independent chunks of data tuples are stored in different servers.  \\n5. When Partitioning is Applied?\\n1. Dataset become much huge that managing and dealing with it become a tedious task.  \\n2. The number of requests are enough larger that the single DB server access is taking huge time and hence the system’s response time become high.  \\n6. Advantages of Partitioning\\n1. Parallelism \\n2. Availability \\n3. Performance \\n4. Manageability \\n5. Reduce Cost, as scaling-up or vertical scaling might be costly.  \\n7. Distributed Database\\n1. A single logical database that is, spread across multiple locations (servers) and logically interconnected by network.  \\n2. This is the product of applying DB optimisation techniques like Clustering, Partitioning and Sharding.  \\n3. Why this is needed? READ Point 5.  \\n8. Sharding\\n1. Technique to implement Horizontal Partitioning.  \\n2. The fundamental idea of Sharding is the idea that instead of having all the data sit on one DB instance, we split it up and introduce a \\nRouting layer so that we can forward the request to the right instances that actually contain the data.  \\n3. Pros\\n1. Scalability \\n2. Availability \\n4. Cons\\n1.  Complexity, making partition mapping, Routing layer to be implemented in the system, Non-uniformity that creates the necessity of Re-Sharding \\n2. Not well suited for Analytical type of queries, as the data is spread across different DB instances. (Scatter-Gather problem)\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 34}), Document(page_content='- LakshayDatabase Scaling Patterns\\nStep by Step Scaling\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 35}), Document(page_content='What will you learn?\\n•Step by Step manner, when to choose which Scaling option.\\n•Which Scaling option is feasible practically at the moment.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 36}), Document(page_content='A Case Study\\nCab Booking APP\\n•Tiny startup.\\n•~10 customers onboard.\\n•A single small machine DB stores all customers, trips, locations, booking \\ndata, and customer trip history.\\n•~1 trip booking in 5 mins.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 37}), Document(page_content='Your App becoming famous, but…\\nThe PROBLEM begins\\n•Requests scales upto 30 bookings per minute.\\n•Your tiny DB system has started performing poorly.\\n•API latency has increased a lot.\\n•Transactions facing Deadlock, Starvation, and frequent failure.\\n•Sluggish App experience.\\n•Customer dis-satisfaction.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 38}), Document(page_content='Is there any solution?\\n•We have to apply some kind of performance optimisation measures.\\n•We might have to scale our system going forward.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 39}), Document(page_content='Pattern 1\\nQuery Optimisation & Connection Pool Implementation\\n•Cache frequently used non-dynamic data like, booking history, payment \\nhistory, user proﬁles etc.\\n•Introduce Database Redundancy. (Or may be use NoSQL)\\n•Use connection pool libraries to Cache DB connections.\\n•Multiple application threads can use same DB connection.\\n•Good optimisations as of now.\\n•Scaled the business to one more city, and now getting ~100 booking per minute.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 40}), Document(page_content='Pattern 2\\nVertical Scaling or Scale-up\\n•Upgrading our initial tiny machine.\\n•RAM by 2x and SSD by 3x etc.\\n•Scale up is pocket friendly till a point only.\\n•More you scale up, cost increases exponentially.\\n•Good Optimisation as of now.\\n•Business is growing, you decided to scale it to 3 more cities and now getting \\n300 booking per minute.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 41}), Document(page_content='Pattern 3\\nCommand Query Responsibility Segregation (CQRS)\\n•The scaled up big machine is not able to handle all read/write requests.\\n•Separate read/write operations physical machine wise.\\n•2 more machines as replica to the primary machine.\\n•All read queries to replicas.\\n•All write queries to primary.\\n•Business is growing, you decided to scale it to 2 more cities.\\n•Primary is not able to handle all write requests.\\n•Lag between primary and replica is impacting user experience.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 42}), Document(page_content='Pattern 4\\nMulti Primary Replication\\n•Why not distribute write request to replica also?\\n•All machines can work as primary & replica.\\n•Multi primary conﬁguration is a logical circular ring.\\n•Write data to any node.\\n•Read data from any node that replies to the broadcast ﬁrst.\\n•You scale to 5 more cities & your system is in pain again. (~50 req/s)\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 43}), Document(page_content='Pattern 5\\nPartitioning of Data by Functionality\\n•What about separating the location tables in separate DB schema?\\n•What about putting that DB in separate machines with primary-replica or \\nmulti-primary conﬁguration?\\n•Diﬀerent DB can host data categorised by diﬀerent functionality.\\n•Backend or application layer has to take responsibility to join the results.\\n•Planning to expand your business to other country.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 44}), Document(page_content='Pattern 6\\nHorizontal Scaling or Scale-out\\n•Sharding - multiple shards.\\n•Allocate 50 machines - all having same DB schema - each machine just hold \\na part of data.\\n•Locality of data should be there.\\n•Each machine can have their own replicas, may be used in failure recovery.\\n•Sharding is generally hard to apply. But “No Pain, No Gain”\\n•Scaling the business across continents.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 45}), Document(page_content='Pattern 7\\nData Centre Wise Partition\\n•Requests travelling across continents are having high latency.\\n•What about distributing traﬃc across data centres?\\n•Data centres across continents.\\n•Enable cross data centre replication which helps disaster recovery.\\n•This always maintain Availability of your system.\\n•Now, Plan for an IPO :p\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 46}), Document(page_content='LEC-20: CAP Theorem \\n1. Basic and one of the most important concept in Distributed Databases.  \\n2. Useful to know this to design ef ﬁcient distributed system for your given business logic. \\n3. Let’s ﬁrst breakdown CAP \\n1. Consistency: In a consistent system, all nodes see the same data simultaneously. If we perform a read operation on a consistent system, it \\nshould return the value of the most recent write operation. The read should cause all nodes to return the same data. All users see the same data at the same time, regardless of the node they connect to. When data is written to a single node, it is then replicated across the other nodes in the system.  \\n2. Availability: When availability is present in a distributed system, it means that the system remains operational all of the time. Every request will get a response regardless of the individual state of the nodes. This means that the system will operate even if there are multiple nodes down. Unlike a consistent system, there’s no guarantee that the response will be the most recent write operation.  \\n3. Partition Tolerance: When a distributed system encounters a partition, it means that there’s a break in communication between nodes. If a \\nsystem is partition-tolerant, the system does not fail, regardless of whether messages are dropped or delayed between nodes within the system. To have partition tolerance, the system must replicate records across combinations of nodes and networks. \\n4. What does the CAP Theorem says,  \\n1. The CAP theorem states that a distributed system can only provide two of three properties simultaneously: consistency, availability, and \\npartition tolerance. The theorem formalises the tradeoff between consistency and availability when there’s a partition.  \\n5. CAP Theorem NoSQL Databases: NoSQL databases are great for distributed networks. They allow for horizontal scaling, and they can quickly scale across multiple nodes. When deciding which NoSQL database to use, it’s important to keep the CAP theorem in mind.  \\n1. CA Databases: CA databases enable consistency and availability across all nodes. Unfortunately, CA databases can’t deliver fault tolerance. In \\nany distributed system, partitions are bound to happen, which means this type of database isn’t a very practical choice. That being said, you still can ﬁnd a CA database if you need one. Some relational databases, such as MySQL or PostgreSQL, allow for consistency and availability. You can \\ndeploy them to nodes using replication.  \\n2. CP Databases: CP databases enable consistency and partition tolerance, but not availability. When a partition occurs, the system has to turn off inconsistent nodes until the partition can be ﬁxed. MongoDB is an example of a CP database. It’s a NoSQL database management system \\n(DBMS) that uses documents for data storage. It’s considered schema-less, which means that it doesn’t require a deﬁned database schema. It’s commonly used in big data and applications running in different locations. The CP system is structured so that there’s only one primary \\nnode that receives all of the write requests in a given replica set. Secondary nodes replicate the data in the primary nodes, so if the primary node fails, a secondary node can stand-in. In banking system Availability is not as important as consistency, so we can opt it (MongoDB).', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 47}), Document(page_content='3. AP Databases: AP databases enable availability and partition tolerance, but not consistency. In the event of a partition, all nodes are available, but they’re not all updated. For example, if a user tries to access data from a bad node, they won’t receive the most up-to-date version of the data. When the partition is eventually resolved, most AP databases will sync the nodes to ensure consistency across them. Apache Cassandra is an example of an AP database. It’s a NoSQL database with no primary node, meaning that all of the nodes remain available. Cassandra allows for eventual consistency because users can re-sync their data right after a partition is resolved. For apps like Facebook, we value availability more than consistency, we’d opt for AP Databases like Cassandra or Amazon DynamoDB.  \\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 47}), Document(page_content='LEC-21: The Master-Slave Database Concept \\n1. Master-Slave is a general way to optimise IO in a system where number of requests goes way high that a single DB server is not able to handle it \\nefﬁciently.  \\n2. Its a Pattern 3 in LEC-19 (Database Scaling Pattern). (Command Query Responsibility Segregation) \\n3. The true or latest data is kept in the Master DB thus write operations are directed there. Reading ops are done only from slaves. This architecture \\nserves the purpose of safeguarding site r eliability, availability, reduce latency etc . If a site receives a lot of trafﬁc and the only available \\ndatabase is one master, it will be overloaded with reading and writing requests. Making the entire system slow for everyone on the site. \\n4. DB replication will take care of distributing data from Master machine to Slaves machines. This can be synchronous or asynchronous depending \\nupon the system’s need.\\nCodeHelp', metadata={'source': 'pdfs\\\\DBMS_Full_Notes.pdf', 'page': 48}), Document(page_content='3 grad.illinois.edu/CareerDevelopment Rachel Green  \\n2 1 0  W .  G R E E N  S T . ,  C H A M P A I G N ,  I L  \\n( 2 1 7 )  5 5 5 - 1 2 3 4  •  R S T U D E N T @ I L L I N O I S . E D U  \\nEDUCATION  \\nPhD in English May 20xx \\nUniversity of Illinois at Urbana-Champaign \\nDissertation title:  “Down on the Farm: World War One and the Emergence of Literary  \\nModernism in the American South”  \\nCommittee : Margaret Black, Naomi Blue, John Jay, Robert Roberts (Chair) \\nMA in English  20xx \\nUniversity of Illinois at Urbana-Champaign \\nBA in English and Communications, summa cum laude  20xx \\nButler University, Indianapolis, IN  \\nTEACHING  & A DVISING   \\nComposition Instructor  20xx-present \\nResearch Writing Program, University of Illinois \\n\\uf0b7Facilitator for seven sections of English composition.\\n\\uf0b7Planned and taught a writing-intensive course based upon current events.\\n\\uf0b7Used instructional technology to enhance pedagogical technique.\\n\\uf0b7Taught in part with an innovative, interdisciplinary team-teaching program design.\\nLiterature Instructor 20xx-present \\nDepartment of English, University of Illinois \\n\\uf0b7Instructor of record for two sections of literature, including Major American Authors  and\\nIntroduction to Poetry per semester.\\n\\uf0b7Integrated multimedia and humanities approaches to teaching literature using film and instructional\\ntechnology.\\nCoordinating Group Leader 20xx-20xx \\nResearch Writing Program, University of Illinois \\n\\uf0b7Planned and led required training session for teaching assistants and new composition teachers.\\n\\uf0b7Helped to mentor new hires to the English Department staff to ensure their engagement and\\nprofessional development.\\n\\uf0b7Provided job shadowing and training opportunities to assist new hires in adjusting to the pace of\\nwork and the tone and style of the University.\\nDiscussion Leader  20xx \\nCarolina Summer Reading Program, University of Illinois  \\n\\uf0b7Led group discussion for first-year students on academic topics.\\nTeaching Assistant 20xx-20xx \\nDepartment of English, University of Illinois at Urbana-Champaign \\n\\uf0b7Taught a section on film criticism, including film history, theory and technical vocabulary.\\n\\uf0b7Planned lessons and assignments, led discussion sections, graded papers and exams.\\n\\uf0b7Organized and led group discussions on social and academic issues.CV SAMPLE', metadata={'source': 'pdfs\\\\rachelgreecv.pdf', 'page': 0}), Document(page_content='4 grad.illinois.edu/CareerDevelopment RESEARCH  EXPERIENCE   \\nDoctoral Researcher 20xx-20xx \\nDepartment of English, University of Illinois at Urbana-Champaign \\n\\uf0b7Conducted primary source research at numerous archives, examining publication history through\\nmultiple sources.\\n\\uf0b7Examined the literature of William Faulkner, Thomas Wolfe, and Tennessee Williams, exploring\\ntheir publication records, construction of literary identity, and relationship with modernism.\\nResearch Assistant 20xx \\nDepartment of English, University of Illinois at Urbana-Champaign \\n\\uf0b7Assistant to Professor Robert Warren, conducting primary and secondary source research.\\n\\uf0b7Organized for the “New Directions in the Study of Southern Literature: An Interdisciplinary\\nConference.”\\nPUBLICATIONS   \\nAssociate Editor of North Carolina Slave Narratives. John Jacob Franz, general editor. Forthcoming \\nfrom University of Illinois Press, 20xx. \\nJohnson, JM, Lolie, T., and Green, R.  “Lost on the Farm: Popular Beliefs” Somebody Journal, Special \\nIssue, Reflections on the Americas. Vol. 6. Accepted and forthcoming. \\nGreen, R. “Fugitives/Agrarians” in A Companion to Twentieth -Century American Poetry. Rutgers \\nPress., 20xx. \\nDavis, D.A. and Green, R.  “Will N. Harben,” “Etheridge Knight,” and “James Wilcox” in Southern \\nWriters: A Biographical Dictionary. Louisiana State University Press, 20xx. \\nCONFERENCE  PRESENTATIONS   \\n“Artistic Colloquialism,” Illinois Graduate College Seminar, speaker and organizer. Urbana, IL, 20xx.  \\n“Transitional Bible Belt,” US Divergence Symposium, Duke University, NC, February 20xx.  \\n“The Ministry of Rev. Thomas H. Jones,” South Atlantic Modern Language Association. Atlanta, GA, \\nMay 20xx. \\n“Shackles and Stripes: The Cinematic Representation of the Southern Chain Gain.” American Literature \\nAssociation. Cambridge, Massachusetts, November 20xx. \\n“Body Place of Sprits in the South,” Queen Mary College, University of London, April 6 -8, 20xx. \\nHONORS  AND  AWARDS  \\nJacob K. Javitz Fellowship, U.S. Department of Education 20xx-present \\nGraduate College Dissertation Completion Award, University of Illinois 20xx \\nCampus Teaching Award based on student evaluations, University of Illinois 20xx-20xx \\nDoctoral Fellowship, Illinois Program for Research in the Humanities,  20xx-20xx \\nUniversity of Illinois \\nSummer Research Grant, Center for Summer Studies, City, ST  20xx \\nGraduate College Conference Travel Grant, University of Illinois 20xx & 20xx \\nMost Outstanding Butler Woman, Butler University, Indianapolis, IN 20xx \\nAcademic Scholarship, Butler University, Indianapolis, IN 20xx-20xx \\nRachel Green, page 2 of 3', metadata={'source': 'pdfs\\\\rachelgreecv.pdf', 'page': 1}), Document(page_content='5 grad.illinois.edu/CareerDevelopment PROFESSIONAL  SERVICE  \\nManaging Editor 20xx-present \\nSouthern Literary Journal  \\n\\uf0b7Process manuscripts submitted for publication\\n\\uf0b7Oversee production and publication procedures.\\n\\uf0b7Maintain editorial correspondence with prospective contributors.\\n\\uf0b7Conduct business transactions including publicity, subscriptions and advertising.\\nPoetry Staff 20xx-present \\nUniversity Quarterly \\n\\uf0b7Review and solicit poems for possible publication.\\nEditorial Assistant 20xx-20xx \\nSouthern Literary Journal \\n\\uf0b7Designed and maintained journal’s internet presence.\\n\\uf0b7Edited copy for publication on a monthly basis.\\nUNIVERSITY  SERVICE  \\nGraduate Mentor 20xx-20xx \\nThe Career Center, University of Illinois \\n\\uf0b7Counsel minority undergraduates on graduate programs, application procedures and funding.\\nCareer Advisory Committee 20xx-20xx \\nGraduate College, University of Illinois \\n\\uf0b7Served on university committee to evaluate and propose career services for graduate students.\\n\\uf0b7Collaborated with faculty and students to prepare final report for submission to the Graduate\\nCollege Dean.\\nUniversity Library Advisory Committee 20xx-20xx \\nUndergraduate Library, University of Illinois \\n\\uf0b7Advised University Librarian on needed services and improvements.\\nPROFESSIONAL  MEMBERSHIPS  \\n\\uf0b7Modern Language Association (MLA)\\n\\uf0b7American Literature Association (ALA)\\n\\uf0b7American Studies Association (ASA)\\n\\uf0b7South Atlantic Modern Language Association\\n(samla)\\uf0b7Society for the Study of Southern Literature\\n\\uf0b7Robert Penn Warren Circle\\n\\uf0b7Southern Research Circle\\n\\uf0b7Fellowship of Southern Writers\\nREFERENCES  \\nJohn Jay , Assoc. Professor of English \\nUniversity of Illinois at Urbana-Champaign \\n(217) 333-1112, jjay@illinois.eduJacob S. Snyder , Assoc. Professor of English \\nUniversity of Illinois at Urbana-Champaign \\n(217) 333-4700, jssnyd@illinois.edu\\nRobert Roberts , Professor of English \\nUniversity of Illinois at Urbana-Champaign \\n(217) 333-0203, rrobe3@illinois.eduSally Briscoe, Assoc. Professor of English \\nButler University, Indianapolis, IN \\n(317) 492-8763, briscoe@butler.edu\\nRachel Green, page 3 of 3', metadata={'source': 'pdfs\\\\rachelgreecv.pdf', 'page': 2}), Document(page_content='YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object\\ndetectors\\nChien-Yao Wang1, Alexey Bochkovskiy, and Hong-Yuan Mark Liao1\\n1Institute of Information Science, Academia Sinica, Taiwan\\nkinyiu@iis.sinica.edu.tw, alexeyab84@gmail.com, and liao@iis.sinica.edu.tw\\nAbstract\\nYOLOv7 surpasses all known object detectors in both\\nspeed and accuracy in the range from 5 FPS to 160 FPS\\nand has the highest accuracy 56.8% AP among all known\\nreal-time object detectors with 30 FPS or higher on GPU\\nV100. YOLOv7-E6 object detector (56 FPS V100, 55.9%\\nAP) outperforms both transformer-based detector SWIN-\\nL Cascade-Mask R-CNN (9.2 FPS A100, 53.9% AP) by\\n509% in speed and 2% in accuracy, and convolutional-\\nbased detector ConvNeXt-XL Cascade-Mask R-CNN (8.6\\nFPS A100, 55.2% AP) by 551% in speed and 0.7% AP\\nin accuracy, as well as YOLOv7 outperforms: YOLOR,\\nYOLOX, Scaled-YOLOv4, YOLOv5, DETR, Deformable\\nDETR, DINO-5scale-R50, ViT-Adapter-B and many other\\nobject detectors in speed and accuracy. Moreover, we train\\nYOLOv7 only on MS COCO dataset from scratch without\\nusing any other datasets or pre-trained weights. Source\\ncode is released in https://github.com/WongKinYiu/yolov7.\\n1. Introduction\\nReal-time object detection is a very important topic in\\ncomputer vision, as it is often a necessary component in\\ncomputer vision systems. For example, multi-object track-\\ning [94, 93], autonomous driving [40, 18], robotics [35, 58],\\nmedical image analysis [34, 46], etc. The computing de-\\nvices that execute real-time object detection is usually some\\nmobile CPU or GPU, as well as various neural processing\\nunits (NPU) developed by major manufacturers. For exam-\\nple, the Apple neural engine (Apple), the neural compute\\nstick (Intel), Jetson AI edge devices (Nvidia), the edge TPU\\n(Google), the neural processing engine (Qualcomm), the AI\\nprocessing unit (MediaTek), and the AI SoCs (Kneron), are\\nall NPUs. Some of the above mentioned edge devices focus\\non speeding up different operations such as vanilla convolu-\\ntion, depth-wise convolution, or MLP operations. In this pa-\\nper, the real-time object detector we proposed mainly hopes\\nthat it can support both mobile GPU and GPU devices from\\nthe edge to the cloud.\\nIn recent years, the real-time object detector is still de-\\nveloped for different edge device. For example, the devel-\\nFigure 1: Comparison with other real-time object detectors, our\\nproposed methods achieve state-of-the-arts performance.\\nopment of MCUNet [49, 48] and NanoDet [54] focused on\\nproducing low-power single-chip and improving the infer-\\nence speed on edge CPU. As for methods such as YOLOX\\n[21] and YOLOR [81], they focus on improving the infer-\\nence speed of various GPUs. More recently, the develop-\\nment of real-time object detector has focused on the de-\\nsign of efﬁcient architecture. As for real-time object de-\\ntectors that can be used on CPU [54, 88, 84, 83], their de-\\nsign is mostly based on MobileNet [28, 66, 27], ShufﬂeNet\\n[92, 55], or GhostNet [25]. Another mainstream real-time\\nobject detectors are developed for GPU [81, 21, 97], they\\nmostly use ResNet [26], DarkNet [63], or DLA [87], and\\nthen use the CSPNet [80] strategy to optimize the architec-\\nture. The development direction of the proposed methods in\\nthis paper are different from that of the current mainstream\\nreal-time object detectors. In addition to architecture op-\\ntimization, our proposed methods will focus on the opti-\\nmization of the training process. Our focus will be on some\\noptimized modules and optimization methods which may\\nstrengthen the training cost for improving the accuracy of\\nobject detection, but without increasing the inference cost.\\nWe call the proposed modules and optimization methods\\ntrainable bag-of-freebies.\\n1arXiv:2207.02696v1  [cs.CV]  6 Jul 2022', metadata={'source': 'pdfs\\\\yolov7paper.pdf', 'page': 0}), Document(page_content='Recently, model re-parameterization [13, 12, 29] and dy-\\nnamic label assignment [20, 17, 42] have become important\\ntopics in network training and object detection. Mainly af-\\nter the above new concepts are proposed, the training of\\nobject detector evolves many new issues. In this paper, we\\nwill present some of the new issues we have discovered and\\ndevise effective methods to address them. For model re-\\nparameterization, we analyze the model re-parameterization\\nstrategies applicable to layers in different networks with the\\nconcept of gradient propagation path, and propose planned\\nre-parameterized model. In addition, when we discover that\\nwith dynamic label assignment technology, the training of\\nmodel with multiple output layers will generate new issues.\\nThat is: “How to assign dynamic targets for the outputs of\\ndifferent branches?” For this problem, we propose a new\\nlabel assignment method called coarse-to-ﬁne lead guided\\nlabel assignment.\\nThe contributions of this paper are summarized as fol-\\nlows: (1) we design several trainable bag-of-freebies meth-\\nods, so that real-time object detection can greatly improve\\nthe detection accuracy without increasing the inference\\ncost; (2) for the evolution of object detection methods, we\\nfound two new issues, namely how re-parameterized mod-\\nule replaces original module, and how dynamic label as-\\nsignment strategy deals with assignment to different output\\nlayers. In addition, we also propose methods to address the\\ndifﬁculties arising from these issues; (3) we propose “ex-\\ntend” and “compound scaling” methods for the real-time\\nobject detector that can effectively utilize parameters and\\ncomputation; and (4) the method we proposed can effec-\\ntively reduce about 40% parameters and 50% computation\\nof state-of-the-art real-time object detector, and has faster\\ninference speed and higher detection accuracy.\\n2. Related work\\n2.1. Real-time object detectors\\nCurrently state-of-the-art real-time object detectors are\\nmainly based on YOLO [61, 62, 63] and FCOS [76, 77],\\nwhich are [3, 79, 81, 21, 54, 85, 23]. Being able to become\\na state-of-the-art real-time object detector usually requires\\nthe following characteristics: (1) a faster and stronger net-\\nwork architecture; (2) a more effective feature integration\\nmethod [22, 97, 37, 74, 59, 30, 9, 45]; (3) a more accurate\\ndetection method [76, 77, 69]; (4) a more robust loss func-\\ntion [96, 64, 6, 56, 95, 57]; (5) a more efﬁcient label assign-\\nment method [99, 20, 17, 82, 42]; and (6) a more efﬁcient\\ntraining method. In this paper, we do not intend to explore\\nself-supervised learning or knowledge distillation methods\\nthat require additional data or large model. Instead, we will\\ndesign new trainable bag-of-freebies method for the issues\\nderived from the state-of-the-art methods associated with\\n(4), (5), and (6) mentioned above.2.2. Model re-parameterization\\nModel re-parametrization techniques [71, 31, 75, 19, 33,\\n11, 4, 24, 13, 12, 10, 29, 14, 78] merge multiple compu-\\ntational modules into one at inference stage. The model\\nre-parameterization technique can be regarded as an en-\\nsemble technique, and we can divide it into two cate-\\ngories, i.e., module-level ensemble and model-level ensem-\\nble. There are two common practices for model-level re-\\nparameterization to obtain the ﬁnal inference model. One\\nis to train multiple identical models with different train-\\ning data, and then average the weights of multiple trained\\nmodels. The other is to perform a weighted average of the\\nweights of models at different iteration number. Module-\\nlevel re-parameterization is a more popular research issue\\nrecently. This type of method splits a module into multi-\\nple identical or different module branches during training\\nand integrates multiple branched modules into a completely\\nequivalent module during inference. However, not all pro-\\nposed re-parameterized module can be perfectly applied to\\ndifferent architectures. With this in mind, we have devel-', metadata={'source': 'pdfs\\\\yolov7paper.pdf', 'page': 1}), Document(page_content='equivalent module during inference. However, not all pro-\\nposed re-parameterized module can be perfectly applied to\\ndifferent architectures. With this in mind, we have devel-\\noped new re-parameterization module and designed related\\napplication strategies for various architectures.\\n2.3. Model scaling\\nModel scaling [72, 60, 74, 73, 15, 16, 2, 51] is a way\\nto scale up or down an already designed model and make\\nit ﬁt in different computing devices. The model scaling\\nmethod usually uses different scaling factors, such as reso-\\nlution (size of input image), depth (number of layer), width\\n(number of channel), and stage (number of feature pyra-\\nmid), so as to achieve a good trade-off for the amount of\\nnetwork parameters, computation, inference speed, and ac-\\ncuracy. Network architecture search (NAS) is one of the\\ncommonly used model scaling methods. NAS can automat-\\nically search for suitable scaling factors from search space\\nwithout deﬁning too complicated rules. The disadvantage\\nof NAS is that it requires very expensive computation to\\ncomplete the search for model scaling factors. In [15], the\\nresearcher analyzes the relationship between scaling factors\\nand the amount of parameters and operations, trying to di-\\nrectly estimate some rules, and thereby obtain the scaling\\nfactors required by model scaling. Checking the literature,\\nwe found that almost all model scaling methods analyze in-\\ndividual scaling factor independently, and even the methods\\nin the compound scaling category also optimized scaling\\nfactor independently. The reason for this is because most\\npopular NAS architectures deal with scaling factors that are\\nnot very correlated. We observed that all concatenation-\\nbased models, such as DenseNet [32] or V oVNet [39], will\\nchange the input width of some layers when the depth of\\nsuch models is scaled. Since the proposed architecture is\\nconcatenation-based, we have to design a new compound\\nscaling method for this model.\\n2', metadata={'source': 'pdfs\\\\yolov7paper.pdf', 'page': 1}), Document(page_content='Figure 2: Extended efﬁcient layer aggregation networks. The proposed extended ELAN (E-ELAN) does not change the gradient transmis-\\nsion path of the original architecture at all, but use group convolution to increase the cardinality of the added features, and combine the\\nfeatures of different groups in a shufﬂe and merge cardinality manner. This way of operation can enhance the features learned by different\\nfeature maps and improve the use of parameters and calculations.\\n3. Architecture\\n3.1. Extended efﬁcient layer aggregation networks\\nIn most of the literature on designing the efﬁcient ar-\\nchitectures, the main considerations are no more than the\\nnumber of parameters, the amount of computation, and the\\ncomputational density. Starting from the characteristics of\\nmemory access cost, Ma et al. [55] also analyzed the in-\\nﬂuence of the input/output channel ratio, the number of\\nbranches of the architecture, and the element-wise opera-\\ntion on the network inference speed. Doll ´aret al. [15] addi-\\ntionally considered activation when performing model scal-\\ning, that is, to put more consideration on the number of el-\\nements in the output tensors of convolutional layers. The\\ndesign of CSPV oVNet [79] in Figure 2 (b) is a variation of\\nV oVNet [39]. In addition to considering the aforementioned\\nbasic designing concerns, the architecture of CSPV oVNet\\n[79] also analyzes the gradient path, in order to enable the\\nweights of different layers to learn more diverse features.\\nThe gradient analysis approach described above makes in-\\nferences faster and more accurate. ELAN [1] in Figure 2 (c)\\nconsiders the following design strategy – “How to design an\\nefﬁcient network?.” They came out with a conclusion: By\\ncontrolling the shortest longest gradient path, a deeper net-\\nwork can learn and converge effectively. In this paper, we\\npropose Extended-ELAN (E-ELAN) based on ELAN and\\nits main architecture is shown in Figure 2 (d).\\nRegardless of the gradient path length and the stacking\\nnumber of computational blocks in large-scale ELAN, it has\\nreached a stable state. If more computational blocks are\\nstacked unlimitedly, this stable state may be destroyed, and\\nthe parameter utilization rate will decrease. The proposedE-ELAN uses expand, shufﬂe, merge cardinality to achieve\\nthe ability to continuously enhance the learning ability of\\nthe network without destroying the original gradient path.\\nIn terms of architecture, E-ELAN only changes the archi-\\ntecture in computational block, while the architecture of\\ntransition layer is completely unchanged. Our strategy is\\nto use group convolution to expand the channel and car-\\ndinality of computational blocks. We will apply the same\\ngroup parameter and channel multiplier to all the compu-\\ntational blocks of a computational layer. Then, the feature\\nmap calculated by each computational block will be shuf-\\nﬂed into ggroups according to the set group parameter g,\\nand then concatenate them together. At this time, the num-\\nber of channels in each group of feature map will be the\\nsame as the number of channels in the original architec-\\nture. Finally, we add ggroups of feature maps to perform\\nmerge cardinality. In addition to maintaining the original\\nELAN design architecture, E-ELAN can also guide differ-\\nent groups of computational blocks to learn more diverse\\nfeatures.\\n3.2. Model scaling for concatenation-based models\\nThe main purpose of model scaling is to adjust some at-\\ntributes of the model and generate models of different scales\\nto meet the needs of different inference speeds. For ex-\\nample the scaling model of EfﬁcientNet [72] considers the\\nwidth, depth, and resolution. As for the scaled-YOLOv4\\n[79], its scaling model is to adjust the number of stages. In\\n[15], Doll ´aret al. analyzed the inﬂuence of vanilla convolu-\\ntion and group convolution on the amount of parameter and\\ncomputation when performing width and depth scaling, and\\nused this to design the corresponding model scaling method.\\n3', metadata={'source': 'pdfs\\\\yolov7paper.pdf', 'page': 2}), Document(page_content='Figure 3: Model scaling for concatenation-based models. From (a) to (b), we observe that when depth scaling is performed on\\nconcatenation-based models, the output width of a computational block also increases. This phenomenon will cause the input width\\nof the subsequent transmission layer to increase. Therefore, we propose (c), that is, when performing model scaling on concatenation-\\nbased models, only the depth in a computational block needs to be scaled, and the remaining of transmission layer is performed with\\ncorresponding width scaling.\\nThe above methods are mainly used in architectures such as\\nPlainNet or ResNet. When these architectures are in execut-\\ning scaling up or scaling down, the in-degree and out-degree\\nof each layer will not change, so we can independently an-\\nalyze the impact of each scaling factor on the amount of\\nparameters and computation. However, if these methods\\nare applied to the concatenation-based architecture, we will\\nﬁnd that when scaling up or scaling down is performed on\\ndepth, the in-degree of a translation layer which is immedi-\\nately after a concatenation-based computational block will\\ndecrease or increase, as shown in Figure 3 (a) and (b).\\nIt can be inferred from the above phenomenon that\\nwe cannot analyze different scaling factors separately for\\na concatenation-based model but must be considered to-\\ngether. Take scaling-up depth as an example, such an ac-\\ntion will cause a ratio change between the input channel and\\noutput channel of a transition layer, which may lead to a de-\\ncrease in the hardware usage of the model. Therefore, we\\nmust propose the corresponding compound model scaling\\nmethod for a concatenation-based model. When we scale\\nthe depth factor of a computational block, we must also cal-\\nculate the change of the output channel of that block. Then,\\nwe will perform width factor scaling with the same amount\\nof change on the transition layers, and the result is shown\\nin Figure 3 (c). Our proposed compound scaling method\\ncan maintain the properties that the model had at the initial\\ndesign and maintains the optimal structure.\\n4. Trainable bag-of-freebies\\n4.1. Planned re-parameterized convolution\\nAlthough RepConv [13] has achieved excellent perfor-\\nmance on the VGG [68], when we directly apply it to\\nResNet [26] and DenseNet [32] and other architectures,\\nits accuracy will be signiﬁcantly reduced. We use gradi-\\nent ﬂow propagation paths to analyze how re-parameterized\\nconvolution should be combined with different network.\\nWe also designed planned re-parameterized convolution ac-\\ncordingly.\\nFigure 4: Planned re-parameterized model. In the proposed\\nplanned re-parameterized model, we found that a layer with resid-\\nual or concatenation connections, its RepConv should not have\\nidentity connection. Under these circumstances, it can be replaced\\nby RepConvN that contains no identity connections.\\nRepConv actually combines 3×3convolution, 1×1\\nconvolution, and identity connection in one convolutional\\nlayer. After analyzing the combination and correspond-\\ning performance of RepConv and different architectures,\\nwe ﬁnd that the identity connection in RepConv destroys\\nthe residual in ResNet and the concatenation in DenseNet,\\nwhich provides more diversity of gradients for different fea-\\nture maps. For the above reasons, we use RepConv with-\\nout identity connection (RepConvN) to design the architec-\\nture of planned re-parameterized convolution. In our think-\\ning, when a convolutional layer with residual or concate-\\nnation is replaced by re-parameterized convolution, there\\nshould be no identity connection. Figure 4 shows an exam-\\nple of our designed “planned re-parameterized convolution”\\nused in PlainNet and ResNet. As for the complete planned\\nre-parameterized convolution experiment in residual-based\\nmodel and concatenation-based model, it will be presented\\nin the ablation study session.\\n4', metadata={'source': 'pdfs\\\\yolov7paper.pdf', 'page': 3}), Document(page_content='Figure 5: Coarse for auxiliary and ﬁne for lead head label assigner. Compare with normal model (a), the schema in (b) has auxiliary head.\\nDifferent from the usual independent label assigner (c), we propose (d) lead head guided label assigner and (e) coarse-to-ﬁne lead head\\nguided label assigner. The proposed label assigner is optimized by lead head prediction and the ground truth to get the labels of training\\nlead head and auxiliary head at the same time. The detailed coarse-to-ﬁne implementation method and constraint design details will be\\nelaborated in Apendix.\\n4.2. Coarse for auxiliary and ﬁne for lead loss\\nDeep supervision [38] is a technique that is often used\\nin training deep networks. Its main concept is to add\\nextra auxiliary head in the middle layers of the network,\\nand the shallow network weights with assistant loss as the\\nguide. Even for architectures such as ResNet [26] and\\nDenseNet [32] which usually converge well, deep supervi-\\nsion [70, 98, 67, 47, 82, 65, 86, 50] can still signiﬁcantly\\nimprove the performance of the model on many tasks. Fig-\\nure 5 (a) and (b) show, respectively, the object detector ar-\\nchitecture “without” and “with” deep supervision. In this\\npaper, we call the head responsible for the ﬁnal output as\\nthe lead head, and the head used to assist training is called\\nauxiliary head.\\nNext we want to discuss the issue of label assignment. In\\nthe past, in the training of deep network, label assignment\\nusually refers directly to the ground truth and generate hard\\nlabel according to the given rules. However, in recent years,\\nif we take object detection as an example, researchers often\\nuse the quality and distribution of prediction output by the\\nnetwork, and then consider together with the ground truth to\\nuse some calculation and optimization methods to generate\\na reliable soft label [61, 8, 36, 99, 91, 44, 43, 90, 20, 17, 42].\\nFor example, YOLO [61] use IoU of prediction of bounding\\nbox regression and ground truth as the soft label of object-\\nness. In this paper, we call the mechanism that considers\\nthe network prediction results together with the ground truth\\nand then assigns soft labels as “label assigner.”\\nDeep supervision needs to be trained on the target ob-\\njectives regardless of the circumstances of auxiliary head or\\nlead head. During the development of soft label assigner re-\\nlated techniques, we accidentally discovered a new deriva-\\ntive issue, i.e., “How to assign soft label to auxiliary head\\nand lead head ?” To the best of our knowledge, the relevant\\nliterature has not explored this issue so far. The results of\\nthe most popular method at present is as shown in Figure 5\\n(c), which is to separate auxiliary head and lead head, and\\nthen use their own prediction results and the ground truthto execute label assignment. The method proposed in this\\npaper is a new label assignment method that guides both\\nauxiliary head and lead head by the lead head prediction.\\nIn other words, we use lead head prediction as guidance to\\ngenerate coarse-to-ﬁne hierarchical labels, which are used\\nfor auxiliary head and lead head learning, respectively. The\\ntwo proposed deep supervision label assignment strategies\\nare shown in Figure 5 (d) and (e), respectively.\\nLead head guided label assigner is mainly calculated\\nbased on the prediction result of the lead head and the\\nground truth, and generate soft label through the optimiza-\\ntion process. This set of soft labels will be used as the tar-\\nget training model for both auxiliary head and lead head.\\nThe reason to do this is because lead head has a relatively\\nstrong learning capability, so the soft label generated from it\\nshould be more representative of the distribution and corre-\\nlation between the source data and the target. Furthermore,\\nwe can view such learning as a kind of generalized residual\\nlearning. By letting the shallower auxiliary head directly\\nlearn the information that lead head has learned, lead head\\nwill be more able to focus on learning residual information', metadata={'source': 'pdfs\\\\yolov7paper.pdf', 'page': 4}), Document(page_content='learning. By letting the shallower auxiliary head directly\\nlearn the information that lead head has learned, lead head\\nwill be more able to focus on learning residual information\\nthat has not yet been learned.\\nCoarse-to-ﬁne lead head guided label assigner also\\nused the predicted result of the lead head and the ground\\ntruth to generate soft label. However, in the process we gen-\\nerate two different sets of soft label, i.e., coarse label and\\nﬁne label, where ﬁne label is the same as the soft label gen-\\nerated by lead head guided label assigner, and coarse label\\nis generated by allowing more grids to be treated as posi-\\ntive target by relaxing the constraints of the positive sample\\nassignment process. The reason for this is that the learning\\nability of an auxiliary head is not as strong as that of a lead\\nhead, and in order to avoid losing the information that needs\\nto be learned, we will focus on optimizing the recall of aux-\\niliary head in the object detection task. As for the output\\nof lead head, we can ﬁlter the high precision results from\\nthe high recall results as the ﬁnal output. However, we must\\nnote that if the additional weight of coarse label is close to\\n5', metadata={'source': 'pdfs\\\\yolov7paper.pdf', 'page': 4}), Document(page_content='Table 1: Comparison of baseline object detectors.\\nModel #Param. FLOPs Size APvalAPval\\n50APval\\n75APval\\nSAPval\\nMAPval\\nL\\nYOLOv4 [3] 64.4M 142.8G 640 49.7% 68.2% 54.3% 32.9% 54.8% 63.7%\\nYOLOR-u5 (r6.1) [81] 46.5M 109.1G 640 50.2% 68.7% 54.6% 33.2% 55.5% 63.7%\\nYOLOv4-CSP [79] 52.9M 120.4G 640 50.3% 68.6% 54.9% 34.2% 55.6% 65.1%\\nYOLOR-CSP [81] 52.9M 120.4G 640 50.8% 69.5% 55.3% 33.7% 56.0% 65.4%\\nYOLOv7 36.9M 104.7G 640 51.2% 69.7% 55.5% 35.2% 56.0% 66.7%\\nimprovement -43% -15% - +0.4 +0.2 +0.2 +1.5 = +1.3\\nYOLOR-CSP-X [81] 96.9M 226.8G 640 52.7% 71.3% 57.4% 36.3% 57.5% 68.3%\\nYOLOv7-X 71.3M 189.9G 640 52.9% 71.1% 57.5% 36.9% 57.7% 68.6%\\nimprovement -36% -19% - +0.2 -0.2 +0.1 +0.6 +0.2 +0.3\\nYOLOv4-tiny [79] 6.1 6.9 416 24.9% 42.1% 25.7% 8.7% 28.4% 39.2%\\nYOLOv7-tiny 6.2 5.8 416 35.2% 52.8% 37.3% 15.7% 38.0% 53.4%\\nimprovement +2% -19% - +10.3 +10.7 +11.6 +7.0 +9.6 +14.2\\nYOLOv4-tiny-3l [79] 8.7 5.2 320 30.8% 47.3% 32.2% 10.9% 31.9% 51.5%\\nYOLOv7-tiny 6.2 3.5 320 30.8% 47.3% 32.2% 10.0% 31.9% 52.2%\\nimprovement -39% -49% - = = = -0.9 = +0.7\\nYOLOR-E6 [81] 115.8M 683.2G 1280 55.7% 73.2% 60.7% 40.1% 60.4% 69.2%\\nYOLOv7-E6 97.2M 515.2G 1280 55.9% 73.5% 61.1% 40.6% 60.3% 70.0%\\nimprovement -19% -33% - +0.2 +0.3 +0.4 +0.5 -0.1 +0.8\\nYOLOR-D6 [81] 151.7M 935.6G 1280 56.1% 73.9% 61.2% 42.4% 60.5% 69.9%\\nYOLOv7-D6 154.7M 806.8G 1280 56.3% 73.8% 61.4% 41.3% 60.6% 70.1%\\nYOLOv7-E6E 151.7M 843.2G 1280 56.8% 74.4% 62.1% 40.8% 62.1% 70.6%\\nimprovement = -11% - +0.7 +0.5 +0.9 -1.6 +1.6 +0.7\\nthat of ﬁne label, it may produce bad prior at ﬁnal predic-\\ntion. Therefore, in order to make those extra coarse positive\\ngrids have less impact, we put restrictions in the decoder,\\nso that the extra coarse positive grids cannot produce soft\\nlabel perfectly. The mechanism mentioned above allows\\nthe importance of ﬁne label and coarse label to be dynam-\\nically adjusted during the learning process, and makes the\\noptimizable upper bound of ﬁne label always higher than\\ncoarse label.\\n4.3. Other trainable bag-of-freebies\\nIn this section we will list some trainable bag-of-\\nfreebies. These freebies are some of the tricks we used\\nin training, but the original concepts were not proposed\\nby us. The training details of these freebies will be elab-\\norated in the Appendix, including (1) Batch normalization\\nin conv-bn-activation topology: This part mainly connects\\nbatch normalization layer directly to convolutional layer.\\nThe purpose of this is to integrate the mean and variance\\nof batch normalization into the bias and weight of convolu-\\ntional layer at the inference stage. (2) Implicit knowledge\\nin YOLOR [81] combined with convolution feature map in\\naddition and multiplication manner: Implicit knowledge in\\nYOLOR can be simpliﬁed to a vector by pre-computing at\\nthe inference stage. This vector can be combined with the\\nbias and weight of the previous or subsequent convolutional\\nlayer. (3) EMA model: EMA is a technique used in mean\\nteacher [75], and in our system we use EMA model purely\\nas the ﬁnal inference model.5. Experiments\\n5.1. Experimental setup\\nWe use Microsoft COCO dataset to conduct experiments\\nand validate our object detection method. All our experi-\\nments did not use pre-trained models. That is, all models\\nwere trained from scratch. During the development pro-\\ncess, we used train 2017 set for training, and then used val\\n2017 set for veriﬁcation and choosing hyperparameters. Fi-\\nnally, we show the performance of object detection on the\\ntest 2017 set and compare it with the state-of-the-art object\\ndetection algorithms. Detailed training parameter settings\\nare described in Appendix.\\nWe designed basic model for edge GPU, normal GPU,\\nand cloud GPU, and they are respectively called YOLOv7-\\ntiny, YOLOv7, and YOLOv7-W6. At the same time, we\\nalso use basic model for model scaling for different ser-\\nvice requirements and get different types of models. For\\nYOLOv7, we do stack scaling on neck, and use the pro-\\nposed compound scaling method to perform scaling-up of', metadata={'source': 'pdfs\\\\yolov7paper.pdf', 'page': 5}), Document(page_content='vice requirements and get different types of models. For\\nYOLOv7, we do stack scaling on neck, and use the pro-\\nposed compound scaling method to perform scaling-up of\\nthe depth and width of the entire model, and use this to ob-\\ntain YOLOv7-X. As for YOLOv7-W6, we use the newly\\nproposed compound scaling method to obtain YOLOv7-E6\\nand YOLOv7-D6. In addition, we use the proposed E-\\nELAN for YOLOv7-E6, and thereby complete YOLOv7-\\nE6E. Since YOLOv7-tiny is an edge GPU-oriented archi-\\ntecture, it will use leaky ReLU as activation function. As\\nfor other models we use SiLU as activation function. We\\nwill describe the scaling factor of each model in detail in\\nAppendix.\\n6', metadata={'source': 'pdfs\\\\yolov7paper.pdf', 'page': 5}), Document(page_content='Table 2: Comparison of state-of-the-art real-time object detectors.\\nModel #Param. FLOPs Size FPS APtest/APvalAPtest\\n50APtest\\n75APtest\\nSAPtest\\nMAPtest\\nL\\nYOLOX-S [21] 9.0M 26.8G 640 102 40.5% / 40.5% - - - - -\\nYOLOX-M [21] 25.3M 73.8G 640 81 47.2% / 46.9% - - - - -\\nYOLOX-L [21] 54.2M 155.6G 640 69 50.1% / 49.7% - - - - -\\nYOLOX-X [21] 99.1M 281.9G 640 58 51.5% / 51.1% - - - - -\\nPPYOLOE-S [85] 7.9M 17.4G 640 208 43.1% / 42.7% 60.5% 46.6% 23.2% 46.4% 56.9%\\nPPYOLOE-M [85] 23.4M 49.9G 640 123 48.9% / 48.6% 66.5% 53.0% 28.6% 52.9% 63.8%\\nPPYOLOE-L [85] 52.2M 110.1G 640 78 51.4% / 50.9% 68.9% 55.6% 31.4% 55.3% 66.1%\\nPPYOLOE-X [85] 98.4M 206.6G 640 45 52.2% / 51.9% 69.9% 56.5% 33.3% 56.3% 66.4%\\nYOLOv5-N (r6.1) [23] 1.9M 4.5G 640 159 - / 28.0% - - - - -\\nYOLOv5-S (r6.1) [23] 7.2M 16.5G 640 156 - / 37.4% - - - - -\\nYOLOv5-M (r6.1) [23] 21.2M 49.0G 640 122 - / 45.4% - - - - -\\nYOLOv5-L (r6.1) [23] 46.5M 109.1G 640 99 - / 49.0% - - - - -\\nYOLOv5-X (r6.1) [23] 86.7M 205.7G 640 83 - / 50.7% - - - - -\\nYOLOR-CSP [81] 52.9M 120.4G 640 106 51.1% / 50.8% 69.6% 55.7% 31.7% 55.3% 64.7%\\nYOLOR-CSP-X [81] 96.9M 226.8G 640 87 53.0% / 52.7% 71.4% 57.9% 33.7% 57.1% 66.8%\\nYOLOv7-tiny-SiLU 6.2M 13.8G 640 286 38.7% / 38.7% 56.7% 41.7% 18.8% 42.4% 51.9%\\nYOLOv7 36.9M 104.7G 640 161 51.4% / 51.2% 69.7% 55.9% 31.8% 55.5% 65.0%\\nYOLOv7-X 71.3M 189.9G 640 114 53.1% / 52.9% 71.2% 57.8% 33.8% 57.1% 67.4%\\nYOLOv5-N6 (r6.1) [23] 3.2M 18.4G 1280 123 - / 36.0% - - - - -\\nYOLOv5-S6 (r6.1) [23] 12.6M 67.2G 1280 122 - / 44.8% - - - - -\\nYOLOv5-M6 (r6.1) [23] 35.7M 200.0G 1280 90 - / 51.3% - - - - -\\nYOLOv5-L6 (r6.1) [23] 76.8M 445.6G 1280 63 - / 53.7% - - - - -\\nYOLOv5-X6 (r6.1) [23] 140.7M 839.2G 1280 38 - / 55.0% - - - - -\\nYOLOR-P6 [81] 37.2M 325.6G 1280 76 53.9% / 53.5% 71.4% 58.9% 36.1% 57.7% 65.6%\\nYOLOR-W6 [81] 79.8G 453.2G 1280 66 55.2% / 54.8% 72.7% 60.5% 37.7% 59.1% 67.1%\\nYOLOR-E6 [81] 115.8M 683.2G 1280 45 55.8% / 55.7% 73.4% 61.1% 38.4% 59.7% 67.7%\\nYOLOR-D6 [81] 151.7M 935.6G 1280 34 56.5% / 56.1% 74.1% 61.9% 38.9% 60.4% 68.7%\\nYOLOv7-W6 70.4M 360.0G 1280 84 54.9% / 54.6% 72.6% 60.1% 37.3% 58.7% 67.1%\\nYOLOv7-E6 97.2M 515.2G 1280 56 56.0% / 55.9% 73.5% 61.2% 38.0% 59.9% 68.4%\\nYOLOv7-D6 154.7M 806.8G 1280 44 56.6% / 56.3% 74.0% 61.8% 38.8% 60.1% 69.5%\\nYOLOv7-E6E 151.7M 843.2G 1280 36 56.8% / 56.8% 74.4% 62.1% 39.3% 60.5% 69.0%\\n1Our FLOPs is calaculated by rectangle input resolution like 640 ×640 or 1280 ×1280.\\n2Our inference time is estimated by using letterbox resize input image to make its long side equals to 640 or 1280.\\n5.2. Baselines\\nWe choose previous version of YOLO [3, 79] and state-\\nof-the-art object detector YOLOR [81] as our baselines. Ta-\\nble 1 shows the comparison of our proposed YOLOv7 mod-\\nels and those baseline that are trained with the same settings.\\nFrom the results we see that if compared with YOLOv4,\\nYOLOv7 has 75% less parameters, 36% less computation,\\nand brings 1.5% higher AP. If compared with state-of-the-\\nart YOLOR-CSP, YOLOv7 has 43% fewer parameters, 15%\\nless computation, and 0.4% higher AP. In the performance\\nof tiny model, compared with YOLOv4-tiny-31, YOLOv7-\\ntiny reduces the number of parameters by 39% and the\\namount of computation by 49%, but maintains the same AP.\\nOn the cloud GPU model, our model can still have a higher\\nAP while reducing the number of parameters by 19% and\\nthe amount of computation by 33%.5.3. Comparison with state-of-the-arts\\nWe compare the proposed method with state-of-the-art\\nobject detectors for general GPUs and Mobile GPUs, and\\nthe results are shown in Table 2. From the results in\\nTable 2 we know that the proposed method has the best\\nspeed-accuracy trade-off comprehensively. If we compare\\nYOLOv7-tiny-SiLU with YOLOv5-N (r6.1), our method\\nis 127 fps faster and 10.7% more accurate on AP. In ad-\\ndition, YOLOv7 has 51.4% AP at frame rate of 161 fps,\\nwhile PPYOLOE-L with the same AP has only 78 fps frame\\nrate. In terms of parameter usage, YOLOv7 is 41% less than\\nPPYOLOE-L. If we compare YOLOv7-X with 114 fps in-', metadata={'source': 'pdfs\\\\yolov7paper.pdf', 'page': 6}), Document(page_content='while PPYOLOE-L with the same AP has only 78 fps frame\\nrate. In terms of parameter usage, YOLOv7 is 41% less than\\nPPYOLOE-L. If we compare YOLOv7-X with 114 fps in-\\nference speed to YOLOv5-L (r6.1) with 99 fps inference\\nspeed, YOLOv7-X can improve AP by 3.9%. If YOLOv7-\\nX is compared with YOLOv5-X (r6.1) of similar scale, the\\ninference speed of YOLOv7-X is 31 fps faster. In addi-\\ntion, in terms of the amount of parameters and computation,\\nYOLOv7-X reduces 22% of parameters and 8% of compu-\\ntation compared to YOLOv5-X (r6.1), but improves AP by\\n2.2%.\\n7', metadata={'source': 'pdfs\\\\yolov7paper.pdf', 'page': 6}), Document(page_content='If we compare YOLOv7 with YOLOR using the input\\nresolution 1280, the inference speed of YOLOv7-W6 is 8\\nfps faster than that of YOLOR-P6, and the detection rate is\\nalso increased by 1% AP. As for the comparison between\\nYOLOv7-E6 and YOLOv5-X6 (r6.1), the former has 0.9%\\nAP gain than the latter, 45% less parameters and 63% less\\ncomputation, and the inference speed is increased by 47%.\\nYOLOv7-D6 has close inference speed to YOLOR-E6, but\\nimproves AP by 0.8%. YOLOv7-E6E has close inference\\nspeed to YOLOR-D6, but improves AP by 0.3%.\\n5.4. Ablation study\\n5.4.1 Proposed compound scaling method\\nTable 3 shows the results obtained when using different\\nmodel scaling strategies for scaling up. Among them, our\\nproposed compound scaling method is to scale up the depth\\nof computational block by 1.5 times and the width of tran-\\nsition block by 1.25 times. If our method is compared with\\nthe method that only scaled up the width, our method can\\nimprove the AP by 0.5% with less parameters and amount\\nof computation. If our method is compared with the method\\nthat only scales up the depth, our method only needs to in-\\ncrease the number of parameters by 2.9% and the amount of\\ncomputation by 1.2%, which can improve the AP by 0.2%.\\nIt can be seen from the results of Table 3 that our proposed\\ncompound scaling strategy can utilize parameters and com-\\nputation more efﬁciently.\\nTable 3: Ablation study on proposed model scaling.\\nModel #Param. FLOPs Size APvalAPval\\n50APval\\n75\\nbase (v7-X light) 47.0M 125.5G 640 51.7% 70.1% 56.0%\\nwidth only (1.25 w)73.4M 195.5G 640 52.4% 70.9% 57.1%\\ndepth only (2.0 d) 69.3M 187.6G 640 52.7% 70.8% 57.3%\\ncompound (v7-X) 71.3M 189.9G 640 52.9% 71.1% 57.5%\\nimprovement - - - +1.2 +1.0 +1.5\\n5.4.2 Proposed planned re-parameterized model\\nIn order to verify the generality of our proposed planed\\nre-parameterized model, we use it on concatenation-based\\nmodel and residual-based model respectively for veriﬁca-\\ntion. The concatenation-based model and residual-based\\nmodel we chose for veriﬁcation are 3-stacked ELAN and\\nCSPDarknet, respectively.\\nIn the experiment of concatenation-based model, we re-\\nplace the 3×3convolutional layers in different positions in\\n3-stacked ELAN with RepConv, and the detailed conﬁgura-\\ntion is shown in Figure 6. From the results shown in Table 4\\nwe see that all higher AP values are present on our proposed\\nplanned re-parameterized model.\\nIn the experiment dealing with residual-based model,\\nsince the original dark block does not have a 3×3con-\\nFigure 6: Planned RepConv 3-stacked ELAN. Blue circles are the\\nposition we replace Conv by RepConv.\\nTable 4: Ablation study on planned RepConcatenation model.\\nModel APvalAPval\\n50APval\\n75APval\\nSAPval\\nMAPval\\nL\\nbase (3-S ELAN) 52.26% 70.41% 56.77% 35.81% 57.00% 67.59%\\nFigure 6 (a) 52.18% 70.34% 56.90% 35.71% 56.83% 67.51%\\nFigure 6 (b) 52.30% 70.30% 56.92% 35.76% 56.95% 67.74%\\nFigure 6 (c) 52.33% 70.56% 56.91% 35.90% 57.06% 67.50%\\nFigure 6 (d) 52.17% 70.32% 56.82% 35.33% 57.06% 68.09%\\nFigure 6 (e) 52.23% 70.20% 56.81% 35.34% 56.97% 66.88%\\nvolution block that conforms to our design strategy, we ad-\\nditionally design a reversed dark block for the experiment,\\nwhose architecture is shown in Figure 7. Since the CSP-\\nDarknet with dark block and reversed dark block has exactly\\nthe same amount of parameters and operations, it is fair to\\ncompare. The experiment results illustrated in Table 5 fully\\nconﬁrm that the proposed planned re-parameterized model\\nis equally effective on residual-based model. We ﬁnd that\\nthe design of RepCSPResNet [85] also ﬁt our design pat-\\ntern.\\nFigure 7: Reversed CSPDarknet. We reverse the position of 1×1\\nand3×3convolutional layer in dark block to ﬁt our planned re-\\nparameterized model design strategy.\\nTable 5: Ablation study on planned RepResidual model.\\nModel APvalAPval\\n50APval\\n75APval\\nSAPval\\nMAPval\\nL\\nbase (YOLOR-W6) 54.82% 72.39% 59.95% 39.68% 59.38% 68.30%\\nRepCSP 54.67% 72.50% 59.58% 40.22% 59.61% 67.87%\\nRCSP 54.36% 71.95% 59.54% 40.15% 59.02% 67.44%', metadata={'source': 'pdfs\\\\yolov7paper.pdf', 'page': 7}), Document(page_content='50APval\\n75APval\\nSAPval\\nMAPval\\nL\\nbase (YOLOR-W6) 54.82% 72.39% 59.95% 39.68% 59.38% 68.30%\\nRepCSP 54.67% 72.50% 59.58% 40.22% 59.61% 67.87%\\nRCSP 54.36% 71.95% 59.54% 40.15% 59.02% 67.44%\\nRepRCSP 54.85% 72.51% 60.08% 40.53% 59.52% 68.06%\\nbase (YOLOR-CSP) 50.81% 69.47% 55.28% 33.74% 56.01% 65.38%\\nRepRCSP 50.91% 69.54% 55.55% 34.44% 55.74% 65.46%\\n8', metadata={'source': 'pdfs\\\\yolov7paper.pdf', 'page': 7}), Document(page_content='Figure 8: Objectness map predicted by different methods at auxiliary head and lead head.\\n5.4.3 Proposed assistant loss for auxiliary head\\nIn the assistant loss for auxiliary head experiments, we com-\\npare the general independent label assignment for lead head\\nand auxiliary head methods, and we also compare the two\\nproposed lead guided label assignment methods. We show\\nall comparison results in Table 6. From the results listed in\\nTable 6, it is clear that any model that increases assistant\\nloss can signiﬁcantly improve the overall performance. In\\naddition, our proposed lead guided label assignment strat-\\negy receives better performance than the general indepen-\\ndent label assignment strategy in AP, AP 50, and AP 75. As\\nfor our proposed coarse for assistant and ﬁne for lead label\\nassignment strategy, it results in best results in all cases. In\\nFigure 8 we show the objectness map predicted by different\\nmethods at auxiliary head and lead head. From Figure 8 we\\nﬁnd that if auxiliary head learns lead guided soft label, it\\nwill indeed help lead head to extract the residual informa-\\ntion from the consistant targets.\\nTable 6: Ablation study on proposed auxiliary head.\\nModel Size APvalAPval\\n50APval\\n75\\nbase (v7-E6) 1280 55.6% 73.2% 60.7%\\nindependent 1280 55.8% 73.4% 60.9%\\nlead guided 1280 55.9% 73.5% 61.0%\\ncoarse-to-ﬁne lead guided 1280 55.9% 73.5% 61.1%\\nimprovement - +0.3 +0.3 +0.4\\nIn Table 7 we further analyze the effect of the proposed\\ncoarse-to-ﬁne lead guided label assignment method on the\\ndecoder of auxiliary head. That is, we compared the results\\nof with/without the introduction of upper bound constraint.\\nJudging from the numbers in the Table, the method of con-\\nstraining the upper bound of objectness by the distance from\\nthe center of the object can achieve better performance.\\nTable 7: Ablation study on constrained auxiliary head.\\nModel Size APvalAPval\\n50APval\\n75\\nbase (v7-E6) 1280 55.6% 73.2% 60.7%\\naux without constraint 1280 55.9% 73.5% 61.0%\\naux with constraint 1280 55.9% 73.5% 61.1%\\nimprovement - +0.3 +0.3 +0.4Since the proposed YOLOv7 uses multiple pyramids to\\njointly predict object detection results, we can directly con-\\nnect auxiliary head to the pyramid in the middle layer for\\ntraining. This type of training can make up for informa-\\ntion that may be lost in the next level pyramid prediction.\\nFor the above reasons, we designed partial auxiliary head\\nin the proposed E-ELAN architecture. Our approach is to\\nconnect auxiliary head after one of the sets of feature map\\nbefore merging cardinality, and this connection can make\\nthe weight of the newly generated set of feature map not\\ndirectly updated by assistant loss. Our design allows each\\npyramid of lead head to still get information from objects\\nwith different sizes. Table 8 shows the results obtained us-\\ning two different methods, i.e., coarse-to-ﬁne lead guided\\nand partial coarse-to-ﬁne lead guided methods. Obviously,\\nthe partial coarse-to-ﬁne lead guided method has a better\\nauxiliary effect.\\nTable 8: Ablation study on partial auxiliary head.\\nModel Size APvalAPval\\n50APval\\n75\\nbase (v7-E6E) 1280 56.3% 74.0% 61.5%\\naux 1280 56.5% 74.0% 61.6%\\npartial aux 1280 56.8% 74.4% 62.1%\\nimprovement - +0.5 +0.4 +0.6\\n6. Conclusions\\nIn this paper we propose a new architecture of real-\\ntime object detector and the corresponding model scaling\\nmethod. Furthermore, we ﬁnd that the evolving process\\nof object detection methods generates new research top-\\nics. During the research process, we found the replace-\\nment problem of re-parameterized module and the alloca-\\ntion problem of dynamic label assignment. To solve the\\nproblem, we propose the trainable bag-of-freebies method\\nto enhance the accuracy of object detection. Based on the\\nabove, we have developed the YOLOv7 series of object de-\\ntection systems, which receives the state-of-the-art results.\\n7. Acknowledgements\\nThe authors wish to thank National Center for High-\\nperformance Computing (NCHC) for providing computa-\\ntional and storage resources.\\n9', metadata={'source': 'pdfs\\\\yolov7paper.pdf', 'page': 8}), Document(page_content='Table 9: More comparison (batch=1, no-TRT, without extra object detection training data)\\nModel #Param. FLOPs Size FPSV100APtest/APvalAPtest\\n50APtest\\n75\\nYOLOv7-tiny-SiLU 6.2M 13.8G 640 286 38.7% /38.7% 56.7% 41.7%\\nPPYOLOE-S [85] 7.9M 17.4G 640 208 43.1% /42.7% 60.5% 46.6%\\nYOLOv7 36.9M 104.7G 640 161 51.4% /51.2% 69.7% 55.9%\\nYOLOv5-N (r6.1) [23] 1.9M 4.5G 640 159 - / 28.0% - -\\nYOLOv5-S (r6.1) [23] 7.2M 16.5G 640 156 - / 37.4% - -\\nPPYOLOE-M [85] 23.4M 49.9G 640 123 48.9% / 48.6% 66.5% 53.0%\\nYOLOv5-N6 (r6.1) [23] 3.2M 18.4G 1280 123 - / 36.0% - -\\nYOLOv5-S6 (r6.1) [23] 12.6M 67.2G 1280 122 - / 44.8% - -\\nYOLOv5-M (r6.1) [23] 21.2M 49.0G 640 122 - / 45.4% - -\\nYOLOv7-X 71.3M 189.9G 640 114 53.1% /52.9% 71.2% 57.8%\\nYOLOR-CSP [81] 52.9M 120.4G 640 106 51.1% / 50.8% 69.6% 55.7%\\nYOLOX-S [21] 9.0M 26.8G 640 102 40.5% / 40.5% - -\\nYOLOv5-L (r6.1) [23] 46.5M 109.1G 640 99 - / 49.0% - -\\nYOLOv5-M6 (r6.1) [23] 35.7M 200.0G 1280 90 - / 51.3% - -\\nYOLOR-CSP-X [81] 96.9M 226.8G 640 87 53.0% / 52.7% 71.4% 57.9%\\nYOLOv7-W6 70.4M 360.0G 1280 84 54.9% /54.6% 72.6% 60.1%\\nYOLOv5-X (r6.1) [23] 86.7M 205.7G 640 83 - / 50.7% - -\\nYOLOX-M [21] 25.3M 73.8G 640 81 47.2% / 46.9% - -\\nPPYOLOE-L [85] 52.2M 110.1G 640 78 51.4% / 50.9% 68.9% 55.6%\\nYOLOR-P6 [81] 37.2M 325.6G 1280 76 53.9% / 53.5% 71.4% 58.9%\\nYOLOX-L [21] 54.2M 155.6G 640 69 50.1% / 49.7% - -\\nYOLOR-W6 [81] 79.8G 453.2G 1280 66 55.2% /54.8% 72.7% 60.5%\\nYOLOv5-L6 (r6.1) [23] 76.8M 445.6G 1280 63 - / 53.7% - -\\nYOLOX-X [21] 99.1M 281.9G 640 58 51.5% / 51.1% - -\\nYOLOv7-E6 97.2M 515.2G 1280 56 56.0% /55.9% 73.5% 61.2%\\nYOLOR-E6 [81] 115.8M 683.2G 1280 45 55.8% / 55.7% 73.4% 61.1%\\nPPYOLOE-X [85] 98.4M 206.6G 640 45 52.2% / 51.9% 69.9% 56.5%\\nYOLOv7-D6 154.7M 806.8G 1280 44 56.6% /56.3% 74.0% 61.8%\\nYOLOv5-X6 (r6.1) [23] 140.7M 839.2G 1280 38 - / 55.0% - -\\nYOLOv7-E6E 151.7M 843.2G 1280 36 56.8% /56.8% 74.4% 62.1%\\nYOLOR-D6 [81] 151.7M 935.6G 1280 34 56.5% / 56.1% 74.1% 61.9%\\nF-RCNN-R101-FPN+ [5] 60.0M 246.0G 1333 20 - / 44.0% - -\\nDeformable DETR [100] 40.0M 173.0G - 19 - / 46.2% - -\\nSwin-B (C-M-RCNN) [52] 145.0M 982.0G 1333 11.6 - / 51.9% - -\\nDETR DC5-R101 [5] 60.0M 253.0G 1333 10 - / 44.9% - -\\nEfﬁcientDet-D7x [74] 77.0M 410.0G 1536 6.5 55.1% / 54.4% 72.4% 58.4%\\nDual-Swin-T (C-M-RCNN) [47] 113.8M 836.0G 1333 6.5 - / 53.6% - -\\nViT-Adapter-B [7] 122.0M 997.0G - 4.4 - / 50.8% - -\\nDual-Swin-B (HTC) [47] 235.0M - 1600 2.5 58.7% /58.4% - -\\nDual-Swin-L (HTC) [47] 453.0M - 1600 1.5 59.4% /59.1% - -\\nModel #Param. FLOPs Size FPSA100APtest/APvalAPtest\\n50APtest\\n75\\nDN-Deformable-DETR [41] 48.0M 265.0G 1333 23.0 - / 48.6% - -\\nConvNeXt-B (C-M-RCNN) [53] - 964.0G 1280 11.5 - / 54.0% 73.1% 58.8%\\nSwin-B (C-M-RCNN) [52] - 982.0G 1280 10.7 - / 53.0% 71.8% 57.5%\\nDINO-5scale (R50) [89] 47.0M 860.0G 1333 10.0 - / 51.0% - -\\nConvNeXt-L (C-M-RCNN) [53] - 1354.0G 1280 10.0 - / 54.8% 73.8% 59.8%\\nSwin-L (C-M-RCNN) [52] - 1382.0G 1280 9.2 - / 53.9% 72.4% 58.8%\\nConvNeXt-XL (C-M-RCNN) [53] - 1898.0G 1280 8.6 - / 55.2% 74.2% 59.9%\\n8. More comparison\\nYOLOv7 surpasses all known object detectors in both\\nspeed and accuracy in the range from 5 FPS to 160 FPS and\\nhas the highest accuracy 56.8% AP test-dev / 56.8% AP\\nmin-val among all known real-time object detectors with 30\\nFPS or higher on GPU V100. YOLOv7-E6 object detector\\n(56 FPS V100, 55.9% AP) outperforms both transformer-\\nbased detector SWIN-L Cascade-Mask R-CNN (9.2 FPS\\nA100, 53.9% AP) by 509% in speed and 2% in accuracy,and convolutional-based detector ConvNeXt-XL Cascade-\\nMask R-CNN (8.6 FPS A100, 55.2% AP) by 551% in speed\\nand 0.7% AP in accuracy, as well as YOLOv7 outperforms:\\nYOLOR, YOLOX, Scaled-YOLOv4, YOLOv5, DETR, De-\\nformable DETR, DINO-5scale-R50, ViT-Adapter-B and\\nmany other object detectors in speed and accuracy. More\\nover, we train YOLOv7 only on MS COCO dataset from\\nscratch without using any other datasets or pre-trained\\nweights.\\n10', metadata={'source': 'pdfs\\\\yolov7paper.pdf', 'page': 9}), Document(page_content='Figure 9: Comparison with other object detectors.\\nFigure 10: Comparison with other real-time object detectors.\\nTable 10: Comparison of different setting.\\nModel Presicion IoU threshold APval\\nYOLOv7-X FP16 (default) 0.65 (default) 52.9%\\nYOLOv7-X FP32 0.65 53.0%\\nYOLOv7-X FP16 0.70 53.0%\\nYOLOv7-X FP32 0.70 53.1%\\nimprovement - - +0.2%\\n*Similar to meituan/YOLOv6 and PPYOLOE, our model could\\nget higher AP when set higher IoU threshold.\\nThe maximum accuracy of the YOLOv7-E6E (56.8%\\nAP) real-time model is +13.7% AP higher than the cur-\\nrent most accurate meituan/YOLOv6-s model (43.1% AP)\\non COCO dataset. Our YOLOv7-tiny (35.2% AP, 0.4\\nms) model is +25% faster and +0.2% AP higher than\\nmeituan/YOLOv6-n (35.0% AP, 0.5 ms) under identical\\nconditions on COCO dataset and V100 GPU with batch=32.\\nFigure 11: Comparison with other real-time object detectors.\\n11', metadata={'source': 'pdfs\\\\yolov7paper.pdf', 'page': 10}), Document(page_content='References\\n[1] anonymous. Designing network design strategies. anony-\\nmous submission , 2022. 3\\n[2] Irwan Bello, William Fedus, Xianzhi Du, Ekin Dogus\\nCubuk, Aravind Srinivas, Tsung-Yi Lin, Jonathon Shlens,\\nand Barret Zoph. Revisiting ResNets: Improved training\\nand scaling strategies. Advances in Neural Information Pro-\\ncessing Systems (NeurIPS) , 34, 2021. 2\\n[3] Alexey Bochkovskiy, Chien-Yao Wang, and Hong-\\nYuan Mark Liao. YOLOv4: Optimal speed and accuracy of\\nobject detection. arXiv preprint arXiv:2004.10934 , 2020.\\n2, 6, 7\\n[4] Yue Cao, Thomas Andrew Geddes, Jean Yee Hwa Yang,\\nand Pengyi Yang. Ensemble deep learning in bioinformat-\\nics.Nature Machine Intelligence , 2(9):500–508, 2020. 2\\n[5] Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nico-\\nlas Usunier, Alexander Kirillov, and Sergey Zagoruyko.\\nEnd-to-end object detection with transformers. In Pro-\\nceedings of the European Conference on Computer Vision\\n(ECCV) , pages 213–229, 2020. 10\\n[6] Kean Chen, Weiyao Lin, Jianguo Li, John See, Ji Wang, and\\nJunni Zou. AP-loss for accurate one-stage object detection.\\nIEEE Transactions on Pattern Analysis and Machine Intel-\\nligence (TPAMI) , 43(11):3782–3798, 2020. 2\\n[7] Zhe Chen, Yuchen Duan, Wenhai Wang, Junjun He, Tong\\nLu, Jifeng Dai, and Yu Qiao. Vision transformer adapter for\\ndense predictions. arXiv preprint arXiv:2205.08534 , 2022.\\n10\\n[8] Jiwoong Choi, Dayoung Chun, Hyun Kim, and Hyuk-Jae\\nLee. Gaussian YOLOv3: An accurate and fast object detec-\\ntor using localization uncertainty for autonomous driving.\\nInProceedings of the IEEE/CVF International Conference\\non Computer Vision (ICCV) , pages 502–511, 2019. 5\\n[9] Xiyang Dai, Yinpeng Chen, Bin Xiao, Dongdong Chen,\\nMengchen Liu, Lu Yuan, and Lei Zhang. Dynamic head:\\nUnifying object detection heads with attentions. In Pro-\\nceedings of the IEEE/CVF Conference on Computer Vision\\nand Pattern Recognition (CVPR) , pages 7373–7382, 2021.\\n2\\n[10] Xiaohan Ding, Honghao Chen, Xiangyu Zhang, Kaiqi\\nHuang, Jungong Han, and Guiguang Ding. Re-\\nparameterizing your optimizers rather than architectures.\\narXiv preprint arXiv:2205.15242 , 2022. 2\\n[11] Xiaohan Ding, Yuchen Guo, Guiguang Ding, and Jungong\\nHan. ACNet: Strengthening the kernel skeletons for pow-\\nerful CNN via asymmetric convolution blocks. In Proceed-\\nings of the IEEE/CVF International Conference on Com-\\nputer Vision (ICCV) , pages 1911–1920, 2019. 2\\n[12] Xiaohan Ding, Xiangyu Zhang, Jungong Han, and\\nGuiguang Ding. Diverse branch block: Building a con-\\nvolution as an inception-like unit. In Proceedings of the\\nIEEE/CVF Conference on Computer Vision and Pattern\\nRecognition (CVPR) , pages 10886–10895, 2021. 2\\n[13] Xiaohan Ding, Xiangyu Zhang, Ningning Ma, Jungong\\nHan, Guiguang Ding, and Jian Sun. RepVGG: Making\\nVGG-style convnets great again. In Proceedings of theIEEE/CVF Conference on Computer Vision and Pattern\\nRecognition (CVPR) , pages 13733–13742, 2021. 2, 4\\n[14] Xiaohan Ding, Xiangyu Zhang, Yizhuang Zhou, Jungong\\nHan, Guiguang Ding, and Jian Sun. Scaling up your ker-\\nnels to 31x31: Revisiting large kernel design in CNNs. In\\nProceedings of the IEEE/CVF Conference on Computer Vi-\\nsion and Pattern Recognition (CVPR) , 2022. 2\\n[15] Piotr Doll ´ar, Mannat Singh, and Ross Girshick. Fast and\\naccurate model scaling. In Proceedings of the IEEE/CVF\\nConference on Computer Vision and Pattern Recognition\\n(CVPR) , pages 924–932, 2021. 2, 3\\n[16] Xianzhi Du, Barret Zoph, Wei-Chih Hung, and Tsung-Yi\\nLin. Simple training strategies and model scaling for object\\ndetection. arXiv preprint arXiv:2107.00057 , 2021. 2\\n[17] Chengjian Feng, Yujie Zhong, Yu Gao, Matthew R Scott,\\nand Weilin Huang. TOOD: Task-aligned one-stage object\\ndetection. In Proceedings of the IEEE/CVF International\\nConference on Computer Vision (ICCV) , pages 3490–3499,\\n2021. 2, 5\\n[18] Di Feng, Christian Haase-Sch ¨utz, Lars Rosenbaum, Heinz\\nHertlein, Claudius Glaeser, Fabian Timm, Werner Wies-\\nbeck, and Klaus Dietmayer. Deep multi-modal object de-', metadata={'source': 'pdfs\\\\yolov7paper.pdf', 'page': 11}), Document(page_content='2021. 2, 5\\n[18] Di Feng, Christian Haase-Sch ¨utz, Lars Rosenbaum, Heinz\\nHertlein, Claudius Glaeser, Fabian Timm, Werner Wies-\\nbeck, and Klaus Dietmayer. Deep multi-modal object de-\\ntection and semantic segmentation for autonomous driv-\\ning: Datasets, methods, and challenges. IEEE Transac-\\ntions on Intelligent Transportation Systems , 22(3):1341–\\n1360, 2020. 1\\n[19] Timur Garipov, Pavel Izmailov, Dmitrii Podoprikhin,\\nDmitry P Vetrov, and Andrew G Wilson. Loss sur-\\nfaces, mode connectivity, and fast ensembling of DNNs.\\nAdvances in Neural Information Processing Systems\\n(NeurIPS) , 31, 2018. 2\\n[20] Zheng Ge, Songtao Liu, Zeming Li, Osamu Yoshie, and\\nJian Sun. OTA: Optimal transport assignment for object\\ndetection. In Proceedings of the IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition (CVPR) , pages\\n303–312, 2021. 2, 5\\n[21] Zheng Ge, Songtao Liu, Feng Wang, Zeming Li, and Jian\\nSun. YOLOX: Exceeding YOLO series in 2021. arXiv\\npreprint arXiv:2107.08430 , 2021. 1, 2, 7, 10\\n[22] Golnaz Ghiasi, Tsung-Yi Lin, and Quoc V Le. NAS-FPN:\\nLearning scalable feature pyramid architecture for object\\ndetection. In Proceedings of the IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition (CVPR) , pages\\n7036–7045, 2019. 2\\n[23] Jocher Glenn. YOLOv5 release v6.1. https://github.com/\\nultralytics/yolov5/releases/tag/v6.1, 2022. 2, 7, 10\\n[24] Shuxuan Guo, Jose M Alvarez, and Mathieu Salzmann. Ex-\\npandNets: Linear over-parameterization to train compact\\nconvolutional networks. Advances in Neural Information\\nProcessing Systems (NeurIPS) , 33:1298–1310, 2020. 2\\n[25] Kai Han, Yunhe Wang, Qi Tian, Jianyuan Guo, Chunjing\\nXu, and Chang Xu. GhostNet: More features from cheap\\noperations. In Proceedings of the IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition (CVPR) , pages\\n1580–1589, 2020. 1\\n[26] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.\\nDeep residual learning for image recognition. In Proceed-\\n12', metadata={'source': 'pdfs\\\\yolov7paper.pdf', 'page': 11}), Document(page_content='ings of the IEEE/CVF Conference on Computer Vision and\\nPattern Recognition (CVPR) , pages 770–778, 2016. 1, 4, 5\\n[27] Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh\\nChen, Bo Chen, Mingxing Tan, Weijun Wang, Yukun Zhu,\\nRuoming Pang, Vijay Vasudevan, et al. Searching for Mo-\\nbileNetV3. In Proceedings of the IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition (CVPR) , pages\\n1314–1324, 2019. 1\\n[28] Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry\\nKalenichenko, Weijun Wang, Tobias Weyand, Marco An-\\ndreetto, and Hartwig Adam. MobileNets: Efﬁcient con-\\nvolutional neural networks for mobile vision applications.\\narXiv preprint arXiv:1704.04861 , 2017. 1\\n[29] Mu Hu, Junyi Feng, Jiashen Hua, Baisheng Lai, Jian-\\nqiang Huang, Xiaojin Gong, and Xiansheng Hua. On-\\nline convolutional re-parameterization. In Proceedings of\\nthe IEEE/CVF Conference on Computer Vision and Pattern\\nRecognition (CVPR) , 2022. 2\\n[30] Miao Hu, Yali Li, Lu Fang, and Shengjin Wang. A2-FPN:\\nAttention aggregation based feature pyramid network for\\ninstance segmentation. In Proceedings of the IEEE/CVF\\nConference on Computer Vision and Pattern Recognition\\n(CVPR) , pages 15343–15352, 2021. 2\\n[31] Gao Huang, Yixuan Li, Geoff Pleiss, Zhuang Liu, John E\\nHopcroft, and Kilian Q Weinberger. Snapshot ensembles:\\nTrain 1, get m for free. International Conference on Learn-\\ning Representations (ICLR) , 2017. 2\\n[32] Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kil-\\nian Q Weinberger. Densely connected convolutional net-\\nworks. In Proceedings of the IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition (CVPR) , pages\\n4700–4708, 2017. 2, 4, 5\\n[33] Pavel Izmailov, Dmitrii Podoprikhin, Timur Garipov,\\nDmitry Vetrov, and Andrew Gordon Wilson. Averaging\\nweights leads to wider optima and better generalization. In\\nConference on Uncertainty in Artiﬁcial Intelligence (UAI) ,\\n2018. 2\\n[34] Paul F Jaeger, Simon AA Kohl, Sebastian Bickel-\\nhaupt, Fabian Isensee, Tristan Anselm Kuder, Heinz-Peter\\nSchlemmer, and Klaus H Maier-Hein. Retina U-Net: Em-\\nbarrassingly simple exploitation of segmentation supervi-\\nsion for medical object detection. In Machine Learning for\\nHealth Workshop , pages 171–183, 2020. 1\\n[35] Hakan Karaoguz and Patric Jensfelt. Object detection ap-\\nproach for robot grasp detection. In IEEE International\\nConference on Robotics and Automation (ICRA) , pages\\n4953–4959, 2019. 1\\n[36] Kang Kim and Hee Seok Lee. Probabilistic anchor as-\\nsignment with iou prediction for object detection. In Pro-\\nceedings of the European conference on computer vision\\n(ECCV) , pages 355–371, 2020. 5\\n[37] Alexander Kirillov, Ross Girshick, Kaiming He, and Piotr\\nDoll´ar. Panoptic feature pyramid networks. In Proceed-\\nings of the IEEE/CVF Conference on Computer Vision and\\nPattern Recognition (CVPR) , pages 6399–6408, 2019. 2\\n[38] Chen-Yu Lee, Saining Xie, Patrick Gallagher, Zhengyou\\nZhang, and Zhuowen Tu. Deeply-supervised nets. In Arti-\\nﬁcial Intelligence and Statistics , pages 562–570, 2015. 5[39] Youngwan Lee, Joong-won Hwang, Sangrok Lee, Yuseok\\nBae, and Jongyoul Park. An energy and GPU-computation\\nefﬁcient backbone network for real-time object detection.\\nInProceedings of the IEEE/CVF Conference on Com-\\nputer Vision and Pattern Recognition Workshops (CVPRW) ,\\npages 0–0, 2019. 2, 3\\n[40] Buyu Li, Wanli Ouyang, Lu Sheng, Xingyu Zeng, and\\nXiaogang Wang. GS3D: An efﬁcient 3d object detection\\nframework for autonomous driving. In Proceedings of the\\nIEEE/CVF Conference on Computer Vision and Pattern\\nRecognition (CVPR) , pages 1019–1028, 2019. 1\\n[41] Feng Li, Hao Zhang, Shilong Liu, Jian Guo, Lionel M\\nNi, and Lei Zhang. DN-DETR: Accelerate detr training\\nby introducing query denoising. In Proceedings of the\\nIEEE/CVF Conference on Computer Vision and Pattern\\nRecognition (CVPR) , pages 13619–13627, 2022. 10\\n[42] Shuai Li, Chenhang He, Ruihuang Li, and Lei Zhang. A\\ndual weighting label assignment scheme for object detec-\\ntion. In Proceedings of the IEEE/CVF Conference on Com-', metadata={'source': 'pdfs\\\\yolov7paper.pdf', 'page': 12}), Document(page_content='[42] Shuai Li, Chenhang He, Ruihuang Li, and Lei Zhang. A\\ndual weighting label assignment scheme for object detec-\\ntion. In Proceedings of the IEEE/CVF Conference on Com-\\nputer Vision and Pattern Recognition (CVPR) , pages 9387–\\n9396, 2022. 2, 5\\n[43] Xiang Li, Wenhai Wang, Xiaolin Hu, Jun Li, Jinhui Tang,\\nand Jian Yang. Generalized focal loss v2: Learning reliable\\nlocalization quality estimation for dense object detection. In\\nProceedings of the IEEE/CVF Conference on Computer Vi-\\nsion and Pattern Recognition (CVPR) , pages 11632–11641,\\n2021. 5\\n[44] Xiang Li, Wenhai Wang, Lijun Wu, Shuo Chen, Xiaolin\\nHu, Jun Li, Jinhui Tang, and Jian Yang. Generalized focal\\nloss: Learning qualiﬁed and distributed bounding boxes for\\ndense object detection. Advances in Neural Information\\nProcessing Systems (NeurIPS) , 33:21002–21012, 2020. 5\\n[45] Yanghao Li, Hanzi Mao, Ross Girshick, and Kaiming He.\\nExploring plain vision transformer backbones for object de-\\ntection. arXiv preprint arXiv:2203.16527 , 2022. 2\\n[46] Zhuoling Li, Minghui Dong, Shiping Wen, Xiang Hu, Pan\\nZhou, and Zhigang Zeng. CLU-CNNs: Object detection for\\nmedical images. Neurocomputing , 350:53–59, 2019. 1\\n[47] Tingting Liang, Xiaojie Chu, Yudong Liu, Yongtao Wang,\\nZhi Tang, Wei Chu, Jingdong Chen, and Haibin Ling. CB-\\nNetV2: A composite backbone network architecture for ob-\\nject detection. arXiv preprint arXiv:2107.00420 , 2021. 5,\\n10\\n[48] Ji Lin, Wei-Ming Chen, Han Cai, Chuang Gan, and Song\\nHan. Memory-efﬁcient patch-based inference for tiny deep\\nlearning. Advances in Neural Information Processing Sys-\\ntems (NeurIPS) , 34:2346–2358, 2021. 1\\n[49] Ji Lin, Wei-Ming Chen, Yujun Lin, Chuang Gan, Song\\nHan, et al. MCUNet: Tiny deep learning on IoT de-\\nvices. Advances in Neural Information Processing Systems\\n(NeurIPS) , 33:11711–11722, 2020. 1\\n[50] Yuxuan Liu, Lujia Wang, and Ming Liu. YOLOStereo3D:\\nA step back to 2D for efﬁcient stereo 3D detection. In\\nIEEE International Conference on Robotics and Automa-\\ntion (ICRA) , pages 13018–13024, 2021. 5\\n[51] Ze Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie,\\nYixuan Wei, Jia Ning, Yue Cao, Zheng Zhang, Li Dong,\\n13', metadata={'source': 'pdfs\\\\yolov7paper.pdf', 'page': 12}), Document(page_content='et al. Swin transformer v2: Scaling up capacity and res-\\nolution. In Proceedings of the IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition (CVPR) , 2022. 2\\n[52] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng\\nZhang, Stephen Lin, and Baining Guo. Swin transformer:\\nHierarchical vision transformer using shifted windows. In\\nProceedings of the IEEE/CVF International Conference on\\nComputer Vision (ICCV) , pages 10012–10022, 2021. 10\\n[53] Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feicht-\\nenhofer, Trevor Darrell, and Saining Xie. A ConvNet for\\nthe 2020s. In Proceedings of the IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition (CVPR) , pages\\n11976–11986, 2022. 10\\n[54] Rangi Lyu. NanoDet-Plus. https://github.com/RangiLyu/\\nnanodet/releases/tag/v1.0.0-alpha-1, 2021. 1, 2\\n[55] Ningning Ma, Xiangyu Zhang, Hai-Tao Zheng, and Jian\\nSun. ShufﬂeNet V2: Practical guidelines for efﬁcient CNN\\narchitecture design. In Proceedings of the European Con-\\nference on Computer Vision (ECCV) , pages 116–131, 2018.\\n1, 3\\n[56] Kemal Oksuz, Baris Can Cam, Emre Akbas, and Sinan\\nKalkan. A ranking-based, balanced loss function unifying\\nclassiﬁcation and localisation in object detection. Advances\\nin Neural Information Processing Systems (NeurIPS) ,\\n33:15534–15545, 2020. 2\\n[57] Kemal Oksuz, Baris Can Cam, Emre Akbas, and Sinan\\nKalkan. Rank & sort loss for object detection and in-\\nstance segmentation. In Proceedings of the IEEE/CVF In-\\nternational Conference on Computer Vision (ICCV) , pages\\n3009–3018, 2021. 2\\n[58] Shuvo Kumar Paul, Muhammed Tawﬁq Chowdhury,\\nMircea Nicolescu, Monica Nicolescu, and David Feil-\\nSeifer. Object detection and pose estimation from rgb and\\ndepth data for real-time, adaptive robotic grasping. In Ad-\\nvances in Computer Vision and Computational Biology ,\\npages 121–142. 2021. 1\\n[59] Siyuan Qiao, Liang-Chieh Chen, and Alan Yuille. De-\\ntectoRS: Detecting objects with recursive feature pyramid\\nand switchable atrous convolution. In Proceedings of the\\nIEEE/CVF Conference on Computer Vision and Pattern\\nRecognition (CVPR) , pages 10213–10224, 2021. 2\\n[60] Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick,\\nKaiming He, and Piotr Doll ´ar. Designing network design\\nspaces. In Proceedings of the IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition (CVPR) , pages\\n10428–10436, 2020. 2\\n[61] Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali\\nFarhadi. You only look once: Uniﬁed, real-time object de-\\ntection. In Proceedings of the IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition (CVPR) , pages\\n779–788, 2016. 2, 5\\n[62] Joseph Redmon and Ali Farhadi. YOLO9000: better, faster,\\nstronger. In Proceedings of the IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition (CVPR) , pages\\n7263–7271, 2017. 2\\n[63] Joseph Redmon and Ali Farhadi. YOLOv3: An incremental\\nimprovement. arXiv preprint arXiv:1804.02767 , 2018. 1, 2[64] Hamid Rezatoﬁghi, Nathan Tsoi, JunYoung Gwak, Amir\\nSadeghian, Ian Reid, and Silvio Savarese. Generalized in-\\ntersection over union: A metric and a loss for bounding\\nbox regression. In Proceedings of the IEEE/CVF Confer-\\nence on Computer Vision and Pattern Recognition (CVPR) ,\\npages 658–666, 2019. 2\\n[65] Byungseok Roh, JaeWoong Shin, Wuhyun Shin, and\\nSaehoon Kim. Sparse DETR: Efﬁcient end-to-end ob-\\nject detection with learnable sparsity. arXiv preprint\\narXiv:2111.14330 , 2021. 5\\n[66] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey\\nZhmoginov, and Liang-Chieh Chen. MobileNetV2: In-\\nverted residuals and linear bottlenecks. In Proceedings of\\nthe IEEE/CVF Conference on Computer Vision and Pattern\\nRecognition (CVPR) , pages 4510–4520, 2018. 1\\n[67] Zhiqiang Shen, Zhuang Liu, Jianguo Li, Yu-Gang Jiang,\\nYurong Chen, and Xiangyang Xue. Object detection\\nfrom scratch with deep supervision. IEEE Transactions\\non Pattern Analysis and Machine Intelligence (TPAMI) ,\\n42(2):398–412, 2019. 5\\n[68] Karen Simonyan and Andrew Zisserman. Very deep convo-', metadata={'source': 'pdfs\\\\yolov7paper.pdf', 'page': 13}), Document(page_content='from scratch with deep supervision. IEEE Transactions\\non Pattern Analysis and Machine Intelligence (TPAMI) ,\\n42(2):398–412, 2019. 5\\n[68] Karen Simonyan and Andrew Zisserman. Very deep convo-\\nlutional networks for large-scale image recognition. arXiv\\npreprint arXiv:1409.1556 , 2014. 4\\n[69] Peize Sun, Rufeng Zhang, Yi Jiang, Tao Kong, Chenfeng\\nXu, Wei Zhan, Masayoshi Tomizuka, Lei Li, Zehuan Yuan,\\nChanghu Wang, et al. Sparse R-CNN: End-to-end ob-\\nject detection with learnable proposals. In Proceedings of\\nthe IEEE/CVF Conference on Computer Vision and Pattern\\nRecognition (CVPR) , pages 14454–14463, 2021. 2\\n[70] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet,\\nScott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent\\nVanhoucke, and Andrew Rabinovich. Going deeper with\\nconvolutions. In Proceedings of the IEEE/CVF Confer-\\nence on Computer Vision and Pattern Recognition (CVPR) ,\\npages 1–9, 2015. 5\\n[71] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon\\nShlens, and Zbigniew Wojna. Rethinking the inception\\narchitecture for computer vision. In Proceedings of the\\nIEEE/CVF Conference on Computer Vision and Pattern\\nRecognition (CVPR) , pages 2818–2826, 2016. 2\\n[72] Mingxing Tan and Quoc Le. EfﬁcientNet: Rethinking\\nmodel scaling for convolutional neural networks. In Inter-\\nnational Conference on Machine Learning (ICML) , pages\\n6105–6114, 2019. 2, 3\\n[73] Mingxing Tan and Quoc Le. EfﬁcientNetv2: Smaller mod-\\nels and faster training. In International Conference on Ma-\\nchine Learning (ICML) , pages 10096–10106, 2021. 2\\n[74] Mingxing Tan, Ruoming Pang, and Quoc V Le. Efﬁcient-\\nDet: Scalable and efﬁcient object detection. In Proceedings\\nof the IEEE/CVF Conference on Computer Vision and Pat-\\ntern Recognition (CVPR) , pages 10781–10790, 2020. 2, 10\\n[75] Antti Tarvainen and Harri Valpola. Mean teachers are better\\nrole models: Weight-averaged consistency targets improve\\nsemi-supervised deep learning results. Advances in Neural\\nInformation Processing Systems (NeurIPS) , 30, 2017. 2, 6\\n[76] Zhi Tian, Chunhua Shen, Hao Chen, and Tong He. FCOS:\\nFully convolutional one-stage object detection. In Proceed-\\n14', metadata={'source': 'pdfs\\\\yolov7paper.pdf', 'page': 13}), Document(page_content='ings of the IEEE/CVF International Conference on Com-\\nputer Vision (ICCV) , pages 9627–9636, 2019. 2\\n[77] Zhi Tian, Chunhua Shen, Hao Chen, and Tong He. FCOS:\\nA simple and strong anchor-free object detector. IEEE\\nTransactions on Pattern Analysis and Machine Intelligence\\n(TPAMI) , 44(4):1922–1933, 2022. 2\\n[78] Pavan Kumar Anasosalu Vasu, James Gabriel, Jeff\\nZhu, Oncel Tuzel, and Anurag Ranjan. An im-\\nproved one millisecond mobile backbone. arXiv preprint\\narXiv:2206.04040 , 2022. 2\\n[79] Chien-Yao Wang, Alexey Bochkovskiy, and Hong-\\nYuan Mark Liao. Scaled-YOLOv4: Scaling cross stage\\npartial network. In Proceedings of the IEEE/CVF Confer-\\nence on Computer Vision and Pattern Recognition (CVPR) ,\\npages 13029–13038, 2021. 2, 3, 6, 7\\n[80] Chien-Yao Wang, Hong-Yuan Mark Liao, Yueh-Hua Wu,\\nPing-Yang Chen, Jun-Wei Hsieh, and I-Hau Yeh. CSP-\\nNet: A new backbone that can enhance learning capabil-\\nity of CNN. In Proceedings of the IEEE/CVF Conference\\non Computer Vision and Pattern Recognition Workshops\\n(CVPRW) , pages 390–391, 2020. 1\\n[81] Chien-Yao Wang, I-Hau Yeh, and Hong-Yuan Mark Liao.\\nYou only learn one representation: Uniﬁed network for\\nmultiple tasks. arXiv preprint arXiv:2105.04206 , 2021. 1,\\n2, 6, 7, 10\\n[82] Jianfeng Wang, Lin Song, Zeming Li, Hongbin Sun, Jian\\nSun, and Nanning Zheng. End-to-end object detection\\nwith fully convolutional network. In Proceedings of the\\nIEEE/CVF Conference on Computer Vision and Pattern\\nRecognition (CVPR) , pages 15849–15858, 2021. 2, 5\\n[83] Bichen Wu, Chaojian Li, Hang Zhang, Xiaoliang Dai,\\nPeizhao Zhang, Matthew Yu, Jialiang Wang, Yingyan Lin,\\nand Peter Vajda. FBNetv5: Neural architecture search for\\nmultiple tasks in one run. arXiv preprint arXiv:2111.10007 ,\\n2021. 1\\n[84] Yunyang Xiong, Hanxiao Liu, Suyog Gupta, Berkin Akin,\\nGabriel Bender, Yongzhe Wang, Pieter-Jan Kindermans,\\nMingxing Tan, Vikas Singh, and Bo Chen. MobileDets:\\nSearching for object detection architectures for mobile ac-\\ncelerators. In Proceedings of the IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition (CVPR) , pages\\n3825–3834, 2021. 1\\n[85] Shangliang Xu, Xinxin Wang, Wenyu Lv, Qinyao\\nChang, Cheng Cui, Kaipeng Deng, Guanzhong Wang,\\nQingqing Dang, Shengyu Wei, Yuning Du, et al. PP-\\nYOLOE: An evolved version of YOLO. arXiv preprint\\narXiv:2203.16250 , 2022. 2, 7, 8, 10\\n[86] Zetong Yang, Yin Zhou, Zhifeng Chen, and Jiquan Ngiam.\\n3D-MAN: 3D multi-frame attention network for object de-\\ntection. In Proceedings of the IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition (CVPR) , pages\\n1863–1872, 2021. 5\\n[87] Fisher Yu, Dequan Wang, Evan Shelhamer, and Trevor\\nDarrell. Deep layer aggregation. In Proceedings of the\\nIEEE/CVF Conference on Computer Vision and Pattern\\nRecognition (CVPR) , pages 2403–2412, 2018. 1\\n[88] Guanghua Yu, Qinyao Chang, Wenyu Lv, Chang Xu, Cheng\\nCui, Wei Ji, Qingqing Dang, Kaipeng Deng, GuanzhongWang, Yuning Du, et al. PP-PicoDet: A better real-\\ntime object detector on mobile devices. arXiv preprint\\narXiv:2111.00902 , 2021. 1\\n[89] Hao Zhang, Feng Li, Shilong Liu, Lei Zhang, Hang Su, Jun\\nZhu, Lionel M Ni, and Heung-Yeung Shum. DINO: DETR\\nwith improved denoising anchor boxes for end-to-end ob-\\nject detection. arXiv preprint arXiv:2203.03605 , 2022. 10\\n[90] Haoyang Zhang, Ying Wang, Feras Dayoub, and Niko Sun-\\nderhauf. VarifocalNet: An IoU-aware dense object detector.\\nInProceedings of the IEEE/CVF Conference on Computer\\nVision and Pattern Recognition (CVPR) , pages 8514–8523,\\n2021. 5\\n[91] Shifeng Zhang, Cheng Chi, Yongqiang Yao, Zhen Lei, and\\nStan Z Li. Bridging the gap between anchor-based and\\nanchor-free detection via adaptive training sample selec-\\ntion. In Proceedings of the IEEE/CVF Conference on Com-\\nputer Vision and Pattern Recognition (CVPR) , pages 9759–\\n9768, 2020. 5\\n[92] Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, and Jian\\nSun. ShufﬂeNet: An extremely efﬁcient convolutional neu-\\nral network for mobile devices. In Proceedings of the\\nIEEE/CVF Conference on Computer Vision and Pattern', metadata={'source': 'pdfs\\\\yolov7paper.pdf', 'page': 14}), Document(page_content='Sun. ShufﬂeNet: An extremely efﬁcient convolutional neu-\\nral network for mobile devices. In Proceedings of the\\nIEEE/CVF Conference on Computer Vision and Pattern\\nRecognition (CVPR) , pages 6848–6856, 2018. 1\\n[93] Yifu Zhang, Peize Sun, Yi Jiang, Dongdong Yu, Zehuan\\nYuan, Ping Luo, Wenyu Liu, and Xinggang Wang. BYTE-\\nTrack: Multi-object tracking by associating every detection\\nbox. arXiv preprint arXiv:2110.06864 , 2021. 1\\n[94] Yifu Zhang, Chunyu Wang, Xinggang Wang, Wenjun Zeng,\\nand Wenyu Liu. FAIRMOT: On the fairness of detec-\\ntion and re-identiﬁcation in multiple object tracking. Inter-\\nnational Journal of Computer Vision , 129(11):3069–3087,\\n2021. 1\\n[95] Zhaohui Zheng, Ping Wang, Wei Liu, Jinze Li, Rongguang\\nYe, and Dongwei Ren. Distance-IoU loss: Faster and bet-\\nter learning for bounding box regression. In Proceedings\\nof the AAAI Conference on Artiﬁcial Intelligence (AAAI) ,\\nvolume 34, pages 12993–13000, 2020. 2\\n[96] Dingfu Zhou, Jin Fang, Xibin Song, Chenye Guan, Junbo\\nYin, Yuchao Dai, and Ruigang Yang. IoU loss for 2D/3D\\nobject detection. In International Conference on 3D Vision\\n(3DV) , pages 85–94, 2019. 2\\n[97] Xingyi Zhou, Dequan Wang, and Philipp Kr ¨ahenb ¨uhl. Ob-\\njects as points. arXiv preprint arXiv:1904.07850 , 2019. 1,\\n2\\n[98] Zongwei Zhou, Md Mahfuzur Rahman Siddiquee, Nima\\nTajbakhsh, and Jianming Liang. UNet++: A nested U-\\nNet architecture for medical image segmentation. In\\nDeep Learning in Medical Image Analysis and Multimodal\\nLearning for Clinical Decision Support , 2018. 5\\n[99] Benjin Zhu, Jianfeng Wang, Zhengkai Jiang, Fuhang Zong,\\nSongtao Liu, Zeming Li, and Jian Sun. AutoAssign: Differ-\\nentiable label assignment for dense object detection. arXiv\\npreprint arXiv:2007.03496 , 2020. 2, 5\\n[100] Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang,\\nand Jifeng Dai. Deformable DETR: Deformable trans-\\nformers for end-to-end object detection. In Proceedings of\\nthe International Conference on Learning Representations\\n(ICLR) , 2021. 10\\n15', metadata={'source': 'pdfs\\\\yolov7paper.pdf', 'page': 14})]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b. The overall design of the DB is called the DB schema.\n",
      "c. Schema is structural  description of data. Schema doesn’t change frequently. Data may change\n",
      "frequently.\n",
      "d. DB schema  corresponds to the variable declarations (along with type) in a program.\n",
      "e. We have 3 types of Schemas: Physical, Logical , several view schemas  called subschemas.\n",
      "f. Logical schema is most important in terms of its effect on application programs , as programmers\n",
      "construct apps by using logical schema.\n",
      "g. Physical data independence , physical schema change should not affect logica l\n",
      "sch\n",
      "ema/application programs.\n",
      "3. Data Models:\n",
      "a. Provides a way to describe the design of a DB at logical level.\n",
      "b. Underlying the structure of the DB is the Data Model; a collection of conceptual tools for describing\n",
      "data, data relationships, data semantics & consistency constraints .\n",
      "c. E.g., ER model, Relational  Model, object -oriented model, object -relational  data model etc.\n",
      "4. Database  Languages:\n",
      "a. Data definition language  (DDL) to specify the database schema.\n",
      "b. Data manipulation language  (DML)  to express database queries and updates.\n",
      "c. Practically , both language features are present in a single DB language, e.g., SQL language.\n",
      "d. DDL\n",
      "i.We specify consistency constraints, which must be checked, every time DB is updated.\n",
      "e. DML\n",
      "i.Data manipulation involves\n",
      "1. Retrieval  of information stored in DB.\n",
      "2. Insertion  of new information into DB.\n",
      "3. Deletion of information from the DB.\n",
      "4. Updating  existing information stored in DB.\n",
      "ii.Query language , a part of DML to specify statement requesting the retrieval of\n",
      "information.\n",
      "5. How is Database accessed from Application programs?\n",
      "a. Apps (written in host languages, C/C++, Java) interacts with DB.\n",
      "b. E.g., Banking system’s module generating payrolls access DB by executing DML statements from\n",
      "the host language.\n",
      "c. API is provided to send DML/DDL statements to DB and retrieve the results.\n",
      "i.Open Database Connectivity ( ODBC), Microsoft “C”.\n",
      "ii.Java Database Connectivity ( JDBC ), Java.\n",
      "6. Database Administrator (DBA)\n",
      "a. A person who has central control of both the data and the programs that access those data.\n",
      "b. Functions  of DBA\n",
      "i.Schema Definition\n",
      "ii.Storage structure and access methods .\n",
      "iii. Schema and physical organization modifications.\n",
      "iv. Authorization control.\n",
      "v.Routine maintenance\n",
      "1. Periodic backups.\n",
      "2. Security patches.\n",
      "3. Any upgrades.\n",
      "7. DBMS  Application  Architectures: Client machines, on which remote DB users work, and server machines\n",
      "on which DB system runs.\n",
      "a. T1 Architecture\n",
      "i.The client, server & DB all present on the same machine.\n",
      "CodeHelp\n"
     ]
    }
   ],
   "source": [
    "print(data[3].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\\n\".join(str(p.page_content) for p in data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of words in the context: 162125\n"
     ]
    }
   ],
   "source": [
    "print(\"The total number of words in the context:\", len(context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=200)\n",
    "context = \"\\n\\n\".join(str(p.page_content) for p in data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "texts = text_splitter.split_text(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LEC-1: Introduction to DBMS \\n1. What is Data?\\na. Data is a collection of raw, unorganized facts and details like text, observations, figures, symbols,\\nand descriptions of things etc.In other words, data does not carry any specific purpose and has no significance by itself.\\nMoreover, data is measured in terms of bits and bytes – which are basic units of information in the\\ncontext of computer storage and processing.\\nb. Data can be recorded and doesn’t have any meaning unless processed.\\n2. Types of Data\\na. Quanti tative\\ni.Numerical form\\nii.Weight, volume, cost of an item.\\nb. Qualitative\\ni.Descriptive, but not numerical.\\nii.Name, gender, hair color of a person.\\n3. What is Information?\\na. Info. Is processed, organized, and structured data.\\nb. It provides context of the data and enables decision making.\\nc. Processed data that make sense to us.\\nd. Information is extracted from the data, by analyzing and interpreti ng pieces of data.\\ne. E.g., you have data of all the people living in your locality, its Data, when you analyze and i\\nnterpret\\nth\\ne data and come to some conclusion that:\\ni.There are 100 senior citizens.\\nii.The sex ratio is 1.1.\\niii. Newborn babies are 100.These are information.\\n4. Data vs Information\\na. Data is a collection of facts, while information puts those facts into context.\\nb. While data is raw and unorganized, information is organized.\\nc. Data points are individual and sometimes unrelated. Information maps out that data to provide abig-picture view of how it all fits together.\\nd. Data, on its own, is meaningless. When it’s analyzed and interpreted, it becomes meaningfulinformation\\n.\\ne. Da\\nta does not depend on information; however, information depends on data.\\nf. Data typically comes in the f orm of graphs, numbers, figures, or statistics. Information is typicall y\\npr\\nesented through words, language, thoughts, and ideas.\\ng. Data isn’t sufficient for decision-making , but you can make decisions based on information.\\n5. What is Database ?\\na. Database is an electronic place/system where data is stored in a way that it can be  easily accessed,\\nmanaged,  and updated.\\nb. To make real use Data, we need Database management system s. (DBMS)\\n6. What is DBMS ?\\na. A database -management system (DBMS) is a collection of interrelated data  and a set of\\nprograms to access those data . The collection of data, usually referred to as the database ,\\ncontai\\nns information relevant to an enterprise. The primary goal of a DBMS is to provide a way to\\nstore and retrieve database  information  that is both convenient and efficient.\\nb. A DBMS is the database itself, along with all the software and functionality. It is used to perform\\ndifferent operations, like addition , access , updating, an d deletion  of the data.\\nCodeHelp\\n\\n7. \\n8. DBMS vs File Systems\\na. File-processing systems  has major disadvantages .\\ni.Data Redundancy and inconsistency\\nii.Difficulty in accessing data\\niii. Data isolation\\niv. Integrity problems\\nv.Atomicity problems\\nvi. Concurrent -access anomalies\\nvii. Security problems\\nb. Above 7 are also the Advantages of DBMS  (answer to “ Why to use DBMS? ”)\\nCodeHelp\\n\\nLEC-2: DBMS Architecture \\n1. View of Data  (Three Schema Architecture)\\na. The major purpose of DBMS is to provide users with an abstract view  of the data. That is, t he\\nsystem hides certain details of how the data is stored and maintained.\\nb. To \\nsimplify user interaction with the system, abstraction is applied through several levels of\\nabstraction.\\nc. The main objective  of three level architecture is to enable multiple users to access the same dat a\\nwith a personalized view while storing the underlying data only once\\nd. Phys\\nical level / Internal level\\ni.The lowest level of abstraction describes how the data are stored.\\nii.Low -level data structures used.\\niii. It has Physical  schema which describes physical storage structure of DB.\\niv. Talks about: Storage allocation (N -ary tree etc), Data compression & encryption etc.\\nv.Goal : We must define algorithms that allow efficient access to data.\\ne. Logical level / Conceptual level:\\ni.The conceptual schema  describes the design of a database at the conceptual leve l,\\ndescribes wh at data are stored in DB, and what relationships  exist among those data.\\nii.User at logical level does not need to be aware about physical -level structures.\\niii. DBA, who must decide what information to keep in the DB use the logical level of\\nabstraction.\\niv\\n.Goal : ease to use.\\nf. View level / External level:\\ni.Highest level of abstraction aims to simplify users’ interaction with the system by\\nproviding different view to different end- user.\\nii.Each view schema  describes the database part that a particular user group is interest ed\\nand hides the remaining database fro m that user group.\\niii. At the external level, a database contains several schemas that sometimes called as\\nsubschema. The subschema is used to describe the different view of the database.\\niv. At views also provide a security mechanism to prevent users from accessing certain parts\\nof DB.\\ng. \\n2. Instances and Schemas\\na. The collection of information stored in the DB at a particular moment is called an instance of DB.\\nCodeHelp\\n\\nb. The overall design of the DB is called the DB schema.\\nc. Schema is structural  description of data. Schema doesn’t change frequently. Data may change\\nfrequently.\\nd. DB schema  corresponds to the variable declarations (along with type) in a program.\\ne. We have 3 types of Schemas: Physical, Logical , several view schemas  called subschemas.\\nf. Logical schema is most important in terms of its effect on application programs , as programmers\\nconstruct apps by using logical schema.\\ng. Physical data independence , physical schema change should not affect logica l\\nsch\\nema/application programs.\\n3. Data Models:\\na. Provides a way to describe the design of a DB at logical level.\\nb. Underlying the structure of the DB is the Data Model; a collection of conceptual tools for describing\\ndata, data relationships, data semantics & consistency constraints .\\nc. E.g., ER model, Relational  Model, object -oriented model, object -relational  data model etc.\\n4. Database  Languages:\\na. Data definition language  (DDL) to specify the database schema.\\nb. Data manipulation language  (DML)  to express database queries and updates.\\nc. Practically , both language features are present in a single DB language, e.g., SQL language.\\nd. DDL\\ni.We specify consistency constraints, which must be checked, every time DB is updated.\\ne. DML\\ni.Data manipulation involves\\n1. Retrieval  of information stored in DB.\\n2. Insertion  of new information into DB.\\n3. Deletion of information from the DB.\\n4. Updating  existing information stored in DB.\\nii.Query language , a part of DML to specify statement requesting the retrieval of\\ninformation.\\n5. How is Database accessed from Application programs?\\na. Apps (written in host languages, C/C++, Java) interacts with DB.\\nb. E.g., Banking system’s module generating payrolls access DB by executing DML statements from\\nthe host language.\\nc. API is provided to send DML/DDL statements to DB and retrieve the results.\\ni.Open Database Connectivity ( ODBC), Microsoft “C”.\\nii.Java Database Connectivity ( JDBC ), Java.\\n6. Database Administrator (DBA)\\na. A person who has central control of both the data and the programs that access those data.\\nb. Functions  of DBA\\ni.Schema Definition\\nii.Storage structure and access methods .\\niii. Schema and physical organization modifications.\\niv. Authorization control.\\nv.Routine maintenance\\n1. Periodic backups.\\n2. Security patches.\\n3. Any upgrades.\\n7. DBMS  Application  Architectures: Client machines, on which remote DB users work, and server machines\\non which DB system runs.\\na. T1 Architecture\\ni.The client, server & DB all present on the same machine.\\nCodeHelp\\n\\nb. T2 Architecture\\ni.App is partitioned into 2 -components.\\nii.Client machine, which invokes DB system functionality at server end through que ry\\nla\\nnguage statements.\\niii. API standards  like ODBC & JDBC  are used to interact between client and server.\\nc. T3 Architecture\\ni.App is partitioned into 3 logical components.\\nii.Client machine is just a frontend and doesn’t contain any direct DB calls.\\niii. Client machine  communicates with App server, and App server communicated with DB\\nsystem to access data.\\niv. Business logic, what action to take at that condition is in App server itself.\\nv.T3 architecture are best for WWW Applications.\\nvi. Advantages :\\n1. Scalability  due to distributed application servers.\\n2. Data integrity, App server acts as a middle layer between client and DB, which\\nminimize the chances of data corruption .\\n3. Security , client can’t directly access DB, hence it is more secure.\\nCodeHelp'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = Chroma.from_texts(texts, embeddings).as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaide\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "question = \" what is Planned re-parameterized convolution? \"\n",
    "docs = vector_index.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Figure 2: Extended efﬁcient layer aggregation networks. The proposed extended ELAN (E-ELAN) does not change the gradient transmis-\\nsion path of the original architecture at all, but use group convolution to increase the cardinality of the added features, and combine the\\nfeatures of different groups in a shufﬂe and merge cardinality manner. This way of operation can enhance the features learned by different\\nfeature maps and improve the use of parameters and calculations.\\n3. Architecture\\n3.1. Extended efﬁcient layer aggregation networks\\nIn most of the literature on designing the efﬁcient ar-\\nchitectures, the main considerations are no more than the\\nnumber of parameters, the amount of computation, and the\\ncomputational density. Starting from the characteristics of\\nmemory access cost, Ma et al. [55] also analyzed the in-\\nﬂuence of the input/output channel ratio, the number of\\nbranches of the architecture, and the element-wise opera-\\ntion on the network inference speed. Doll ´aret al. [15] addi-\\ntionally considered activation when performing model scal-\\ning, that is, to put more consideration on the number of el-\\nements in the output tensors of convolutional layers. The\\ndesign of CSPV oVNet [79] in Figure 2 (b) is a variation of\\nV oVNet [39]. In addition to considering the aforementioned\\nbasic designing concerns, the architecture of CSPV oVNet\\n[79] also analyzes the gradient path, in order to enable the\\nweights of different layers to learn more diverse features.\\nThe gradient analysis approach described above makes in-\\nferences faster and more accurate. ELAN [1] in Figure 2 (c)\\nconsiders the following design strategy – “How to design an\\nefﬁcient network?.” They came out with a conclusion: By\\ncontrolling the shortest longest gradient path, a deeper net-\\nwork can learn and converge effectively. In this paper, we\\npropose Extended-ELAN (E-ELAN) based on ELAN and\\nits main architecture is shown in Figure 2 (d).\\nRegardless of the gradient path length and the stacking\\nnumber of computational blocks in large-scale ELAN, it has\\nreached a stable state. If more computational blocks are\\nstacked unlimitedly, this stable state may be destroyed, and\\nthe parameter utilization rate will decrease. The proposedE-ELAN uses expand, shufﬂe, merge cardinality to achieve\\nthe ability to continuously enhance the learning ability of\\nthe network without destroying the original gradient path.\\nIn terms of architecture, E-ELAN only changes the archi-\\ntecture in computational block, while the architecture of\\ntransition layer is completely unchanged. Our strategy is\\nto use group convolution to expand the channel and car-\\ndinality of computational blocks. We will apply the same\\ngroup parameter and channel multiplier to all the compu-\\ntational blocks of a computational layer. Then, the feature\\nmap calculated by each computational block will be shuf-\\nﬂed into ggroups according to the set group parameter g,\\nand then concatenate them together. At this time, the num-\\nber of channels in each group of feature map will be the\\nsame as the number of channels in the original architec-\\nture. Finally, we add ggroups of feature maps to perform\\nmerge cardinality. In addition to maintaining the original\\nELAN design architecture, E-ELAN can also guide differ-\\nent groups of computational blocks to learn more diverse\\nfeatures.\\n3.2. Model scaling for concatenation-based models\\nThe main purpose of model scaling is to adjust some at-\\ntributes of the model and generate models of different scales\\nto meet the needs of different inference speeds. For ex-\\nample the scaling model of EfﬁcientNet [72] considers the\\nwidth, depth, and resolution. As for the scaled-YOLOv4\\n[79], its scaling model is to adjust the number of stages. In\\n[15], Doll ´aret al. analyzed the inﬂuence of vanilla convolu-\\ntion and group convolution on the amount of parameter and\\ncomputation when performing width and depth scaling, and\\nused this to design the corresponding model scaling method.\\n3\\n\\nFigure 3: Model scaling for concatenation-based models. From (a) to (b), we observe that when depth scaling is performed on\\nconcatenation-based models, the output width of a computational block also increases. This phenomenon will cause the input width\\nof the subsequent transmission layer to increase. Therefore, we propose (c), that is, when performing model scaling on concatenation-\\nbased models, only the depth in a computational block needs to be scaled, and the remaining of transmission layer is performed with\\ncorresponding width scaling.\\nThe above methods are mainly used in architectures such as\\nPlainNet or ResNet. When these architectures are in execut-\\ning scaling up or scaling down, the in-degree and out-degree\\nof each layer will not change, so we can independently an-\\nalyze the impact of each scaling factor on the amount of\\nparameters and computation. However, if these methods\\nare applied to the concatenation-based architecture, we will\\nﬁnd that when scaling up or scaling down is performed on\\ndepth, the in-degree of a translation layer which is immedi-\\nately after a concatenation-based computational block will\\ndecrease or increase, as shown in Figure 3 (a) and (b).\\nIt can be inferred from the above phenomenon that\\nwe cannot analyze different scaling factors separately for\\na concatenation-based model but must be considered to-\\ngether. Take scaling-up depth as an example, such an ac-\\ntion will cause a ratio change between the input channel and\\noutput channel of a transition layer, which may lead to a de-\\ncrease in the hardware usage of the model. Therefore, we\\nmust propose the corresponding compound model scaling\\nmethod for a concatenation-based model. When we scale\\nthe depth factor of a computational block, we must also cal-\\nculate the change of the output channel of that block. Then,\\nwe will perform width factor scaling with the same amount\\nof change on the transition layers, and the result is shown\\nin Figure 3 (c). Our proposed compound scaling method\\ncan maintain the properties that the model had at the initial\\ndesign and maintains the optimal structure.\\n4. Trainable bag-of-freebies\\n4.1. Planned re-parameterized convolution\\nAlthough RepConv [13] has achieved excellent perfor-\\nmance on the VGG [68], when we directly apply it to\\nResNet [26] and DenseNet [32] and other architectures,\\nits accuracy will be signiﬁcantly reduced. We use gradi-\\nent ﬂow propagation paths to analyze how re-parameterized\\nconvolution should be combined with different network.\\nWe also designed planned re-parameterized convolution ac-\\ncordingly.\\nFigure 4: Planned re-parameterized model. In the proposed\\nplanned re-parameterized model, we found that a layer with resid-\\nual or concatenation connections, its RepConv should not have\\nidentity connection. Under these circumstances, it can be replaced\\nby RepConvN that contains no identity connections.\\nRepConv actually combines 3×3convolution, 1×1\\nconvolution, and identity connection in one convolutional\\nlayer. After analyzing the combination and correspond-\\ning performance of RepConv and different architectures,\\nwe ﬁnd that the identity connection in RepConv destroys\\nthe residual in ResNet and the concatenation in DenseNet,\\nwhich provides more diversity of gradients for different fea-\\nture maps. For the above reasons, we use RepConv with-\\nout identity connection (RepConvN) to design the architec-\\nture of planned re-parameterized convolution. In our think-\\ning, when a convolutional layer with residual or concate-\\nnation is replaced by re-parameterized convolution, there\\nshould be no identity connection. Figure 4 shows an exam-\\nple of our designed “planned re-parameterized convolution”\\nused in PlainNet and ResNet. As for the complete planned\\nre-parameterized convolution experiment in residual-based\\nmodel and concatenation-based model, it will be presented\\nin the ablation study session.\\n4'),\n",
       " Document(page_content='References\\n[1] anonymous. Designing network design strategies. anony-\\nmous submission , 2022. 3\\n[2] Irwan Bello, William Fedus, Xianzhi Du, Ekin Dogus\\nCubuk, Aravind Srinivas, Tsung-Yi Lin, Jonathon Shlens,\\nand Barret Zoph. Revisiting ResNets: Improved training\\nand scaling strategies. Advances in Neural Information Pro-\\ncessing Systems (NeurIPS) , 34, 2021. 2\\n[3] Alexey Bochkovskiy, Chien-Yao Wang, and Hong-\\nYuan Mark Liao. YOLOv4: Optimal speed and accuracy of\\nobject detection. arXiv preprint arXiv:2004.10934 , 2020.\\n2, 6, 7\\n[4] Yue Cao, Thomas Andrew Geddes, Jean Yee Hwa Yang,\\nand Pengyi Yang. Ensemble deep learning in bioinformat-\\nics.Nature Machine Intelligence , 2(9):500–508, 2020. 2\\n[5] Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nico-\\nlas Usunier, Alexander Kirillov, and Sergey Zagoruyko.\\nEnd-to-end object detection with transformers. In Pro-\\nceedings of the European Conference on Computer Vision\\n(ECCV) , pages 213–229, 2020. 10\\n[6] Kean Chen, Weiyao Lin, Jianguo Li, John See, Ji Wang, and\\nJunni Zou. AP-loss for accurate one-stage object detection.\\nIEEE Transactions on Pattern Analysis and Machine Intel-\\nligence (TPAMI) , 43(11):3782–3798, 2020. 2\\n[7] Zhe Chen, Yuchen Duan, Wenhai Wang, Junjun He, Tong\\nLu, Jifeng Dai, and Yu Qiao. Vision transformer adapter for\\ndense predictions. arXiv preprint arXiv:2205.08534 , 2022.\\n10\\n[8] Jiwoong Choi, Dayoung Chun, Hyun Kim, and Hyuk-Jae\\nLee. Gaussian YOLOv3: An accurate and fast object detec-\\ntor using localization uncertainty for autonomous driving.\\nInProceedings of the IEEE/CVF International Conference\\non Computer Vision (ICCV) , pages 502–511, 2019. 5\\n[9] Xiyang Dai, Yinpeng Chen, Bin Xiao, Dongdong Chen,\\nMengchen Liu, Lu Yuan, and Lei Zhang. Dynamic head:\\nUnifying object detection heads with attentions. In Pro-\\nceedings of the IEEE/CVF Conference on Computer Vision\\nand Pattern Recognition (CVPR) , pages 7373–7382, 2021.\\n2\\n[10] Xiaohan Ding, Honghao Chen, Xiangyu Zhang, Kaiqi\\nHuang, Jungong Han, and Guiguang Ding. Re-\\nparameterizing your optimizers rather than architectures.\\narXiv preprint arXiv:2205.15242 , 2022. 2\\n[11] Xiaohan Ding, Yuchen Guo, Guiguang Ding, and Jungong\\nHan. ACNet: Strengthening the kernel skeletons for pow-\\nerful CNN via asymmetric convolution blocks. In Proceed-\\nings of the IEEE/CVF International Conference on Com-\\nputer Vision (ICCV) , pages 1911–1920, 2019. 2\\n[12] Xiaohan Ding, Xiangyu Zhang, Jungong Han, and\\nGuiguang Ding. Diverse branch block: Building a con-\\nvolution as an inception-like unit. In Proceedings of the\\nIEEE/CVF Conference on Computer Vision and Pattern\\nRecognition (CVPR) , pages 10886–10895, 2021. 2\\n[13] Xiaohan Ding, Xiangyu Zhang, Ningning Ma, Jungong\\nHan, Guiguang Ding, and Jian Sun. RepVGG: Making\\nVGG-style convnets great again. In Proceedings of theIEEE/CVF Conference on Computer Vision and Pattern\\nRecognition (CVPR) , pages 13733–13742, 2021. 2, 4\\n[14] Xiaohan Ding, Xiangyu Zhang, Yizhuang Zhou, Jungong\\nHan, Guiguang Ding, and Jian Sun. Scaling up your ker-\\nnels to 31x31: Revisiting large kernel design in CNNs. In\\nProceedings of the IEEE/CVF Conference on Computer Vi-\\nsion and Pattern Recognition (CVPR) , 2022. 2\\n[15] Piotr Doll ´ar, Mannat Singh, and Ross Girshick. Fast and\\naccurate model scaling. In Proceedings of the IEEE/CVF\\nConference on Computer Vision and Pattern Recognition\\n(CVPR) , pages 924–932, 2021. 2, 3\\n[16] Xianzhi Du, Barret Zoph, Wei-Chih Hung, and Tsung-Yi\\nLin. Simple training strategies and model scaling for object\\ndetection. arXiv preprint arXiv:2107.00057 , 2021. 2\\n[17] Chengjian Feng, Yujie Zhong, Yu Gao, Matthew R Scott,\\nand Weilin Huang. TOOD: Task-aligned one-stage object\\ndetection. In Proceedings of the IEEE/CVF International\\nConference on Computer Vision (ICCV) , pages 3490–3499,\\n2021. 2, 5\\n[18] Di Feng, Christian Haase-Sch ¨utz, Lars Rosenbaum, Heinz\\nHertlein, Claudius Glaeser, Fabian Timm, Werner Wies-\\nbeck, and Klaus Dietmayer. Deep multi-modal object de-\\n\\n2021. 2, 5\\n[18] Di Feng, Christian Haase-Sch ¨utz, Lars Rosenbaum, Heinz\\nHertlein, Claudius Glaeser, Fabian Timm, Werner Wies-\\nbeck, and Klaus Dietmayer. Deep multi-modal object de-\\ntection and semantic segmentation for autonomous driv-\\ning: Datasets, methods, and challenges. IEEE Transac-\\ntions on Intelligent Transportation Systems , 22(3):1341–\\n1360, 2020. 1\\n[19] Timur Garipov, Pavel Izmailov, Dmitrii Podoprikhin,\\nDmitry P Vetrov, and Andrew G Wilson. Loss sur-\\nfaces, mode connectivity, and fast ensembling of DNNs.\\nAdvances in Neural Information Processing Systems\\n(NeurIPS) , 31, 2018. 2\\n[20] Zheng Ge, Songtao Liu, Zeming Li, Osamu Yoshie, and\\nJian Sun. OTA: Optimal transport assignment for object\\ndetection. In Proceedings of the IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition (CVPR) , pages\\n303–312, 2021. 2, 5\\n[21] Zheng Ge, Songtao Liu, Feng Wang, Zeming Li, and Jian\\nSun. YOLOX: Exceeding YOLO series in 2021. arXiv\\npreprint arXiv:2107.08430 , 2021. 1, 2, 7, 10\\n[22] Golnaz Ghiasi, Tsung-Yi Lin, and Quoc V Le. NAS-FPN:\\nLearning scalable feature pyramid architecture for object\\ndetection. In Proceedings of the IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition (CVPR) , pages\\n7036–7045, 2019. 2\\n[23] Jocher Glenn. YOLOv5 release v6.1. https://github.com/\\nultralytics/yolov5/releases/tag/v6.1, 2022. 2, 7, 10\\n[24] Shuxuan Guo, Jose M Alvarez, and Mathieu Salzmann. Ex-\\npandNets: Linear over-parameterization to train compact\\nconvolutional networks. Advances in Neural Information\\nProcessing Systems (NeurIPS) , 33:1298–1310, 2020. 2\\n[25] Kai Han, Yunhe Wang, Qi Tian, Jianyuan Guo, Chunjing\\nXu, and Chang Xu. GhostNet: More features from cheap\\noperations. In Proceedings of the IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition (CVPR) , pages\\n1580–1589, 2020. 1\\n[26] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.\\nDeep residual learning for image recognition. In Proceed-\\n12\\n\\nings of the IEEE/CVF Conference on Computer Vision and\\nPattern Recognition (CVPR) , pages 770–778, 2016. 1, 4, 5\\n[27] Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh\\nChen, Bo Chen, Mingxing Tan, Weijun Wang, Yukun Zhu,\\nRuoming Pang, Vijay Vasudevan, et al. Searching for Mo-\\nbileNetV3. In Proceedings of the IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition (CVPR) , pages\\n1314–1324, 2019. 1\\n[28] Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry\\nKalenichenko, Weijun Wang, Tobias Weyand, Marco An-\\ndreetto, and Hartwig Adam. MobileNets: Efﬁcient con-\\nvolutional neural networks for mobile vision applications.\\narXiv preprint arXiv:1704.04861 , 2017. 1\\n[29] Mu Hu, Junyi Feng, Jiashen Hua, Baisheng Lai, Jian-\\nqiang Huang, Xiaojin Gong, and Xiansheng Hua. On-\\nline convolutional re-parameterization. In Proceedings of\\nthe IEEE/CVF Conference on Computer Vision and Pattern\\nRecognition (CVPR) , 2022. 2\\n[30] Miao Hu, Yali Li, Lu Fang, and Shengjin Wang. A2-FPN:\\nAttention aggregation based feature pyramid network for\\ninstance segmentation. In Proceedings of the IEEE/CVF\\nConference on Computer Vision and Pattern Recognition\\n(CVPR) , pages 15343–15352, 2021. 2\\n[31] Gao Huang, Yixuan Li, Geoff Pleiss, Zhuang Liu, John E\\nHopcroft, and Kilian Q Weinberger. Snapshot ensembles:\\nTrain 1, get m for free. International Conference on Learn-\\ning Representations (ICLR) , 2017. 2\\n[32] Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kil-\\nian Q Weinberger. Densely connected convolutional net-\\nworks. In Proceedings of the IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition (CVPR) , pages\\n4700–4708, 2017. 2, 4, 5\\n[33] Pavel Izmailov, Dmitrii Podoprikhin, Timur Garipov,\\nDmitry Vetrov, and Andrew Gordon Wilson. Averaging\\nweights leads to wider optima and better generalization. In\\nConference on Uncertainty in Artiﬁcial Intelligence (UAI) ,\\n2018. 2\\n[34] Paul F Jaeger, Simon AA Kohl, Sebastian Bickel-\\nhaupt, Fabian Isensee, Tristan Anselm Kuder, Heinz-Peter\\nSchlemmer, and Klaus H Maier-Hein. Retina U-Net: Em-\\nbarrassingly simple exploitation of segmentation supervi-\\nsion for medical object detection. In Machine Learning for\\nHealth Workshop , pages 171–183, 2020. 1\\n[35] Hakan Karaoguz and Patric Jensfelt. Object detection ap-\\nproach for robot grasp detection. In IEEE International\\nConference on Robotics and Automation (ICRA) , pages\\n4953–4959, 2019. 1\\n[36] Kang Kim and Hee Seok Lee. Probabilistic anchor as-\\nsignment with iou prediction for object detection. In Pro-\\nceedings of the European conference on computer vision\\n(ECCV) , pages 355–371, 2020. 5\\n[37] Alexander Kirillov, Ross Girshick, Kaiming He, and Piotr\\nDoll´ar. Panoptic feature pyramid networks. In Proceed-\\nings of the IEEE/CVF Conference on Computer Vision and\\nPattern Recognition (CVPR) , pages 6399–6408, 2019. 2\\n[38] Chen-Yu Lee, Saining Xie, Patrick Gallagher, Zhengyou\\nZhang, and Zhuowen Tu. Deeply-supervised nets. In Arti-\\nﬁcial Intelligence and Statistics , pages 562–570, 2015. 5[39] Youngwan Lee, Joong-won Hwang, Sangrok Lee, Yuseok\\nBae, and Jongyoul Park. An energy and GPU-computation\\nefﬁcient backbone network for real-time object detection.\\nInProceedings of the IEEE/CVF Conference on Com-\\nputer Vision and Pattern Recognition Workshops (CVPRW) ,\\npages 0–0, 2019. 2, 3\\n[40] Buyu Li, Wanli Ouyang, Lu Sheng, Xingyu Zeng, and\\nXiaogang Wang. GS3D: An efﬁcient 3d object detection\\nframework for autonomous driving. In Proceedings of the\\nIEEE/CVF Conference on Computer Vision and Pattern\\nRecognition (CVPR) , pages 1019–1028, 2019. 1\\n[41] Feng Li, Hao Zhang, Shilong Liu, Jian Guo, Lionel M\\nNi, and Lei Zhang. DN-DETR: Accelerate detr training\\nby introducing query denoising. In Proceedings of the\\nIEEE/CVF Conference on Computer Vision and Pattern\\nRecognition (CVPR) , pages 13619–13627, 2022. 10\\n[42] Shuai Li, Chenhang He, Ruihuang Li, and Lei Zhang. A\\ndual weighting label assignment scheme for object detec-\\ntion. In Proceedings of the IEEE/CVF Conference on Com-'),\n",
       " Document(page_content='YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object\\ndetectors\\nChien-Yao Wang1, Alexey Bochkovskiy, and Hong-Yuan Mark Liao1\\n1Institute of Information Science, Academia Sinica, Taiwan\\nkinyiu@iis.sinica.edu.tw, alexeyab84@gmail.com, and liao@iis.sinica.edu.tw\\nAbstract\\nYOLOv7 surpasses all known object detectors in both\\nspeed and accuracy in the range from 5 FPS to 160 FPS\\nand has the highest accuracy 56.8% AP among all known\\nreal-time object detectors with 30 FPS or higher on GPU\\nV100. YOLOv7-E6 object detector (56 FPS V100, 55.9%\\nAP) outperforms both transformer-based detector SWIN-\\nL Cascade-Mask R-CNN (9.2 FPS A100, 53.9% AP) by\\n509% in speed and 2% in accuracy, and convolutional-\\nbased detector ConvNeXt-XL Cascade-Mask R-CNN (8.6\\nFPS A100, 55.2% AP) by 551% in speed and 0.7% AP\\nin accuracy, as well as YOLOv7 outperforms: YOLOR,\\nYOLOX, Scaled-YOLOv4, YOLOv5, DETR, Deformable\\nDETR, DINO-5scale-R50, ViT-Adapter-B and many other\\nobject detectors in speed and accuracy. Moreover, we train\\nYOLOv7 only on MS COCO dataset from scratch without\\nusing any other datasets or pre-trained weights. Source\\ncode is released in https://github.com/WongKinYiu/yolov7.\\n1. Introduction\\nReal-time object detection is a very important topic in\\ncomputer vision, as it is often a necessary component in\\ncomputer vision systems. For example, multi-object track-\\ning [94, 93], autonomous driving [40, 18], robotics [35, 58],\\nmedical image analysis [34, 46], etc. The computing de-\\nvices that execute real-time object detection is usually some\\nmobile CPU or GPU, as well as various neural processing\\nunits (NPU) developed by major manufacturers. For exam-\\nple, the Apple neural engine (Apple), the neural compute\\nstick (Intel), Jetson AI edge devices (Nvidia), the edge TPU\\n(Google), the neural processing engine (Qualcomm), the AI\\nprocessing unit (MediaTek), and the AI SoCs (Kneron), are\\nall NPUs. Some of the above mentioned edge devices focus\\non speeding up different operations such as vanilla convolu-\\ntion, depth-wise convolution, or MLP operations. In this pa-\\nper, the real-time object detector we proposed mainly hopes\\nthat it can support both mobile GPU and GPU devices from\\nthe edge to the cloud.\\nIn recent years, the real-time object detector is still de-\\nveloped for different edge device. For example, the devel-\\nFigure 1: Comparison with other real-time object detectors, our\\nproposed methods achieve state-of-the-arts performance.\\nopment of MCUNet [49, 48] and NanoDet [54] focused on\\nproducing low-power single-chip and improving the infer-\\nence speed on edge CPU. As for methods such as YOLOX\\n[21] and YOLOR [81], they focus on improving the infer-\\nence speed of various GPUs. More recently, the develop-\\nment of real-time object detector has focused on the de-\\nsign of efﬁcient architecture. As for real-time object de-\\ntectors that can be used on CPU [54, 88, 84, 83], their de-\\nsign is mostly based on MobileNet [28, 66, 27], ShufﬂeNet\\n[92, 55], or GhostNet [25]. Another mainstream real-time\\nobject detectors are developed for GPU [81, 21, 97], they\\nmostly use ResNet [26], DarkNet [63], or DLA [87], and\\nthen use the CSPNet [80] strategy to optimize the architec-\\nture. The development direction of the proposed methods in\\nthis paper are different from that of the current mainstream\\nreal-time object detectors. In addition to architecture op-\\ntimization, our proposed methods will focus on the opti-\\nmization of the training process. Our focus will be on some\\noptimized modules and optimization methods which may\\nstrengthen the training cost for improving the accuracy of\\nobject detection, but without increasing the inference cost.\\nWe call the proposed modules and optimization methods\\ntrainable bag-of-freebies.\\n1arXiv:2207.02696v1  [cs.CV]  6 Jul 2022\\n\\nRecently, model re-parameterization [13, 12, 29] and dy-\\nnamic label assignment [20, 17, 42] have become important\\ntopics in network training and object detection. Mainly af-\\nter the above new concepts are proposed, the training of\\nobject detector evolves many new issues. In this paper, we\\nwill present some of the new issues we have discovered and\\ndevise effective methods to address them. For model re-\\nparameterization, we analyze the model re-parameterization\\nstrategies applicable to layers in different networks with the\\nconcept of gradient propagation path, and propose planned\\nre-parameterized model. In addition, when we discover that\\nwith dynamic label assignment technology, the training of\\nmodel with multiple output layers will generate new issues.\\nThat is: “How to assign dynamic targets for the outputs of\\ndifferent branches?” For this problem, we propose a new\\nlabel assignment method called coarse-to-ﬁne lead guided\\nlabel assignment.\\nThe contributions of this paper are summarized as fol-\\nlows: (1) we design several trainable bag-of-freebies meth-\\nods, so that real-time object detection can greatly improve\\nthe detection accuracy without increasing the inference\\ncost; (2) for the evolution of object detection methods, we\\nfound two new issues, namely how re-parameterized mod-\\nule replaces original module, and how dynamic label as-\\nsignment strategy deals with assignment to different output\\nlayers. In addition, we also propose methods to address the\\ndifﬁculties arising from these issues; (3) we propose “ex-\\ntend” and “compound scaling” methods for the real-time\\nobject detector that can effectively utilize parameters and\\ncomputation; and (4) the method we proposed can effec-\\ntively reduce about 40% parameters and 50% computation\\nof state-of-the-art real-time object detector, and has faster\\ninference speed and higher detection accuracy.\\n2. Related work\\n2.1. Real-time object detectors\\nCurrently state-of-the-art real-time object detectors are\\nmainly based on YOLO [61, 62, 63] and FCOS [76, 77],\\nwhich are [3, 79, 81, 21, 54, 85, 23]. Being able to become\\na state-of-the-art real-time object detector usually requires\\nthe following characteristics: (1) a faster and stronger net-\\nwork architecture; (2) a more effective feature integration\\nmethod [22, 97, 37, 74, 59, 30, 9, 45]; (3) a more accurate\\ndetection method [76, 77, 69]; (4) a more robust loss func-\\ntion [96, 64, 6, 56, 95, 57]; (5) a more efﬁcient label assign-\\nment method [99, 20, 17, 82, 42]; and (6) a more efﬁcient\\ntraining method. In this paper, we do not intend to explore\\nself-supervised learning or knowledge distillation methods\\nthat require additional data or large model. Instead, we will\\ndesign new trainable bag-of-freebies method for the issues\\nderived from the state-of-the-art methods associated with\\n(4), (5), and (6) mentioned above.2.2. Model re-parameterization\\nModel re-parametrization techniques [71, 31, 75, 19, 33,\\n11, 4, 24, 13, 12, 10, 29, 14, 78] merge multiple compu-\\ntational modules into one at inference stage. The model\\nre-parameterization technique can be regarded as an en-\\nsemble technique, and we can divide it into two cate-\\ngories, i.e., module-level ensemble and model-level ensem-\\nble. There are two common practices for model-level re-\\nparameterization to obtain the ﬁnal inference model. One\\nis to train multiple identical models with different train-\\ning data, and then average the weights of multiple trained\\nmodels. The other is to perform a weighted average of the\\nweights of models at different iteration number. Module-\\nlevel re-parameterization is a more popular research issue\\nrecently. This type of method splits a module into multi-\\nple identical or different module branches during training\\nand integrates multiple branched modules into a completely\\nequivalent module during inference. However, not all pro-\\nposed re-parameterized module can be perfectly applied to\\ndifferent architectures. With this in mind, we have devel-\\n\\nequivalent module during inference. However, not all pro-\\nposed re-parameterized module can be perfectly applied to\\ndifferent architectures. With this in mind, we have devel-\\noped new re-parameterization module and designed related\\napplication strategies for various architectures.\\n2.3. Model scaling\\nModel scaling [72, 60, 74, 73, 15, 16, 2, 51] is a way\\nto scale up or down an already designed model and make\\nit ﬁt in different computing devices. The model scaling\\nmethod usually uses different scaling factors, such as reso-\\nlution (size of input image), depth (number of layer), width\\n(number of channel), and stage (number of feature pyra-\\nmid), so as to achieve a good trade-off for the amount of\\nnetwork parameters, computation, inference speed, and ac-\\ncuracy. Network architecture search (NAS) is one of the\\ncommonly used model scaling methods. NAS can automat-\\nically search for suitable scaling factors from search space\\nwithout deﬁning too complicated rules. The disadvantage\\nof NAS is that it requires very expensive computation to\\ncomplete the search for model scaling factors. In [15], the\\nresearcher analyzes the relationship between scaling factors\\nand the amount of parameters and operations, trying to di-\\nrectly estimate some rules, and thereby obtain the scaling\\nfactors required by model scaling. Checking the literature,\\nwe found that almost all model scaling methods analyze in-\\ndividual scaling factor independently, and even the methods\\nin the compound scaling category also optimized scaling\\nfactor independently. The reason for this is because most\\npopular NAS architectures deal with scaling factors that are\\nnot very correlated. We observed that all concatenation-\\nbased models, such as DenseNet [32] or V oVNet [39], will\\nchange the input width of some layers when the depth of\\nsuch models is scaled. Since the proposed architecture is\\nconcatenation-based, we have to design a new compound\\nscaling method for this model.\\n2'),\n",
       " Document(page_content='[42] Shuai Li, Chenhang He, Ruihuang Li, and Lei Zhang. A\\ndual weighting label assignment scheme for object detec-\\ntion. In Proceedings of the IEEE/CVF Conference on Com-\\nputer Vision and Pattern Recognition (CVPR) , pages 9387–\\n9396, 2022. 2, 5\\n[43] Xiang Li, Wenhai Wang, Xiaolin Hu, Jun Li, Jinhui Tang,\\nand Jian Yang. Generalized focal loss v2: Learning reliable\\nlocalization quality estimation for dense object detection. In\\nProceedings of the IEEE/CVF Conference on Computer Vi-\\nsion and Pattern Recognition (CVPR) , pages 11632–11641,\\n2021. 5\\n[44] Xiang Li, Wenhai Wang, Lijun Wu, Shuo Chen, Xiaolin\\nHu, Jun Li, Jinhui Tang, and Jian Yang. Generalized focal\\nloss: Learning qualiﬁed and distributed bounding boxes for\\ndense object detection. Advances in Neural Information\\nProcessing Systems (NeurIPS) , 33:21002–21012, 2020. 5\\n[45] Yanghao Li, Hanzi Mao, Ross Girshick, and Kaiming He.\\nExploring plain vision transformer backbones for object de-\\ntection. arXiv preprint arXiv:2203.16527 , 2022. 2\\n[46] Zhuoling Li, Minghui Dong, Shiping Wen, Xiang Hu, Pan\\nZhou, and Zhigang Zeng. CLU-CNNs: Object detection for\\nmedical images. Neurocomputing , 350:53–59, 2019. 1\\n[47] Tingting Liang, Xiaojie Chu, Yudong Liu, Yongtao Wang,\\nZhi Tang, Wei Chu, Jingdong Chen, and Haibin Ling. CB-\\nNetV2: A composite backbone network architecture for ob-\\nject detection. arXiv preprint arXiv:2107.00420 , 2021. 5,\\n10\\n[48] Ji Lin, Wei-Ming Chen, Han Cai, Chuang Gan, and Song\\nHan. Memory-efﬁcient patch-based inference for tiny deep\\nlearning. Advances in Neural Information Processing Sys-\\ntems (NeurIPS) , 34:2346–2358, 2021. 1\\n[49] Ji Lin, Wei-Ming Chen, Yujun Lin, Chuang Gan, Song\\nHan, et al. MCUNet: Tiny deep learning on IoT de-\\nvices. Advances in Neural Information Processing Systems\\n(NeurIPS) , 33:11711–11722, 2020. 1\\n[50] Yuxuan Liu, Lujia Wang, and Ming Liu. YOLOStereo3D:\\nA step back to 2D for efﬁcient stereo 3D detection. In\\nIEEE International Conference on Robotics and Automa-\\ntion (ICRA) , pages 13018–13024, 2021. 5\\n[51] Ze Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie,\\nYixuan Wei, Jia Ning, Yue Cao, Zheng Zhang, Li Dong,\\n13\\n\\net al. Swin transformer v2: Scaling up capacity and res-\\nolution. In Proceedings of the IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition (CVPR) , 2022. 2\\n[52] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng\\nZhang, Stephen Lin, and Baining Guo. Swin transformer:\\nHierarchical vision transformer using shifted windows. In\\nProceedings of the IEEE/CVF International Conference on\\nComputer Vision (ICCV) , pages 10012–10022, 2021. 10\\n[53] Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feicht-\\nenhofer, Trevor Darrell, and Saining Xie. A ConvNet for\\nthe 2020s. In Proceedings of the IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition (CVPR) , pages\\n11976–11986, 2022. 10\\n[54] Rangi Lyu. NanoDet-Plus. https://github.com/RangiLyu/\\nnanodet/releases/tag/v1.0.0-alpha-1, 2021. 1, 2\\n[55] Ningning Ma, Xiangyu Zhang, Hai-Tao Zheng, and Jian\\nSun. ShufﬂeNet V2: Practical guidelines for efﬁcient CNN\\narchitecture design. In Proceedings of the European Con-\\nference on Computer Vision (ECCV) , pages 116–131, 2018.\\n1, 3\\n[56] Kemal Oksuz, Baris Can Cam, Emre Akbas, and Sinan\\nKalkan. A ranking-based, balanced loss function unifying\\nclassiﬁcation and localisation in object detection. Advances\\nin Neural Information Processing Systems (NeurIPS) ,\\n33:15534–15545, 2020. 2\\n[57] Kemal Oksuz, Baris Can Cam, Emre Akbas, and Sinan\\nKalkan. Rank & sort loss for object detection and in-\\nstance segmentation. In Proceedings of the IEEE/CVF In-\\nternational Conference on Computer Vision (ICCV) , pages\\n3009–3018, 2021. 2\\n[58] Shuvo Kumar Paul, Muhammed Tawﬁq Chowdhury,\\nMircea Nicolescu, Monica Nicolescu, and David Feil-\\nSeifer. Object detection and pose estimation from rgb and\\ndepth data for real-time, adaptive robotic grasping. In Ad-\\nvances in Computer Vision and Computational Biology ,\\npages 121–142. 2021. 1\\n[59] Siyuan Qiao, Liang-Chieh Chen, and Alan Yuille. De-\\ntectoRS: Detecting objects with recursive feature pyramid\\nand switchable atrous convolution. In Proceedings of the\\nIEEE/CVF Conference on Computer Vision and Pattern\\nRecognition (CVPR) , pages 10213–10224, 2021. 2\\n[60] Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick,\\nKaiming He, and Piotr Doll ´ar. Designing network design\\nspaces. In Proceedings of the IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition (CVPR) , pages\\n10428–10436, 2020. 2\\n[61] Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali\\nFarhadi. You only look once: Uniﬁed, real-time object de-\\ntection. In Proceedings of the IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition (CVPR) , pages\\n779–788, 2016. 2, 5\\n[62] Joseph Redmon and Ali Farhadi. YOLO9000: better, faster,\\nstronger. In Proceedings of the IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition (CVPR) , pages\\n7263–7271, 2017. 2\\n[63] Joseph Redmon and Ali Farhadi. YOLOv3: An incremental\\nimprovement. arXiv preprint arXiv:1804.02767 , 2018. 1, 2[64] Hamid Rezatoﬁghi, Nathan Tsoi, JunYoung Gwak, Amir\\nSadeghian, Ian Reid, and Silvio Savarese. Generalized in-\\ntersection over union: A metric and a loss for bounding\\nbox regression. In Proceedings of the IEEE/CVF Confer-\\nence on Computer Vision and Pattern Recognition (CVPR) ,\\npages 658–666, 2019. 2\\n[65] Byungseok Roh, JaeWoong Shin, Wuhyun Shin, and\\nSaehoon Kim. Sparse DETR: Efﬁcient end-to-end ob-\\nject detection with learnable sparsity. arXiv preprint\\narXiv:2111.14330 , 2021. 5\\n[66] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey\\nZhmoginov, and Liang-Chieh Chen. MobileNetV2: In-\\nverted residuals and linear bottlenecks. In Proceedings of\\nthe IEEE/CVF Conference on Computer Vision and Pattern\\nRecognition (CVPR) , pages 4510–4520, 2018. 1\\n[67] Zhiqiang Shen, Zhuang Liu, Jianguo Li, Yu-Gang Jiang,\\nYurong Chen, and Xiangyang Xue. Object detection\\nfrom scratch with deep supervision. IEEE Transactions\\non Pattern Analysis and Machine Intelligence (TPAMI) ,\\n42(2):398–412, 2019. 5\\n[68] Karen Simonyan and Andrew Zisserman. Very deep convo-\\n\\nfrom scratch with deep supervision. IEEE Transactions\\non Pattern Analysis and Machine Intelligence (TPAMI) ,\\n42(2):398–412, 2019. 5\\n[68] Karen Simonyan and Andrew Zisserman. Very deep convo-\\nlutional networks for large-scale image recognition. arXiv\\npreprint arXiv:1409.1556 , 2014. 4\\n[69] Peize Sun, Rufeng Zhang, Yi Jiang, Tao Kong, Chenfeng\\nXu, Wei Zhan, Masayoshi Tomizuka, Lei Li, Zehuan Yuan,\\nChanghu Wang, et al. Sparse R-CNN: End-to-end ob-\\nject detection with learnable proposals. In Proceedings of\\nthe IEEE/CVF Conference on Computer Vision and Pattern\\nRecognition (CVPR) , pages 14454–14463, 2021. 2\\n[70] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet,\\nScott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent\\nVanhoucke, and Andrew Rabinovich. Going deeper with\\nconvolutions. In Proceedings of the IEEE/CVF Confer-\\nence on Computer Vision and Pattern Recognition (CVPR) ,\\npages 1–9, 2015. 5\\n[71] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon\\nShlens, and Zbigniew Wojna. Rethinking the inception\\narchitecture for computer vision. In Proceedings of the\\nIEEE/CVF Conference on Computer Vision and Pattern\\nRecognition (CVPR) , pages 2818–2826, 2016. 2\\n[72] Mingxing Tan and Quoc Le. EfﬁcientNet: Rethinking\\nmodel scaling for convolutional neural networks. In Inter-\\nnational Conference on Machine Learning (ICML) , pages\\n6105–6114, 2019. 2, 3\\n[73] Mingxing Tan and Quoc Le. EfﬁcientNetv2: Smaller mod-\\nels and faster training. In International Conference on Ma-\\nchine Learning (ICML) , pages 10096–10106, 2021. 2\\n[74] Mingxing Tan, Ruoming Pang, and Quoc V Le. Efﬁcient-\\nDet: Scalable and efﬁcient object detection. In Proceedings\\nof the IEEE/CVF Conference on Computer Vision and Pat-\\ntern Recognition (CVPR) , pages 10781–10790, 2020. 2, 10\\n[75] Antti Tarvainen and Harri Valpola. Mean teachers are better\\nrole models: Weight-averaged consistency targets improve\\nsemi-supervised deep learning results. Advances in Neural\\nInformation Processing Systems (NeurIPS) , 30, 2017. 2, 6\\n[76] Zhi Tian, Chunhua Shen, Hao Chen, and Tong He. FCOS:\\nFully convolutional one-stage object detection. In Proceed-\\n14')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "  Answer the question as detailed as possible from the provided context, make sure to provide all the details, if the answer is not in\n",
    "  provided context just say, \"answer is not available in the context\", don't provide the wrong answer\\n\\n\n",
    "  Context:\\n {context}?\\n\n",
    "  Question: \\n{question}\\n\n",
    "\n",
    "  Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template = prompt_template, input_variables = [\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
    "                             temperature=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaide\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "response = chain(\n",
    "    {\"input_documents\":docs, \"question\": question}\n",
    "    , return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': 'Planned re-parameterized convolution is a method to replace a convolutional layer with residual or concatenation connections with a re-parameterized convolution without identity connection.'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
